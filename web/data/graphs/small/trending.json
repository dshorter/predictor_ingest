{
  "meta": {
    "view": "trending",
    "nodeCount": 10,
    "edgeCount": 7,
    "exportedAt": "2026-01-25T12:00:00Z",
    "dateRange": {
      "start": "2025-10-25",
      "end": "2026-01-25"
    },
    "filters": {
      "minVelocity": 0.1,
      "minConfidence": 0.3
    }
  },
  "elements": {
    "nodes": [
      {
        "data": {
          "id": "program:eu_ai_act",
          "label": "EU AI Act",
          "type": "Program",
          "aliases": [
            "AI Act"
          ],
          "firstSeen": "2026-01-24",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 5,
          "mentionCount30d": 11,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "repo:transformers",
          "label": "transformers",
          "type": "Repo",
          "aliases": [
            "huggingface/transformers"
          ],
          "firstSeen": "2025-10-29",
          "lastSeen": "2025-12-08",
          "mentionCount7d": 5,
          "mentionCount30d": 17,
          "velocity": 0.93
        }
      },
      {
        "data": {
          "id": "dataset:common_crawl",
          "label": "Common Crawl",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-12",
          "lastSeen": "2025-12-17",
          "mentionCount7d": 8,
          "mentionCount30d": 34,
          "velocity": 0.87
        }
      },
      {
        "data": {
          "id": "paper:attention_is_all_you_need_v2",
          "label": "Attention Is All You Need v2",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2026-01-14",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 6,
          "mentionCount30d": 26,
          "velocity": 0.87
        }
      },
      {
        "data": {
          "id": "tech:transformer_architecture",
          "label": "Transformer Architecture",
          "type": "Tech",
          "aliases": [
            "Transformers"
          ],
          "firstSeen": "2025-12-01",
          "lastSeen": "2025-12-06",
          "mentionCount7d": 4,
          "mentionCount30d": 13,
          "velocity": 0.83
        }
      },
      {
        "data": {
          "id": "event:neurips_2025",
          "label": "NeurIPS 2025",
          "type": "Event",
          "aliases": [],
          "firstSeen": "2025-11-27",
          "lastSeen": "2025-12-05",
          "mentionCount7d": 6,
          "mentionCount30d": 14,
          "velocity": 0.74
        }
      },
      {
        "data": {
          "id": "org:openai",
          "label": "OpenAI",
          "type": "Org",
          "aliases": [
            "Open AI"
          ],
          "firstSeen": "2026-01-14",
          "lastSeen": "2026-01-15",
          "mentionCount7d": 21,
          "mentionCount30d": 68,
          "velocity": 0.73
        }
      },
      {
        "data": {
          "id": "tech:mixture_of_experts",
          "label": "Mixture of Experts",
          "type": "Tech",
          "aliases": [
            "MoE"
          ],
          "firstSeen": "2025-11-14",
          "lastSeen": "2025-12-31",
          "mentionCount7d": 11,
          "mentionCount30d": 30,
          "velocity": 0.69
        }
      },
      {
        "data": {
          "id": "topic:ai_safety",
          "label": "AI Safety",
          "type": "Topic",
          "aliases": [
            "AI Alignment"
          ],
          "firstSeen": "2025-11-03",
          "lastSeen": "2026-01-19",
          "mentionCount7d": 8,
          "mentionCount30d": 17,
          "velocity": 0.63
        }
      },
      {
        "data": {
          "id": "tool:langchain",
          "label": "LangChain",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-08",
          "lastSeen": "2026-01-15",
          "mentionCount7d": 7,
          "mentionCount30d": 18,
          "velocity": 0.55
        }
      }
    ],
    "edges": [
      {
        "data": {
          "id": "e:eu_ai_act_openai_governs",
          "source": "program:eu_ai_act",
          "target": "org:openai",
          "rel": "GOVERNS",
          "kind": "inferred",
          "confidence": 0.83
        }
      },
      {
        "data": {
          "id": "e:openai_ai_safety_mentions",
          "source": "org:openai",
          "target": "topic:ai_safety",
          "rel": "MENTIONS",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2026-01-18_wired_2827",
              "url": "https://wired.com/2026/01/18/openai_ai_safety",
              "published": "2026-01-18",
              "snippet": "AI Safety was mentioned as a key factor in the analysis..."
            },
            {
              "docId": "2026-01-25_openai_blog_5315",
              "url": "https://openai.com/blog/2026/01/25/openai_ai_safety",
              "published": "2026-01-25",
              "snippet": "Multiple references to AI Safety appear throughout the report..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:transformers_transformer_architecture_uses_tech",
          "source": "repo:transformers",
          "target": "tech:transformer_architecture",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.69,
          "evidence": [
            {
              "docId": "2026-01-19_openai_blog_6310",
              "url": "https://openai.com/blog/2026/01/19/transformers_transformer_archi",
              "published": "2026-01-19",
              "snippet": "Under the hood, transformers implements Transformer Architecture for improved efficiency..."
            },
            {
              "docId": "2026-01-21_mit_technology__4923",
              "url": "https://technologyreview.com/2026/01/21/transformers_transformer_archi",
              "published": "2026-01-21",
              "snippet": "transformers leverages Transformer Architecture to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-21_the_gradient_2133",
              "url": "https://thegradient.pub/2026/01/21/transformers_transformer_archi",
              "published": "2026-01-21",
              "snippet": "Technical details reveal transformers relies heavily on Transformer Architecture..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:attention_is_all_you_need_v2_mixture_of_experts_uses_tech",
          "source": "paper:attention_is_all_you_need_v2",
          "target": "tech:mixture_of_experts",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-17_techcrunch_6107",
              "url": "https://techcrunch.com/2026/01/17/attention_is_all_you_need_v2_m",
              "published": "2026-01-17",
              "snippet": "Under the hood, Attention Is All You Need v2 implements Mixture of Experts for improved efficiency..."
            },
            {
              "docId": "2026-01-24_weights_and_bia_8397",
              "url": "https://wandb.ai/articles/2026/01/24/attention_is_all_you_need_v2_m",
              "published": "2026-01-24",
              "snippet": "Attention Is All You Need v2 leverages Mixture of Experts to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-24_wired_1344",
              "url": "https://wired.com/2026/01/24/attention_is_all_you_need_v2_m",
              "published": "2026-01-24",
              "snippet": "Technical details reveal Attention Is All You Need v2 relies heavily on Mixture of Experts..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:openai_attention_is_all_you_need_v2_published",
          "source": "org:openai",
          "target": "paper:attention_is_all_you_need_v2",
          "rel": "PUBLISHED",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2026-01-23_wired_5272",
              "url": "https://wired.com/2026/01/23/openai_attention_is_all_you_ne",
              "published": "2026-01-23",
              "snippet": "OpenAI published \"Attention Is All You Need v2\" detailing novel approaches..."
            },
            {
              "docId": "2026-01-23_venturebeat_7484",
              "url": "https://venturebeat.com/2026/01/23/openai_attention_is_all_you_ne",
              "published": "2026-01-23",
              "snippet": "OpenAI published \"Attention Is All You Need v2\" detailing novel approaches..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:common_crawl_transformer_architecture_uses_tech",
          "source": "dataset:common_crawl",
          "target": "tech:transformer_architecture",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:common_crawl_mixture_of_experts_uses_tech",
          "source": "dataset:common_crawl",
          "target": "tech:mixture_of_experts",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.57
        }
      }
    ]
  }
}