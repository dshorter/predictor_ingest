{
  "meta": {
    "view": "dependencies",
    "nodeCount": 281,
    "edgeCount": 688,
    "exportedAt": "2026-01-25T12:00:00Z",
    "dateRange": {
      "start": "2025-10-25",
      "end": "2026-01-25"
    }
  },
  "elements": {
    "nodes": [
      {
        "data": {
          "id": "tech:tokenizer_bpe_next",
          "label": "Tokenizer BPE Next",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-31",
          "lastSeen": "2026-01-22",
          "mentionCount7d": 1,
          "mentionCount30d": 11,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "dataset:starcoder_data",
          "label": "StarCoder Data",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2026-01-09",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 7,
          "mentionCount30d": 34,
          "velocity": 0.6
        }
      },
      {
        "data": {
          "id": "repo:gpt4all",
          "label": "gpt4all",
          "type": "Repo",
          "aliases": [],
          "firstSeen": "2025-11-03",
          "lastSeen": "2025-11-12",
          "mentionCount7d": 5,
          "mentionCount30d": 30,
          "velocity": 0.24
        }
      },
      {
        "data": {
          "id": "model:stable_diffusion_4_max",
          "label": "Stable Diffusion 4 Max",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-26",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 35,
          "mentionCount30d": 74,
          "velocity": 0.97
        }
      },
      {
        "data": {
          "id": "model:gpt_5_v2",
          "label": "GPT-5 v2",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-10",
          "lastSeen": "2026-01-16",
          "mentionCount7d": 7,
          "mentionCount30d": 25,
          "velocity": 0.65
        }
      },
      {
        "data": {
          "id": "tech:qlora",
          "label": "QLoRA",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-10-31",
          "lastSeen": "2026-01-01",
          "mentionCount7d": 13,
          "mentionCount30d": 79,
          "velocity": 0.48
        }
      },
      {
        "data": {
          "id": "paper:textbooks_are_all_you_need",
          "label": "Textbooks Are All You Need",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2026-01-25",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 13,
          "mentionCount30d": 40,
          "velocity": 0.93
        }
      },
      {
        "data": {
          "id": "model:claude_opus_45",
          "label": "Claude Opus 4.5",
          "type": "Model",
          "aliases": [
            "Opus 4.5",
            "Claude Opus"
          ],
          "firstSeen": "2025-11-21",
          "lastSeen": "2025-12-25",
          "mentionCount7d": 10,
          "mentionCount30d": 58,
          "velocity": 0.85
        }
      },
      {
        "data": {
          "id": "tech:tool_use_v2",
          "label": "Tool Use v2",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-22",
          "lastSeen": "2026-01-01",
          "mentionCount7d": 15,
          "mentionCount30d": 30,
          "velocity": 0.73
        }
      },
      {
        "data": {
          "id": "benchmark:mbpp",
          "label": "MBPP",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2025-12-12",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 6,
          "mentionCount30d": 21,
          "velocity": 0.26
        }
      },
      {
        "data": {
          "id": "model:dall_e_4_edge",
          "label": "DALL-E 4 Edge",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-06",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 38,
          "mentionCount30d": 108,
          "velocity": 0.23
        }
      },
      {
        "data": {
          "id": "model:claude_opus_45_pro",
          "label": "Claude Opus 4.5 Pro",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-19",
          "lastSeen": "2026-01-19",
          "mentionCount7d": 6,
          "mentionCount30d": 21,
          "velocity": 0.67
        }
      },
      {
        "data": {
          "id": "paper:scaling_data_constrained_language_models",
          "label": "Scaling Data-Constrained Language Models",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2026-01-15",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 6,
          "mentionCount30d": 15,
          "velocity": 0.92
        }
      },
      {
        "data": {
          "id": "model:midjourney_v7",
          "label": "Midjourney V7",
          "type": "Model",
          "aliases": [
            "MJ V7"
          ],
          "firstSeen": "2025-11-23",
          "lastSeen": "2026-01-12",
          "mentionCount7d": 17,
          "mentionCount30d": 29,
          "velocity": 0.5
        }
      },
      {
        "data": {
          "id": "model:qwen_3",
          "label": "Qwen-3",
          "type": "Model",
          "aliases": [
            "Qwen3",
            "Qwen 3"
          ],
          "firstSeen": "2025-11-10",
          "lastSeen": "2025-12-06",
          "mentionCount7d": 42,
          "mentionCount30d": 47,
          "velocity": 0.54
        }
      },
      {
        "data": {
          "id": "tech:synthetic_data_generation",
          "label": "Synthetic Data Generation",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-10-27",
          "lastSeen": "2026-01-12",
          "mentionCount7d": 4,
          "mentionCount30d": 31,
          "velocity": 0.12
        }
      },
      {
        "data": {
          "id": "model:codex_2_ultra",
          "label": "Codex 2 Ultra",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-06",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 17,
          "mentionCount30d": 48,
          "velocity": 0.77
        }
      },
      {
        "data": {
          "id": "paper:llm_agents:_a_survey_pro",
          "label": "LLM Agents: A Survey Pro",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-11-02",
          "lastSeen": "2025-12-28",
          "mentionCount7d": 6,
          "mentionCount30d": 13,
          "velocity": 0.42
        }
      },
      {
        "data": {
          "id": "tool:localai",
          "label": "LocalAI",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-18",
          "lastSeen": "2025-12-13",
          "mentionCount7d": 3,
          "mentionCount30d": 8,
          "velocity": 0.91
        }
      },
      {
        "data": {
          "id": "tech:tool_use",
          "label": "Tool Use",
          "type": "Tech",
          "aliases": [
            "Function Calling"
          ],
          "firstSeen": "2025-10-30",
          "lastSeen": "2025-11-03",
          "mentionCount7d": 8,
          "mentionCount30d": 19,
          "velocity": 0.33
        }
      },
      {
        "data": {
          "id": "benchmark:truthfulqa_plus",
          "label": "TruthfulQA Plus",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2026-01-02",
          "lastSeen": "2026-01-06",
          "mentionCount7d": 12,
          "mentionCount30d": 20,
          "velocity": 0.97
        }
      },
      {
        "data": {
          "id": "tech:lora",
          "label": "LoRA",
          "type": "Tech",
          "aliases": [
            "Low-Rank Adaptation"
          ],
          "firstSeen": "2025-10-26",
          "lastSeen": "2025-10-26",
          "mentionCount7d": 1,
          "mentionCount30d": 14,
          "velocity": 0.96
        }
      },
      {
        "data": {
          "id": "tech:group_query_attention",
          "label": "Group Query Attention",
          "type": "Tech",
          "aliases": [
            "GQA"
          ],
          "firstSeen": "2025-12-05",
          "lastSeen": "2026-01-17",
          "mentionCount7d": 6,
          "mentionCount30d": 31,
          "velocity": 0.41
        }
      },
      {
        "data": {
          "id": "model:aya_3",
          "label": "Aya 3",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-21",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 31,
          "mentionCount30d": 69,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "benchmark:gpqa_next",
          "label": "GPQA Next",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2026-01-01",
          "lastSeen": "2026-01-10",
          "mentionCount7d": 1,
          "mentionCount30d": 3,
          "velocity": 0.52
        }
      },
      {
        "data": {
          "id": "paper:tree_of_thoughts:_deliberate_problem_sol",
          "label": "Tree of Thoughts: Deliberate Problem Solving with LLMs",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-12-01",
          "lastSeen": "2026-01-06",
          "mentionCount7d": 0,
          "mentionCount30d": 4,
          "velocity": 0.55
        }
      },
      {
        "data": {
          "id": "paper:chain_of_thought_prompting_elicits_reaso",
          "label": "Chain-of-Thought Prompting Elicits Reasoning",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-12-20",
          "lastSeen": "2025-12-27",
          "mentionCount7d": 10,
          "mentionCount30d": 27,
          "velocity": 0.67
        }
      },
      {
        "data": {
          "id": "model:gemini_ultra_2_max",
          "label": "Gemini Ultra 2 Max",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-10-25",
          "lastSeen": "2025-11-20",
          "mentionCount7d": 17,
          "mentionCount30d": 40,
          "velocity": 0.63
        }
      },
      {
        "data": {
          "id": "model:whisper_v4_v2",
          "label": "Whisper v4 v2",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-24",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 37,
          "mentionCount30d": 70,
          "velocity": 0.42
        }
      },
      {
        "data": {
          "id": "tech:flash_attention",
          "label": "Flash Attention",
          "type": "Tech",
          "aliases": [
            "FlashAttention"
          ],
          "firstSeen": "2025-11-04",
          "lastSeen": "2026-01-10",
          "mentionCount7d": 10,
          "mentionCount30d": 49,
          "velocity": 0.6
        }
      },
      {
        "data": {
          "id": "tool:gradio_max",
          "label": "Gradio Max",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-14",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 14,
          "mentionCount30d": 50,
          "velocity": 0.66
        }
      },
      {
        "data": {
          "id": "model:dall_e_4_lite",
          "label": "DALL-E 4 Lite",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-05",
          "lastSeen": "2026-01-10",
          "mentionCount7d": 11,
          "mentionCount30d": 17,
          "velocity": 0.59
        }
      },
      {
        "data": {
          "id": "tech:lora_ultra",
          "label": "LoRA Ultra",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-25",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 2,
          "mentionCount30d": 5,
          "velocity": 0.61
        }
      },
      {
        "data": {
          "id": "model:jamba_2_lite",
          "label": "Jamba 2 Lite",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-20",
          "lastSeen": "2026-01-22",
          "mentionCount7d": 1,
          "mentionCount30d": 10,
          "velocity": 0.41
        }
      },
      {
        "data": {
          "id": "tech:multimodal_fusion_plus",
          "label": "Multimodal Fusion Plus",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-12",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 27,
          "mentionCount30d": 34,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "tool:crewai_core",
          "label": "CrewAI Core",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-20",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 8,
          "mentionCount30d": 18,
          "velocity": 0.25
        }
      },
      {
        "data": {
          "id": "repo:vllm_v2",
          "label": "vllm v2",
          "type": "Repo",
          "aliases": [],
          "firstSeen": "2026-01-22",
          "lastSeen": "2026-01-23",
          "mentionCount7d": 5,
          "mentionCount30d": 28,
          "velocity": 0.76
        }
      },
      {
        "data": {
          "id": "tool:streamlit",
          "label": "Streamlit",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-24",
          "lastSeen": "2026-01-16",
          "mentionCount7d": 9,
          "mentionCount30d": 18,
          "velocity": 0.69
        }
      },
      {
        "data": {
          "id": "dataset:roots_core",
          "label": "ROOTS Core",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-11-16",
          "lastSeen": "2025-11-25",
          "mentionCount7d": 14,
          "mentionCount30d": 29,
          "velocity": 0.55
        }
      },
      {
        "data": {
          "id": "model:phi_4_lite",
          "label": "Phi-4 Lite",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-04",
          "lastSeen": "2025-11-12",
          "mentionCount7d": 14,
          "mentionCount30d": 20,
          "velocity": 0.56
        }
      },
      {
        "data": {
          "id": "benchmark:mt_bench",
          "label": "MT-Bench",
          "type": "Benchmark",
          "aliases": [
            "MTBench"
          ],
          "firstSeen": "2026-01-13",
          "lastSeen": "2026-01-20",
          "mentionCount7d": 4,
          "mentionCount30d": 13,
          "velocity": 0.94
        }
      },
      {
        "data": {
          "id": "model:deepseek_v3_plus",
          "label": "DeepSeek-V3 Plus",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-28",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 18,
          "mentionCount30d": 51,
          "velocity": 0.35
        }
      },
      {
        "data": {
          "id": "model:qwen_3_ultra",
          "label": "Qwen-3 Ultra",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-19",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 34,
          "mentionCount30d": 101,
          "velocity": 0.93
        }
      },
      {
        "data": {
          "id": "model:palm_3",
          "label": "PaLM 3",
          "type": "Model",
          "aliases": [
            "PaLM3"
          ],
          "firstSeen": "2025-12-26",
          "lastSeen": "2026-01-08",
          "mentionCount7d": 26,
          "mentionCount30d": 108,
          "velocity": 0.39
        }
      },
      {
        "data": {
          "id": "model:sora_2_max",
          "label": "Sora 2 Max",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-13",
          "lastSeen": "2026-01-17",
          "mentionCount7d": 46,
          "mentionCount30d": 70,
          "velocity": 0.48
        }
      },
      {
        "data": {
          "id": "model:llama_4",
          "label": "Llama 4",
          "type": "Model",
          "aliases": [
            "LLaMA 4",
            "Llama-4"
          ],
          "firstSeen": "2026-01-06",
          "lastSeen": "2026-01-16",
          "mentionCount7d": 17,
          "mentionCount30d": 66,
          "velocity": 0.12
        }
      },
      {
        "data": {
          "id": "model:command_r_plus_lite",
          "label": "Command R+ Lite",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-17",
          "lastSeen": "2026-01-19",
          "mentionCount7d": 21,
          "mentionCount30d": 53,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "model:yi_large",
          "label": "Yi-Large",
          "type": "Model",
          "aliases": [
            "Yi Large"
          ],
          "firstSeen": "2025-12-12",
          "lastSeen": "2026-01-01",
          "mentionCount7d": 10,
          "mentionCount30d": 19,
          "velocity": 0.44
        }
      },
      {
        "data": {
          "id": "dataset:c4",
          "label": "C4",
          "type": "Dataset",
          "aliases": [
            "Colossal Clean Crawled Corpus"
          ],
          "firstSeen": "2025-11-20",
          "lastSeen": "2025-11-29",
          "mentionCount7d": 20,
          "mentionCount30d": 26,
          "velocity": 0.88
        }
      },
      {
        "data": {
          "id": "model:aya_3_v2",
          "label": "Aya 3 v2",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-10-26",
          "lastSeen": "2025-12-27",
          "mentionCount7d": 50,
          "mentionCount30d": 120,
          "velocity": 0.27
        }
      },
      {
        "data": {
          "id": "tech:red_teaming",
          "label": "Red Teaming",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-10-26",
          "lastSeen": "2025-11-29",
          "mentionCount7d": 9,
          "mentionCount30d": 71,
          "velocity": 0.12
        }
      },
      {
        "data": {
          "id": "tech:rlhf_mini",
          "label": "RLHF Mini",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-25",
          "lastSeen": "2025-12-28",
          "mentionCount7d": 27,
          "mentionCount30d": 34,
          "velocity": 0.61
        }
      },
      {
        "data": {
          "id": "model:codex_2",
          "label": "Codex 2",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-10-27",
          "lastSeen": "2026-01-11",
          "mentionCount7d": 11,
          "mentionCount30d": 77,
          "velocity": 0.46
        }
      },
      {
        "data": {
          "id": "model:palm_3_ultra",
          "label": "PaLM 3 Ultra",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-29",
          "lastSeen": "2025-12-15",
          "mentionCount7d": 6,
          "mentionCount30d": 18,
          "velocity": 0.27
        }
      },
      {
        "data": {
          "id": "tool:tensorrt_llm_next",
          "label": "TensorRT-LLM Next",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-08",
          "lastSeen": "2026-01-15",
          "mentionCount7d": 5,
          "mentionCount30d": 17,
          "velocity": 0.19
        }
      },
      {
        "data": {
          "id": "tool:litellm_edge",
          "label": "LiteLLM Edge",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-05",
          "lastSeen": "2026-01-12",
          "mentionCount7d": 14,
          "mentionCount30d": 31,
          "velocity": 0.24
        }
      },
      {
        "data": {
          "id": "paper:lora:_low_rank_adaptation_of_large_langu",
          "label": "LoRA: Low-Rank Adaptation of Large Language Models",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-12-18",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 0,
          "mentionCount30d": 3,
          "velocity": 0.16
        }
      },
      {
        "data": {
          "id": "tool:tensorrt_llm",
          "label": "TensorRT-LLM",
          "type": "Tool",
          "aliases": [
            "TensorRT LLM"
          ],
          "firstSeen": "2025-12-15",
          "lastSeen": "2026-01-17",
          "mentionCount7d": 15,
          "mentionCount30d": 33,
          "velocity": 0.28
        }
      },
      {
        "data": {
          "id": "tool:haystack_mini",
          "label": "Haystack Mini",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-04",
          "lastSeen": "2026-01-11",
          "mentionCount7d": 1,
          "mentionCount30d": 7,
          "velocity": 0.9
        }
      },
      {
        "data": {
          "id": "dataset:mc4",
          "label": "mC4",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-11-19",
          "lastSeen": "2025-11-21",
          "mentionCount7d": 5,
          "mentionCount30d": 24,
          "velocity": 0.86
        }
      },
      {
        "data": {
          "id": "dataset:openwebtext2",
          "label": "OpenWebText2",
          "type": "Dataset",
          "aliases": [
            "OWT2"
          ],
          "firstSeen": "2025-12-12",
          "lastSeen": "2026-01-16",
          "mentionCount7d": 3,
          "mentionCount30d": 25,
          "velocity": 0.65
        }
      },
      {
        "data": {
          "id": "tool:cody_pro",
          "label": "Cody Pro",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-22",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 6,
          "mentionCount30d": 26,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "tech:dpo_plus",
          "label": "DPO Plus",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-17",
          "lastSeen": "2026-01-20",
          "mentionCount7d": 12,
          "mentionCount30d": 33,
          "velocity": 0.51
        }
      },
      {
        "data": {
          "id": "tech:flash_attention_core",
          "label": "Flash Attention Core",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-14",
          "lastSeen": "2025-12-28",
          "mentionCount7d": 2,
          "mentionCount30d": 3,
          "velocity": 0.93
        }
      },
      {
        "data": {
          "id": "model:gemma_3_lite",
          "label": "Gemma 3 Lite",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-08",
          "lastSeen": "2026-01-15",
          "mentionCount7d": 3,
          "mentionCount30d": 13,
          "velocity": 0.94
        }
      },
      {
        "data": {
          "id": "paper:attention_is_all_you_need_v2",
          "label": "Attention Is All You Need v2",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-11-13",
          "lastSeen": "2025-12-21",
          "mentionCount7d": 7,
          "mentionCount30d": 32,
          "velocity": 0.15
        }
      },
      {
        "data": {
          "id": "repo:open_interpreter",
          "label": "open-interpreter",
          "type": "Repo",
          "aliases": [],
          "firstSeen": "2025-12-18",
          "lastSeen": "2026-01-22",
          "mentionCount7d": 16,
          "mentionCount30d": 44,
          "velocity": 0.35
        }
      },
      {
        "data": {
          "id": "tool:crewai",
          "label": "CrewAI",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-12",
          "lastSeen": "2025-12-27",
          "mentionCount7d": 0,
          "mentionCount30d": 1,
          "velocity": 0.23
        }
      },
      {
        "data": {
          "id": "benchmark:hellaswag",
          "label": "HellaSwag",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2025-12-04",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 3,
          "mentionCount30d": 26,
          "velocity": 0.84
        }
      },
      {
        "data": {
          "id": "repo:autogpt",
          "label": "AutoGPT",
          "type": "Repo",
          "aliases": [
            "Significant-Gravitas/AutoGPT"
          ],
          "firstSeen": "2025-10-29",
          "lastSeen": "2025-12-13",
          "mentionCount7d": 3,
          "mentionCount30d": 25,
          "velocity": 0.55
        }
      },
      {
        "data": {
          "id": "tool:semantic_kernel_edge",
          "label": "Semantic Kernel Edge",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-04",
          "lastSeen": "2025-12-19",
          "mentionCount7d": 11,
          "mentionCount30d": 31,
          "velocity": 0.68
        }
      },
      {
        "data": {
          "id": "tool:haystack",
          "label": "Haystack",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-24",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 11,
          "mentionCount30d": 45,
          "velocity": 0.3
        }
      },
      {
        "data": {
          "id": "tool:llamaindex_ultra",
          "label": "LlamaIndex Ultra",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-20",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 12,
          "mentionCount30d": 42,
          "velocity": 0.86
        }
      },
      {
        "data": {
          "id": "tool:vllm_core",
          "label": "vLLM Core",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-23",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 7,
          "mentionCount30d": 32,
          "velocity": 0.95
        }
      },
      {
        "data": {
          "id": "model:claude_sonnet_4_lite",
          "label": "Claude Sonnet 4 Lite",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-09",
          "lastSeen": "2025-12-03",
          "mentionCount7d": 26,
          "mentionCount30d": 57,
          "velocity": 0.89
        }
      },
      {
        "data": {
          "id": "repo:transformers_next",
          "label": "transformers Next",
          "type": "Repo",
          "aliases": [],
          "firstSeen": "2025-12-02",
          "lastSeen": "2026-01-02",
          "mentionCount7d": 7,
          "mentionCount30d": 16,
          "velocity": 0.48
        }
      },
      {
        "data": {
          "id": "tech:sliding_window_attention",
          "label": "Sliding Window Attention",
          "type": "Tech",
          "aliases": [
            "SWA"
          ],
          "firstSeen": "2025-12-13",
          "lastSeen": "2025-12-24",
          "mentionCount7d": 18,
          "mentionCount30d": 41,
          "velocity": 0.1
        }
      },
      {
        "data": {
          "id": "tech:red_teaming_mini",
          "label": "Red Teaming Mini",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-14",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 28,
          "mentionCount30d": 32,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "tech:sparse_attention_lite",
          "label": "Sparse Attention Lite",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-17",
          "lastSeen": "2025-11-29",
          "mentionCount7d": 21,
          "mentionCount30d": 47,
          "velocity": 0.64
        }
      },
      {
        "data": {
          "id": "model:stable_diffusion_4_mini",
          "label": "Stable Diffusion 4 Mini",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-13",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 8,
          "mentionCount30d": 18,
          "velocity": 0.62
        }
      },
      {
        "data": {
          "id": "tech:chain_of_thought_max",
          "label": "Chain-of-Thought Max",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-10",
          "lastSeen": "2025-12-25",
          "mentionCount7d": 10,
          "mentionCount30d": 49,
          "velocity": 0.3
        }
      },
      {
        "data": {
          "id": "tool:mlflow_lite",
          "label": "MLflow Lite",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-10-29",
          "lastSeen": "2025-12-22",
          "mentionCount7d": 14,
          "mentionCount30d": 44,
          "velocity": 0.1
        }
      },
      {
        "data": {
          "id": "model:claude_sonnet_4",
          "label": "Claude Sonnet 4",
          "type": "Model",
          "aliases": [
            "Sonnet 4"
          ],
          "firstSeen": "2026-01-15",
          "lastSeen": "2026-01-16",
          "mentionCount7d": 10,
          "mentionCount30d": 22,
          "velocity": 0.82
        }
      },
      {
        "data": {
          "id": "repo:langchain_lite",
          "label": "langchain Lite",
          "type": "Repo",
          "aliases": [],
          "firstSeen": "2026-01-13",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 21,
          "mentionCount30d": 37,
          "velocity": 0.57
        }
      },
      {
        "data": {
          "id": "dataset:laion_5b",
          "label": "LAION-5B",
          "type": "Dataset",
          "aliases": [
            "LAION"
          ],
          "firstSeen": "2026-01-02",
          "lastSeen": "2026-01-06",
          "mentionCount7d": 0,
          "mentionCount30d": 2,
          "velocity": 0.74
        }
      },
      {
        "data": {
          "id": "model:command_r_plus_ultra",
          "label": "Command R+ Ultra",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-14",
          "lastSeen": "2025-11-14",
          "mentionCount7d": 11,
          "mentionCount30d": 52,
          "velocity": 0.71
        }
      },
      {
        "data": {
          "id": "benchmark:mt_bench_v2",
          "label": "MT-Bench v2",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2025-12-19",
          "lastSeen": "2026-01-04",
          "mentionCount7d": 6,
          "mentionCount30d": 21,
          "velocity": 0.5
        }
      },
      {
        "data": {
          "id": "model:gemini_ultra_2",
          "label": "Gemini Ultra 2",
          "type": "Model",
          "aliases": [
            "Gemini 2",
            "Gemini Ultra"
          ],
          "firstSeen": "2025-12-10",
          "lastSeen": "2026-01-16",
          "mentionCount7d": 9,
          "mentionCount30d": 71,
          "velocity": 0.82
        }
      },
      {
        "data": {
          "id": "model:codex_2_lite",
          "label": "Codex 2 Lite",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-09",
          "lastSeen": "2026-01-08",
          "mentionCount7d": 14,
          "mentionCount30d": 44,
          "velocity": 0.21
        }
      },
      {
        "data": {
          "id": "tech:tree_of_thought",
          "label": "Tree of Thought",
          "type": "Tech",
          "aliases": [
            "ToT"
          ],
          "firstSeen": "2025-11-28",
          "lastSeen": "2025-12-05",
          "mentionCount7d": 6,
          "mentionCount30d": 19,
          "velocity": 0.82
        }
      },
      {
        "data": {
          "id": "model:claude_opus_45_max",
          "label": "Claude Opus 4.5 Max",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-14",
          "lastSeen": "2025-12-31",
          "mentionCount7d": 30,
          "mentionCount30d": 105,
          "velocity": 0.71
        }
      },
      {
        "data": {
          "id": "model:nemotron_5",
          "label": "Nemotron-5",
          "type": "Model",
          "aliases": [
            "Nemotron 5"
          ],
          "firstSeen": "2025-12-27",
          "lastSeen": "2026-01-01",
          "mentionCount7d": 33,
          "mentionCount30d": 139,
          "velocity": 0.07
        }
      },
      {
        "data": {
          "id": "tech:kv_cache_optimization",
          "label": "KV Cache Optimization",
          "type": "Tech",
          "aliases": [
            "KV Cache"
          ],
          "firstSeen": "2025-11-02",
          "lastSeen": "2025-12-31",
          "mentionCount7d": 20,
          "mentionCount30d": 41,
          "velocity": 0.91
        }
      },
      {
        "data": {
          "id": "tech:rlhf_edge",
          "label": "RLHF Edge",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-09",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 11,
          "mentionCount30d": 79,
          "velocity": 0.96
        }
      },
      {
        "data": {
          "id": "tool:llamaindex",
          "label": "LlamaIndex",
          "type": "Tool",
          "aliases": [
            "Llama Index"
          ],
          "firstSeen": "2026-01-15",
          "lastSeen": "2026-01-16",
          "mentionCount7d": 2,
          "mentionCount30d": 16,
          "velocity": 0.67
        }
      },
      {
        "data": {
          "id": "tool:flowise",
          "label": "Flowise",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-12",
          "lastSeen": "2026-01-10",
          "mentionCount7d": 16,
          "mentionCount30d": 29,
          "velocity": 0.72
        }
      },
      {
        "data": {
          "id": "tech:sliding_window_attention_pro",
          "label": "Sliding Window Attention Pro",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-02",
          "lastSeen": "2026-01-04",
          "mentionCount7d": 1,
          "mentionCount30d": 5,
          "velocity": 0.96
        }
      },
      {
        "data": {
          "id": "benchmark:mmlu",
          "label": "MMLU",
          "type": "Benchmark",
          "aliases": [
            "Massive Multitask Language Understanding"
          ],
          "firstSeen": "2025-12-06",
          "lastSeen": "2025-12-09",
          "mentionCount7d": 10,
          "mentionCount30d": 24,
          "velocity": 0.6
        }
      },
      {
        "data": {
          "id": "tool:copilot",
          "label": "Copilot",
          "type": "Tool",
          "aliases": [
            "GitHub Copilot"
          ],
          "firstSeen": "2025-10-31",
          "lastSeen": "2025-11-22",
          "mentionCount7d": 12,
          "mentionCount30d": 23,
          "velocity": 0.42
        }
      },
      {
        "data": {
          "id": "model:midjourney_v7_plus",
          "label": "Midjourney V7 Plus",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-04",
          "lastSeen": "2025-12-20",
          "mentionCount7d": 30,
          "mentionCount30d": 78,
          "velocity": 0.09
        }
      },
      {
        "data": {
          "id": "tool:streamlit_pro",
          "label": "Streamlit Pro",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-03",
          "lastSeen": "2025-12-18",
          "mentionCount7d": 6,
          "mentionCount30d": 10,
          "velocity": 0.88
        }
      },
      {
        "data": {
          "id": "tech:distillation_next",
          "label": "Distillation Next",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-14",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 10,
          "mentionCount30d": 57,
          "velocity": 0.9
        }
      },
      {
        "data": {
          "id": "tech:distillation",
          "label": "Distillation",
          "type": "Tech",
          "aliases": [
            "Knowledge Distillation"
          ],
          "firstSeen": "2025-12-04",
          "lastSeen": "2026-01-02",
          "mentionCount7d": 1,
          "mentionCount30d": 9,
          "velocity": 0.95
        }
      },
      {
        "data": {
          "id": "tech:rotary_position_embedding_pro",
          "label": "Rotary Position Embedding Pro",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-28",
          "lastSeen": "2026-01-23",
          "mentionCount7d": 6,
          "mentionCount30d": 25,
          "velocity": 0.68
        }
      },
      {
        "data": {
          "id": "dataset:starcoder_data_pro",
          "label": "StarCoder Data Pro",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-18",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 3,
          "mentionCount30d": 31,
          "velocity": 0.58
        }
      },
      {
        "data": {
          "id": "tool:autogpt_max",
          "label": "AutoGPT Max",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-16",
          "lastSeen": "2025-12-20",
          "mentionCount7d": 17,
          "mentionCount30d": 42,
          "velocity": 0.2
        }
      },
      {
        "data": {
          "id": "model:palm_3_v2",
          "label": "PaLM 3 v2",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-18",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 43,
          "mentionCount30d": 113,
          "velocity": 0.4
        }
      },
      {
        "data": {
          "id": "tool:cody",
          "label": "Cody",
          "type": "Tool",
          "aliases": [
            "Sourcegraph Cody"
          ],
          "firstSeen": "2025-11-03",
          "lastSeen": "2025-12-03",
          "mentionCount7d": 7,
          "mentionCount30d": 18,
          "velocity": 0.36
        }
      },
      {
        "data": {
          "id": "model:gpt_5",
          "label": "GPT-5",
          "type": "Model",
          "aliases": [
            "GPT 5",
            "gpt-5"
          ],
          "firstSeen": "2025-11-20",
          "lastSeen": "2025-12-21",
          "mentionCount7d": 19,
          "mentionCount30d": 56,
          "velocity": 0.95
        }
      },
      {
        "data": {
          "id": "model:command_r_plus_plus",
          "label": "Command R+ Plus",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-12",
          "lastSeen": "2026-01-04",
          "mentionCount7d": 1,
          "mentionCount30d": 9,
          "velocity": 0.15
        }
      },
      {
        "data": {
          "id": "tech:constitutional_ai_mini",
          "label": "Constitutional AI Mini",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-16",
          "lastSeen": "2026-01-16",
          "mentionCount7d": 8,
          "mentionCount30d": 9,
          "velocity": 0.56
        }
      },
      {
        "data": {
          "id": "tech:qlora_pro",
          "label": "QLoRA Pro",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-16",
          "lastSeen": "2026-01-19",
          "mentionCount7d": 8,
          "mentionCount30d": 29,
          "velocity": 0.79
        }
      },
      {
        "data": {
          "id": "paper:scaling_laws_for_neural_language_models_",
          "label": "Scaling Laws for Neural Language Models (2025)",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-11-28",
          "lastSeen": "2026-01-13",
          "mentionCount7d": 5,
          "mentionCount30d": 18,
          "velocity": 0.97
        }
      },
      {
        "data": {
          "id": "model:sora_2",
          "label": "Sora 2",
          "type": "Model",
          "aliases": [
            "Sora V2"
          ],
          "firstSeen": "2026-01-17",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 8,
          "mentionCount30d": 29,
          "velocity": 0.17
        }
      },
      {
        "data": {
          "id": "dataset:openwebtext2_mini",
          "label": "OpenWebText2 Mini",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2026-01-25",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 4,
          "mentionCount30d": 8,
          "velocity": 0.95
        }
      },
      {
        "data": {
          "id": "tool:dify",
          "label": "Dify",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-11",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 5,
          "mentionCount30d": 22,
          "velocity": 0.39
        }
      },
      {
        "data": {
          "id": "tech:kv_cache_optimization_max",
          "label": "KV Cache Optimization Max",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-11",
          "lastSeen": "2026-01-05",
          "mentionCount7d": 1,
          "mentionCount30d": 7,
          "velocity": 0.98
        }
      },
      {
        "data": {
          "id": "tech:transformer_architecture_edge",
          "label": "Transformer Architecture Edge",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-01",
          "lastSeen": "2025-12-08",
          "mentionCount7d": 14,
          "mentionCount30d": 22,
          "velocity": 0.32
        }
      },
      {
        "data": {
          "id": "tool:vllm_edge",
          "label": "vLLM Edge",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-15",
          "lastSeen": "2026-01-17",
          "mentionCount7d": 7,
          "mentionCount30d": 19,
          "velocity": 0.29
        }
      },
      {
        "data": {
          "id": "tool:cursor",
          "label": "Cursor",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-18",
          "lastSeen": "2025-11-24",
          "mentionCount7d": 2,
          "mentionCount30d": 7,
          "velocity": 0.19
        }
      },
      {
        "data": {
          "id": "dataset:the_pile",
          "label": "The Pile",
          "type": "Dataset",
          "aliases": [
            "Pile"
          ],
          "firstSeen": "2025-12-15",
          "lastSeen": "2025-12-16",
          "mentionCount7d": 5,
          "mentionCount30d": 38,
          "velocity": 0.13
        }
      },
      {
        "data": {
          "id": "repo:llamacpp",
          "label": "llama.cpp",
          "type": "Repo",
          "aliases": [],
          "firstSeen": "2025-11-29",
          "lastSeen": "2025-12-11",
          "mentionCount7d": 13,
          "mentionCount30d": 39,
          "velocity": 0.07
        }
      },
      {
        "data": {
          "id": "paper:direct_preference_optimization",
          "label": "Direct Preference Optimization",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-12-28",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 6,
          "mentionCount30d": 23,
          "velocity": 0.21
        }
      },
      {
        "data": {
          "id": "model:phi_4_ultra",
          "label": "Phi-4 Ultra",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-16",
          "lastSeen": "2025-11-26",
          "mentionCount7d": 40,
          "mentionCount30d": 129,
          "velocity": 0.78
        }
      },
      {
        "data": {
          "id": "dataset:redpajama_v2",
          "label": "RedPajama v2",
          "type": "Dataset",
          "aliases": [
            "RedPajama"
          ],
          "firstSeen": "2025-10-28",
          "lastSeen": "2026-01-17",
          "mentionCount7d": 16,
          "mentionCount30d": 32,
          "velocity": 0.23
        }
      },
      {
        "data": {
          "id": "dataset:laion_5b_edge",
          "label": "LAION-5B Edge",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-14",
          "lastSeen": "2026-01-10",
          "mentionCount7d": 14,
          "mentionCount30d": 51,
          "velocity": 0.61
        }
      },
      {
        "data": {
          "id": "dataset:wikipedia_dump_2025",
          "label": "Wikipedia Dump 2025",
          "type": "Dataset",
          "aliases": [
            "Wikipedia"
          ],
          "firstSeen": "2026-01-08",
          "lastSeen": "2026-01-13",
          "mentionCount7d": 3,
          "mentionCount30d": 34,
          "velocity": 0.67
        }
      },
      {
        "data": {
          "id": "tech:rlhf",
          "label": "RLHF",
          "type": "Tech",
          "aliases": [
            "Reinforcement Learning from Human Feedback"
          ],
          "firstSeen": "2025-11-02",
          "lastSeen": "2025-11-16",
          "mentionCount7d": 3,
          "mentionCount30d": 23,
          "velocity": 0.06
        }
      },
      {
        "data": {
          "id": "model:deepseek_v3",
          "label": "DeepSeek-V3",
          "type": "Model",
          "aliases": [
            "DeepSeek V3"
          ],
          "firstSeen": "2026-01-22",
          "lastSeen": "2026-01-23",
          "mentionCount7d": 5,
          "mentionCount30d": 12,
          "velocity": 0.73
        }
      },
      {
        "data": {
          "id": "benchmark:lmsys_chatbot_arena_lite",
          "label": "LMSYS Chatbot Arena Lite",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2026-01-05",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 7,
          "mentionCount30d": 28,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "model:phi_4_mini",
          "label": "Phi-4 Mini",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-19",
          "lastSeen": "2025-12-06",
          "mentionCount7d": 41,
          "mentionCount30d": 118,
          "velocity": 0.11
        }
      },
      {
        "data": {
          "id": "tech:chain_of_thought_pro",
          "label": "Chain-of-Thought Pro",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-09",
          "lastSeen": "2026-01-05",
          "mentionCount7d": 6,
          "mentionCount30d": 11,
          "velocity": 0.14
        }
      },
      {
        "data": {
          "id": "dataset:dolma",
          "label": "Dolma",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-11-02",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 10,
          "mentionCount30d": 26,
          "velocity": 0.76
        }
      },
      {
        "data": {
          "id": "tool:haystack_core",
          "label": "Haystack Core",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-30",
          "lastSeen": "2025-12-06",
          "mentionCount7d": 3,
          "mentionCount30d": 20,
          "velocity": 0.19
        }
      },
      {
        "data": {
          "id": "dataset:the_stack_v2",
          "label": "The Stack v2",
          "type": "Dataset",
          "aliases": [
            "The Stack"
          ],
          "firstSeen": "2025-11-12",
          "lastSeen": "2025-12-09",
          "mentionCount7d": 2,
          "mentionCount30d": 4,
          "velocity": 0.37
        }
      },
      {
        "data": {
          "id": "tool:semantic_kernel",
          "label": "Semantic Kernel",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-10-25",
          "lastSeen": "2025-11-08",
          "mentionCount7d": 1,
          "mentionCount30d": 13,
          "velocity": 0.18
        }
      },
      {
        "data": {
          "id": "repo:vllm",
          "label": "vllm",
          "type": "Repo",
          "aliases": [
            "vllm-project/vllm"
          ],
          "firstSeen": "2025-11-04",
          "lastSeen": "2026-01-20",
          "mentionCount7d": 8,
          "mentionCount30d": 32,
          "velocity": 0.25
        }
      },
      {
        "data": {
          "id": "tech:tree_of_thought_lite",
          "label": "Tree of Thought Lite",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-26",
          "lastSeen": "2025-12-27",
          "mentionCount7d": 4,
          "mentionCount30d": 44,
          "velocity": 0.28
        }
      },
      {
        "data": {
          "id": "model:mixtral_8x22b",
          "label": "Mixtral 8x22B",
          "type": "Model",
          "aliases": [
            "Mixtral-8x22B"
          ],
          "firstSeen": "2025-12-31",
          "lastSeen": "2026-01-06",
          "mentionCount7d": 30,
          "mentionCount30d": 115,
          "velocity": 0.48
        }
      },
      {
        "data": {
          "id": "dataset:slimpajama",
          "label": "SlimPajama",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2026-01-02",
          "lastSeen": "2026-01-11",
          "mentionCount7d": 6,
          "mentionCount30d": 28,
          "velocity": 0.56
        }
      },
      {
        "data": {
          "id": "model:gemma_3",
          "label": "Gemma 3",
          "type": "Model",
          "aliases": [
            "Gemma3"
          ],
          "firstSeen": "2025-12-09",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 13,
          "mentionCount30d": 33,
          "velocity": 0.95
        }
      },
      {
        "data": {
          "id": "tool:ollama_edge",
          "label": "Ollama Edge",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-01",
          "lastSeen": "2026-01-17",
          "mentionCount7d": 12,
          "mentionCount30d": 58,
          "velocity": 0.77
        }
      },
      {
        "data": {
          "id": "tech:rotary_position_embedding_v2",
          "label": "Rotary Position Embedding v2",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-15",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 2,
          "mentionCount30d": 3,
          "velocity": 0.26
        }
      },
      {
        "data": {
          "id": "tool:flowise_max",
          "label": "Flowise Max",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-24",
          "lastSeen": "2025-12-26",
          "mentionCount7d": 8,
          "mentionCount30d": 20,
          "velocity": 0.67
        }
      },
      {
        "data": {
          "id": "tech:rotary_position_embedding",
          "label": "Rotary Position Embedding",
          "type": "Tech",
          "aliases": [
            "RoPE"
          ],
          "firstSeen": "2025-12-28",
          "lastSeen": "2026-01-03",
          "mentionCount7d": 1,
          "mentionCount30d": 9,
          "velocity": 0.87
        }
      },
      {
        "data": {
          "id": "tech:group_query_attention_v2",
          "label": "Group Query Attention v2",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-05",
          "lastSeen": "2025-12-18",
          "mentionCount7d": 4,
          "mentionCount30d": 16,
          "velocity": 0.91
        }
      },
      {
        "data": {
          "id": "model:grok_3",
          "label": "Grok-3",
          "type": "Model",
          "aliases": [
            "Grok 3"
          ],
          "firstSeen": "2025-12-02",
          "lastSeen": "2025-12-16",
          "mentionCount7d": 19,
          "mentionCount30d": 37,
          "velocity": 0.44
        }
      },
      {
        "data": {
          "id": "model:llama_4_max",
          "label": "Llama 4 Max",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-01",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 31,
          "mentionCount30d": 76,
          "velocity": 0.47
        }
      },
      {
        "data": {
          "id": "paper:toolformer:_language_models_can_teach_th",
          "label": "Toolformer: Language Models Can Teach Themselves to Use Tools",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-12-18",
          "lastSeen": "2025-12-18",
          "mentionCount7d": 14,
          "mentionCount30d": 26,
          "velocity": 0.27
        }
      },
      {
        "data": {
          "id": "tech:transformer_architecture_pro",
          "label": "Transformer Architecture Pro",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-10-27",
          "lastSeen": "2026-01-19",
          "mentionCount7d": 4,
          "mentionCount30d": 10,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "repo:localai",
          "label": "LocalAI",
          "type": "Repo",
          "aliases": [],
          "firstSeen": "2026-01-06",
          "lastSeen": "2026-01-13",
          "mentionCount7d": 6,
          "mentionCount30d": 52,
          "velocity": 0.86
        }
      },
      {
        "data": {
          "id": "dataset:the_pile_core",
          "label": "The Pile Core",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-06",
          "lastSeen": "2025-12-20",
          "mentionCount7d": 7,
          "mentionCount30d": 23,
          "velocity": 0.24
        }
      },
      {
        "data": {
          "id": "model:qwen_3_next",
          "label": "Qwen-3 Next",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-28",
          "lastSeen": "2026-01-23",
          "mentionCount7d": 10,
          "mentionCount30d": 49,
          "velocity": 0.99
        }
      },
      {
        "data": {
          "id": "benchmark:gpqa",
          "label": "GPQA",
          "type": "Benchmark",
          "aliases": [
            "Graduate-Level Google-Proof QA"
          ],
          "firstSeen": "2025-12-24",
          "lastSeen": "2026-01-02",
          "mentionCount7d": 3,
          "mentionCount30d": 13,
          "velocity": 0.96
        }
      },
      {
        "data": {
          "id": "tech:quantization_plus",
          "label": "Quantization Plus",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-17",
          "lastSeen": "2025-11-25",
          "mentionCount7d": 11,
          "mentionCount30d": 45,
          "velocity": 0.17
        }
      },
      {
        "data": {
          "id": "model:yi_large_lite",
          "label": "Yi-Large Lite",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-09",
          "lastSeen": "2025-11-25",
          "mentionCount7d": 17,
          "mentionCount30d": 48,
          "velocity": 0.39
        }
      },
      {
        "data": {
          "id": "dataset:slimpajama_edge",
          "label": "SlimPajama Edge",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-02",
          "lastSeen": "2025-12-19",
          "mentionCount7d": 8,
          "mentionCount30d": 36,
          "velocity": 0.25
        }
      },
      {
        "data": {
          "id": "model:jamba_2",
          "label": "Jamba 2",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-07",
          "lastSeen": "2026-01-23",
          "mentionCount7d": 46,
          "mentionCount30d": 79,
          "velocity": 0.35
        }
      },
      {
        "data": {
          "id": "model:gemini_ultra_2_edge",
          "label": "Gemini Ultra 2 Edge",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-07",
          "lastSeen": "2026-01-19",
          "mentionCount7d": 6,
          "mentionCount30d": 28,
          "velocity": 0.58
        }
      },
      {
        "data": {
          "id": "model:deepseek_v3_edge",
          "label": "DeepSeek-V3 Edge",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-10-28",
          "lastSeen": "2026-01-20",
          "mentionCount7d": 2,
          "mentionCount30d": 13,
          "velocity": 0.51
        }
      },
      {
        "data": {
          "id": "tech:dpo_lite",
          "label": "DPO Lite",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-14",
          "lastSeen": "2025-12-15",
          "mentionCount7d": 7,
          "mentionCount30d": 15,
          "velocity": 0.72
        }
      },
      {
        "data": {
          "id": "benchmark:math",
          "label": "MATH",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2026-01-20",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 1,
          "mentionCount30d": 3,
          "velocity": 0.69
        }
      },
      {
        "data": {
          "id": "paper:direct_preference_optimization_ultra",
          "label": "Direct Preference Optimization Ultra",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2026-01-03",
          "lastSeen": "2026-01-17",
          "mentionCount7d": 2,
          "mentionCount30d": 5,
          "velocity": 0.88
        }
      },
      {
        "data": {
          "id": "model:claude_sonnet_4_edge",
          "label": "Claude Sonnet 4 Edge",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-01",
          "lastSeen": "2025-12-24",
          "mentionCount7d": 43,
          "mentionCount30d": 108,
          "velocity": 0.4
        }
      },
      {
        "data": {
          "id": "tool:mlflow",
          "label": "MLflow",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-09",
          "lastSeen": "2026-01-03",
          "mentionCount7d": 6,
          "mentionCount30d": 18,
          "velocity": 0.89
        }
      },
      {
        "data": {
          "id": "tech:mixture_of_experts_max",
          "label": "Mixture of Experts Max",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-01",
          "lastSeen": "2025-12-14",
          "mentionCount7d": 19,
          "mentionCount30d": 34,
          "velocity": 0.68
        }
      },
      {
        "data": {
          "id": "tech:group_query_attention_core",
          "label": "Group Query Attention Core",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-01",
          "lastSeen": "2026-01-15",
          "mentionCount7d": 13,
          "mentionCount30d": 53,
          "velocity": 0.19
        }
      },
      {
        "data": {
          "id": "tech:quantization",
          "label": "Quantization",
          "type": "Tech",
          "aliases": [
            "GPTQ",
            "AWQ"
          ],
          "firstSeen": "2025-12-31",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 10,
          "mentionCount30d": 55,
          "velocity": 0.54
        }
      },
      {
        "data": {
          "id": "tool:copilot_ultra",
          "label": "Copilot Ultra",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-23",
          "lastSeen": "2026-01-22",
          "mentionCount7d": 3,
          "mentionCount30d": 20,
          "velocity": 0.85
        }
      },
      {
        "data": {
          "id": "repo:langchain",
          "label": "langchain",
          "type": "Repo",
          "aliases": [
            "langchain-ai/langchain"
          ],
          "firstSeen": "2025-12-01",
          "lastSeen": "2025-12-25",
          "mentionCount7d": 8,
          "mentionCount30d": 26,
          "velocity": 0.39
        }
      },
      {
        "data": {
          "id": "tech:gguf_ultra",
          "label": "GGUF Ultra",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-19",
          "lastSeen": "2026-01-08",
          "mentionCount7d": 5,
          "mentionCount30d": 11,
          "velocity": 0.78
        }
      },
      {
        "data": {
          "id": "model:codex_2_pro",
          "label": "Codex 2 Pro",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-28",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 11,
          "mentionCount30d": 45,
          "velocity": 0.66
        }
      },
      {
        "data": {
          "id": "benchmark:humaneval_edge",
          "label": "HumanEval Edge",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2025-11-11",
          "lastSeen": "2025-12-29",
          "mentionCount7d": 2,
          "mentionCount30d": 2,
          "velocity": 0.34
        }
      },
      {
        "data": {
          "id": "tech:qlora_ultra",
          "label": "QLoRA Ultra",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-07",
          "lastSeen": "2026-01-20",
          "mentionCount7d": 2,
          "mentionCount30d": 9,
          "velocity": 0.97
        }
      },
      {
        "data": {
          "id": "model:claude_opus_45_edge",
          "label": "Claude Opus 4.5 Edge",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-12",
          "lastSeen": "2025-12-18",
          "mentionCount7d": 13,
          "mentionCount30d": 66,
          "velocity": 0.49
        }
      },
      {
        "data": {
          "id": "tool:llamaindex_core",
          "label": "LlamaIndex Core",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-10-28",
          "lastSeen": "2026-01-15",
          "mentionCount7d": 8,
          "mentionCount30d": 23,
          "velocity": 0.25
        }
      },
      {
        "data": {
          "id": "model:falcon_3_v2",
          "label": "Falcon 3 v2",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-06",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 13,
          "mentionCount30d": 49,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "model:command_r_plus",
          "label": "Command R+",
          "type": "Model",
          "aliases": [
            "Command R Plus"
          ],
          "firstSeen": "2025-12-30",
          "lastSeen": "2026-01-20",
          "mentionCount7d": 29,
          "mentionCount30d": 66,
          "velocity": 0.35
        }
      },
      {
        "data": {
          "id": "tool:vllm",
          "label": "vLLM",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-25",
          "lastSeen": "2025-12-24",
          "mentionCount7d": 1,
          "mentionCount30d": 12,
          "velocity": 0.72
        }
      },
      {
        "data": {
          "id": "model:gemma_3_v2",
          "label": "Gemma 3 v2",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-14",
          "lastSeen": "2026-01-15",
          "mentionCount7d": 13,
          "mentionCount30d": 70,
          "velocity": 0.6
        }
      },
      {
        "data": {
          "id": "tool:langchain_plus",
          "label": "LangChain Plus",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-10-29",
          "lastSeen": "2025-11-03",
          "mentionCount7d": 7,
          "mentionCount30d": 25,
          "velocity": 0.65
        }
      },
      {
        "data": {
          "id": "tool:dify_ultra",
          "label": "Dify Ultra",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-24",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 8,
          "mentionCount30d": 38,
          "velocity": 0.29
        }
      },
      {
        "data": {
          "id": "benchmark:math_v2",
          "label": "MATH v2",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2025-10-29",
          "lastSeen": "2026-01-13",
          "mentionCount7d": 6,
          "mentionCount30d": 39,
          "velocity": 0.55
        }
      },
      {
        "data": {
          "id": "tool:weights_and_biases",
          "label": "Weights & Biases",
          "type": "Tool",
          "aliases": [
            "W&B",
            "wandb"
          ],
          "firstSeen": "2025-11-18",
          "lastSeen": "2025-12-27",
          "mentionCount7d": 6,
          "mentionCount30d": 13,
          "velocity": 0.61
        }
      },
      {
        "data": {
          "id": "tech:retrieval_augmented_generation_plus",
          "label": "Retrieval-Augmented Generation Plus",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-19",
          "lastSeen": "2026-01-22",
          "mentionCount7d": 13,
          "mentionCount30d": 15,
          "velocity": 0.17
        }
      },
      {
        "data": {
          "id": "tech:mixture_of_experts_core",
          "label": "Mixture of Experts Core",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-10",
          "lastSeen": "2026-01-15",
          "mentionCount7d": 29,
          "mentionCount30d": 87,
          "velocity": 0.63
        }
      },
      {
        "data": {
          "id": "tech:lora_core",
          "label": "LoRA Core",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-21",
          "lastSeen": "2025-12-29",
          "mentionCount7d": 12,
          "mentionCount30d": 35,
          "velocity": 0.33
        }
      },
      {
        "data": {
          "id": "tool:gradio",
          "label": "Gradio",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-29",
          "lastSeen": "2025-12-05",
          "mentionCount7d": 12,
          "mentionCount30d": 47,
          "velocity": 0.67
        }
      },
      {
        "data": {
          "id": "model:nemotron_5_ultra",
          "label": "Nemotron-5 Ultra",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-19",
          "lastSeen": "2025-12-28",
          "mentionCount7d": 29,
          "mentionCount30d": 58,
          "velocity": 0.4
        }
      },
      {
        "data": {
          "id": "repo:llamacpp_lite",
          "label": "llama.cpp Lite",
          "type": "Repo",
          "aliases": [],
          "firstSeen": "2025-11-19",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 4,
          "mentionCount30d": 20,
          "velocity": 0.8
        }
      },
      {
        "data": {
          "id": "model:gpt_4o_mini_2_ultra",
          "label": "GPT-4o Mini 2 Ultra",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-19",
          "lastSeen": "2025-12-11",
          "mentionCount7d": 10,
          "mentionCount30d": 44,
          "velocity": 0.18
        }
      },
      {
        "data": {
          "id": "model:gpt_4o_mini_2",
          "label": "GPT-4o Mini 2",
          "type": "Model",
          "aliases": [
            "GPT4o Mini 2"
          ],
          "firstSeen": "2025-11-04",
          "lastSeen": "2025-11-07",
          "mentionCount7d": 9,
          "mentionCount30d": 58,
          "velocity": 0.89
        }
      },
      {
        "data": {
          "id": "model:dall_e_4_plus",
          "label": "DALL-E 4 Plus",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-01",
          "lastSeen": "2025-12-10",
          "mentionCount7d": 52,
          "mentionCount30d": 107,
          "velocity": 0.51
        }
      },
      {
        "data": {
          "id": "benchmark:bigbench_hard_plus",
          "label": "BigBench Hard Plus",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2025-10-30",
          "lastSeen": "2026-01-15",
          "mentionCount7d": 2,
          "mentionCount30d": 11,
          "velocity": 0.1
        }
      },
      {
        "data": {
          "id": "tech:dpo",
          "label": "DPO",
          "type": "Tech",
          "aliases": [
            "Direct Preference Optimization"
          ],
          "firstSeen": "2026-01-22",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 29,
          "mentionCount30d": 70,
          "velocity": 0.49
        }
      },
      {
        "data": {
          "id": "benchmark:bigbench_hard",
          "label": "BigBench Hard",
          "type": "Benchmark",
          "aliases": [
            "BBH"
          ],
          "firstSeen": "2025-12-13",
          "lastSeen": "2025-12-22",
          "mentionCount7d": 2,
          "mentionCount30d": 12,
          "velocity": 0.22
        }
      },
      {
        "data": {
          "id": "tech:sparse_attention",
          "label": "Sparse Attention",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-25",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 18,
          "mentionCount30d": 35,
          "velocity": 0.38
        }
      },
      {
        "data": {
          "id": "dataset:c4_ultra",
          "label": "C4 Ultra",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-08",
          "lastSeen": "2025-12-15",
          "mentionCount7d": 4,
          "mentionCount30d": 16,
          "velocity": 0.79
        }
      },
      {
        "data": {
          "id": "model:llama_4_next",
          "label": "Llama 4 Next",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-25",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 36,
          "mentionCount30d": 127,
          "velocity": 0.6
        }
      },
      {
        "data": {
          "id": "tech:constitutional_ai_ultra",
          "label": "Constitutional AI Ultra",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-13",
          "lastSeen": "2026-01-16",
          "mentionCount7d": 7,
          "mentionCount30d": 27,
          "velocity": 0.58
        }
      },
      {
        "data": {
          "id": "tech:synthetic_data_generation_ultra",
          "label": "Synthetic Data Generation Ultra",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-11",
          "lastSeen": "2026-01-19",
          "mentionCount7d": 14,
          "mentionCount30d": 43,
          "velocity": 0.84
        }
      },
      {
        "data": {
          "id": "benchmark:hellaswag_v2",
          "label": "HellaSwag v2",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2026-01-05",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 0,
          "mentionCount30d": 2,
          "velocity": 0.34
        }
      },
      {
        "data": {
          "id": "model:palm_3_max",
          "label": "PaLM 3 Max",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-18",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 26,
          "mentionCount30d": 75,
          "velocity": 0.53
        }
      },
      {
        "data": {
          "id": "tool:weights_and_biases_plus",
          "label": "Weights & Biases Plus",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-19",
          "lastSeen": "2026-01-19",
          "mentionCount7d": 1,
          "mentionCount30d": 3,
          "velocity": 0.82
        }
      },
      {
        "data": {
          "id": "benchmark:alpacaeval_2_lite",
          "label": "AlpacaEval 2 Lite",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2025-11-26",
          "lastSeen": "2025-12-02",
          "mentionCount7d": 12,
          "mentionCount30d": 35,
          "velocity": 0.94
        }
      },
      {
        "data": {
          "id": "model:dall_e_4",
          "label": "DALL-E 4",
          "type": "Model",
          "aliases": [
            "DALLE 4"
          ],
          "firstSeen": "2026-01-15",
          "lastSeen": "2026-01-20",
          "mentionCount7d": 19,
          "mentionCount30d": 61,
          "velocity": 0.7
        }
      },
      {
        "data": {
          "id": "benchmark:humaneval",
          "label": "HumanEval",
          "type": "Benchmark",
          "aliases": [
            "Human Eval"
          ],
          "firstSeen": "2025-10-28",
          "lastSeen": "2025-11-07",
          "mentionCount7d": 2,
          "mentionCount30d": 18,
          "velocity": 0.88
        }
      },
      {
        "data": {
          "id": "tool:langchain",
          "label": "LangChain",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-20",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 13,
          "mentionCount30d": 27,
          "velocity": 0.46
        }
      },
      {
        "data": {
          "id": "model:mixtral_8x22b_edge",
          "label": "Mixtral 8x22B Edge",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-15",
          "lastSeen": "2025-11-23",
          "mentionCount7d": 3,
          "mentionCount30d": 35,
          "velocity": 0.73
        }
      },
      {
        "data": {
          "id": "benchmark:swe_bench",
          "label": "SWE-bench",
          "type": "Benchmark",
          "aliases": [
            "SWE Bench"
          ],
          "firstSeen": "2025-12-24",
          "lastSeen": "2026-01-09",
          "mentionCount7d": 1,
          "mentionCount30d": 3,
          "velocity": 0.13
        }
      },
      {
        "data": {
          "id": "model:aya_3_edge",
          "label": "Aya 3 Edge",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-03",
          "lastSeen": "2026-01-06",
          "mentionCount7d": 14,
          "mentionCount30d": 55,
          "velocity": 0.61
        }
      },
      {
        "data": {
          "id": "tech:multimodal_fusion",
          "label": "Multimodal Fusion",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-07",
          "lastSeen": "2025-12-10",
          "mentionCount7d": 20,
          "mentionCount30d": 30,
          "velocity": 0.25
        }
      },
      {
        "data": {
          "id": "tool:litellm",
          "label": "LiteLLM",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-04",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 8,
          "mentionCount30d": 24,
          "velocity": 0.31
        }
      },
      {
        "data": {
          "id": "benchmark:arc_agi_lite",
          "label": "ARC-AGI Lite",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2026-01-13",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 6,
          "mentionCount30d": 14,
          "velocity": 0.55
        }
      },
      {
        "data": {
          "id": "model:midjourney_v7_edge",
          "label": "Midjourney V7 Edge",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-06",
          "lastSeen": "2026-01-12",
          "mentionCount7d": 17,
          "mentionCount30d": 48,
          "velocity": 0.55
        }
      },
      {
        "data": {
          "id": "model:grok_3_ultra",
          "label": "Grok-3 Ultra",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-18",
          "lastSeen": "2025-12-17",
          "mentionCount7d": 16,
          "mentionCount30d": 129,
          "velocity": 0.54
        }
      },
      {
        "data": {
          "id": "model:phi_4",
          "label": "Phi-4",
          "type": "Model",
          "aliases": [
            "Phi 4"
          ],
          "firstSeen": "2026-01-03",
          "lastSeen": "2026-01-17",
          "mentionCount7d": 35,
          "mentionCount30d": 49,
          "velocity": 0.93
        }
      },
      {
        "data": {
          "id": "benchmark:truthfulqa",
          "label": "TruthfulQA",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2025-12-02",
          "lastSeen": "2026-01-05",
          "mentionCount7d": 2,
          "mentionCount30d": 5,
          "velocity": 0.96
        }
      },
      {
        "data": {
          "id": "benchmark:swe_bench_next",
          "label": "SWE-bench Next",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2025-12-20",
          "lastSeen": "2026-01-23",
          "mentionCount7d": 7,
          "mentionCount30d": 47,
          "velocity": 0.67
        }
      },
      {
        "data": {
          "id": "tech:kv_cache_optimization_next",
          "label": "KV Cache Optimization Next",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-25",
          "lastSeen": "2025-12-30",
          "mentionCount7d": 27,
          "mentionCount30d": 74,
          "velocity": 0.11
        }
      },
      {
        "data": {
          "id": "model:falcon_3_pro",
          "label": "Falcon 3 Pro",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-15",
          "lastSeen": "2025-12-11",
          "mentionCount7d": 25,
          "mentionCount30d": 142,
          "velocity": 0.35
        }
      },
      {
        "data": {
          "id": "paper:attention_is_all_you_need_v2_v2",
          "label": "Attention Is All You Need v2 v2",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-12-16",
          "lastSeen": "2025-12-21",
          "mentionCount7d": 4,
          "mentionCount30d": 10,
          "velocity": 0.96
        }
      },
      {
        "data": {
          "id": "tech:multimodal_fusion_lite",
          "label": "Multimodal Fusion Lite",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-19",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 8,
          "mentionCount30d": 49,
          "velocity": 0.5
        }
      },
      {
        "data": {
          "id": "dataset:the_stack_v2_ultra",
          "label": "The Stack v2 Ultra",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-11-20",
          "lastSeen": "2025-12-03",
          "mentionCount7d": 5,
          "mentionCount30d": 44,
          "velocity": 0.44
        }
      },
      {
        "data": {
          "id": "model:stable_diffusion_4",
          "label": "Stable Diffusion 4",
          "type": "Model",
          "aliases": [
            "SD4",
            "SD 4"
          ],
          "firstSeen": "2025-12-13",
          "lastSeen": "2025-12-27",
          "mentionCount7d": 5,
          "mentionCount30d": 30,
          "velocity": 0.51
        }
      },
      {
        "data": {
          "id": "benchmark:gsm8k",
          "label": "GSM8K",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2026-01-03",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 10,
          "mentionCount30d": 14,
          "velocity": 0.93
        }
      },
      {
        "data": {
          "id": "repo:text_generation_webui",
          "label": "text-generation-webui",
          "type": "Repo",
          "aliases": [
            "oobabooga"
          ],
          "firstSeen": "2025-11-07",
          "lastSeen": "2026-01-06",
          "mentionCount7d": 8,
          "mentionCount30d": 26,
          "velocity": 0.74
        }
      },
      {
        "data": {
          "id": "tool:localai_next",
          "label": "LocalAI Next",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2026-01-17",
          "lastSeen": "2026-01-17",
          "mentionCount7d": 10,
          "mentionCount30d": 21,
          "velocity": 0.42
        }
      },
      {
        "data": {
          "id": "dataset:fineweb",
          "label": "FineWeb",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-31",
          "lastSeen": "2026-01-17",
          "mentionCount7d": 3,
          "mentionCount30d": 10,
          "velocity": 0.47
        }
      },
      {
        "data": {
          "id": "tech:gguf",
          "label": "GGUF",
          "type": "Tech",
          "aliases": [
            "GGML"
          ],
          "firstSeen": "2026-01-04",
          "lastSeen": "2026-01-11",
          "mentionCount7d": 28,
          "mentionCount30d": 77,
          "velocity": 0.85
        }
      },
      {
        "data": {
          "id": "dataset:common_crawl",
          "label": "Common Crawl",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2026-01-13",
          "lastSeen": "2026-01-18",
          "mentionCount7d": 6,
          "mentionCount30d": 26,
          "velocity": 0.7
        }
      },
      {
        "data": {
          "id": "model:whisper_v4",
          "label": "Whisper v4",
          "type": "Model",
          "aliases": [
            "Whisper V4"
          ],
          "firstSeen": "2026-01-23",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 2,
          "mentionCount30d": 12,
          "velocity": 0.49
        }
      },
      {
        "data": {
          "id": "tech:tokenizer_bpe",
          "label": "Tokenizer BPE",
          "type": "Tech",
          "aliases": [
            "Byte Pair Encoding"
          ],
          "firstSeen": "2026-01-24",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 26,
          "mentionCount30d": 56,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "tool:autogpt_edge",
          "label": "AutoGPT Edge",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-29",
          "lastSeen": "2025-11-29",
          "mentionCount7d": 19,
          "mentionCount30d": 28,
          "velocity": 0.7
        }
      },
      {
        "data": {
          "id": "paper:self_play_fine_tuning_for_language_model",
          "label": "Self-Play Fine-Tuning for Language Models",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-11-18",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 9,
          "mentionCount30d": 20,
          "velocity": 0.92
        }
      },
      {
        "data": {
          "id": "model:whisper_v4_max",
          "label": "Whisper v4 Max",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-10-31",
          "lastSeen": "2025-11-03",
          "mentionCount7d": 14,
          "mentionCount30d": 36,
          "velocity": 0.95
        }
      },
      {
        "data": {
          "id": "dataset:redpajama_v2_v2",
          "label": "RedPajama v2 v2",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-10-25",
          "lastSeen": "2025-11-27",
          "mentionCount7d": 10,
          "mentionCount30d": 18,
          "velocity": 0.1
        }
      },
      {
        "data": {
          "id": "tech:quantization_edge",
          "label": "Quantization Edge",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-25",
          "lastSeen": "2025-12-08",
          "mentionCount7d": 33,
          "mentionCount30d": 65,
          "velocity": 0.76
        }
      },
      {
        "data": {
          "id": "dataset:fineweb_v2",
          "label": "FineWeb v2",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2026-01-20",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 15,
          "mentionCount30d": 27,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "benchmark:winogrande",
          "label": "WinoGrande",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2025-12-17",
          "lastSeen": "2026-01-12",
          "mentionCount7d": 18,
          "mentionCount30d": 21,
          "velocity": 0.24
        }
      },
      {
        "data": {
          "id": "repo:ollama",
          "label": "ollama",
          "type": "Repo",
          "aliases": [
            "ollama/ollama"
          ],
          "firstSeen": "2025-11-27",
          "lastSeen": "2026-01-13",
          "mentionCount7d": 0,
          "mentionCount30d": 2,
          "velocity": 0.71
        }
      },
      {
        "data": {
          "id": "tech:speculative_decoding_plus",
          "label": "Speculative Decoding Plus",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-12-23",
          "lastSeen": "2025-12-23",
          "mentionCount7d": 25,
          "mentionCount30d": 51,
          "velocity": 0.98
        }
      },
      {
        "data": {
          "id": "benchmark:alpacaeval_2",
          "label": "AlpacaEval 2",
          "type": "Benchmark",
          "aliases": [
            "AlpacaEval"
          ],
          "firstSeen": "2026-01-02",
          "lastSeen": "2026-01-12",
          "mentionCount7d": 1,
          "mentionCount30d": 8,
          "velocity": 0.47
        }
      },
      {
        "data": {
          "id": "model:whisper_v4_next",
          "label": "Whisper v4 Next",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-17",
          "lastSeen": "2025-12-18",
          "mentionCount7d": 19,
          "mentionCount30d": 23,
          "velocity": 0.07
        }
      },
      {
        "data": {
          "id": "dataset:refinedweb_ultra",
          "label": "RefinedWeb Ultra",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-01",
          "lastSeen": "2025-12-10",
          "mentionCount7d": 4,
          "mentionCount30d": 16,
          "velocity": 0.84
        }
      },
      {
        "data": {
          "id": "model:sora_2_ultra",
          "label": "Sora 2 Ultra",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-02",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 3,
          "mentionCount30d": 10,
          "velocity": 0.09
        }
      },
      {
        "data": {
          "id": "paper:flash_attention:_fast_and_memory_efficie",
          "label": "Flash Attention: Fast and Memory-Efficient Attention",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-12-05",
          "lastSeen": "2026-01-05",
          "mentionCount7d": 9,
          "mentionCount30d": 11,
          "velocity": 0.86
        }
      },
      {
        "data": {
          "id": "tool:weights_and_biases_core",
          "label": "Weights & Biases Core",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-02",
          "lastSeen": "2025-12-05",
          "mentionCount7d": 11,
          "mentionCount30d": 31,
          "velocity": 0.73
        }
      },
      {
        "data": {
          "id": "benchmark:arc_agi",
          "label": "ARC-AGI",
          "type": "Benchmark",
          "aliases": [
            "ARC AGI"
          ],
          "firstSeen": "2026-01-20",
          "lastSeen": "2026-01-23",
          "mentionCount7d": 12,
          "mentionCount30d": 25,
          "velocity": 0.82
        }
      },
      {
        "data": {
          "id": "model:falcon_3",
          "label": "Falcon 3",
          "type": "Model",
          "aliases": [
            "Falcon3"
          ],
          "firstSeen": "2026-01-24",
          "lastSeen": "2026-01-24",
          "mentionCount7d": 11,
          "mentionCount30d": 44,
          "velocity": 1.0
        }
      },
      {
        "data": {
          "id": "model:jamba_2_edge",
          "label": "Jamba 2 Edge",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-12",
          "lastSeen": "2026-01-23",
          "mentionCount7d": 5,
          "mentionCount30d": 25,
          "velocity": 0.52
        }
      },
      {
        "data": {
          "id": "benchmark:mmlu_max",
          "label": "MMLU Max",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2026-01-24",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 14,
          "mentionCount30d": 31,
          "velocity": 0.84
        }
      },
      {
        "data": {
          "id": "tool:ollama",
          "label": "Ollama",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-17",
          "lastSeen": "2025-12-29",
          "mentionCount7d": 5,
          "mentionCount30d": 21,
          "velocity": 0.13
        }
      },
      {
        "data": {
          "id": "tech:speculative_decoding",
          "label": "Speculative Decoding",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2026-01-19",
          "lastSeen": "2026-01-19",
          "mentionCount7d": 9,
          "mentionCount30d": 46,
          "velocity": 0.67
        }
      },
      {
        "data": {
          "id": "dataset:common_crawl_plus",
          "label": "Common Crawl Plus",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-13",
          "lastSeen": "2025-12-23",
          "mentionCount7d": 5,
          "mentionCount30d": 23,
          "velocity": 0.44
        }
      },
      {
        "data": {
          "id": "paper:mixture_of_experts_meets_instruction_tun",
          "label": "Mixture of Experts Meets Instruction Tuning",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-12-08",
          "lastSeen": "2026-01-01",
          "mentionCount7d": 6,
          "mentionCount30d": 23,
          "velocity": 0.64
        }
      },
      {
        "data": {
          "id": "model:mixtral_8x22b_core",
          "label": "Mixtral 8x22B Core",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-25",
          "lastSeen": "2025-12-10",
          "mentionCount7d": 23,
          "mentionCount30d": 36,
          "velocity": 0.96
        }
      },
      {
        "data": {
          "id": "tech:transformer_architecture",
          "label": "Transformer Architecture",
          "type": "Tech",
          "aliases": [
            "Transformers"
          ],
          "firstSeen": "2026-01-01",
          "lastSeen": "2026-01-09",
          "mentionCount7d": 4,
          "mentionCount30d": 11,
          "velocity": 0.09
        }
      },
      {
        "data": {
          "id": "tool:semantic_kernel_mini",
          "label": "Semantic Kernel Mini",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-04",
          "lastSeen": "2025-12-17",
          "mentionCount7d": 5,
          "mentionCount30d": 23,
          "velocity": 0.13
        }
      },
      {
        "data": {
          "id": "dataset:roots",
          "label": "ROOTS",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2026-01-25",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 8,
          "mentionCount30d": 19,
          "velocity": 0.86
        }
      },
      {
        "data": {
          "id": "tech:chain_of_thought",
          "label": "Chain-of-Thought",
          "type": "Tech",
          "aliases": [
            "CoT"
          ],
          "firstSeen": "2025-11-06",
          "lastSeen": "2026-01-05",
          "mentionCount7d": 1,
          "mentionCount30d": 4,
          "velocity": 0.89
        }
      },
      {
        "data": {
          "id": "tool:mlflow_next",
          "label": "MLflow Next",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-12-01",
          "lastSeen": "2025-12-25",
          "mentionCount7d": 1,
          "mentionCount30d": 7,
          "velocity": 0.77
        }
      },
      {
        "data": {
          "id": "model:gemini_ultra_2_lite",
          "label": "Gemini Ultra 2 Lite",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-10-27",
          "lastSeen": "2026-01-20",
          "mentionCount7d": 35,
          "mentionCount30d": 42,
          "velocity": 0.77
        }
      },
      {
        "data": {
          "id": "tech:sliding_window_attention_ultra",
          "label": "Sliding Window Attention Ultra",
          "type": "Tech",
          "aliases": [],
          "firstSeen": "2025-11-20",
          "lastSeen": "2025-12-23",
          "mentionCount7d": 30,
          "mentionCount30d": 78,
          "velocity": 0.79
        }
      },
      {
        "data": {
          "id": "tech:mixture_of_experts",
          "label": "Mixture of Experts",
          "type": "Tech",
          "aliases": [
            "MoE"
          ],
          "firstSeen": "2025-11-09",
          "lastSeen": "2025-12-23",
          "mentionCount7d": 16,
          "mentionCount30d": 30,
          "velocity": 0.17
        }
      },
      {
        "data": {
          "id": "paper:constitutional_ai:_harmlessness_from_ai_",
          "label": "Constitutional AI: Harmlessness from AI Feedback",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-12-12",
          "lastSeen": "2026-01-07",
          "mentionCount7d": 4,
          "mentionCount30d": 9,
          "velocity": 0.89
        }
      },
      {
        "data": {
          "id": "model:nemotron_5_v2",
          "label": "Nemotron-5 v2",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-01",
          "lastSeen": "2025-12-31",
          "mentionCount7d": 7,
          "mentionCount30d": 58,
          "velocity": 0.2
        }
      },
      {
        "data": {
          "id": "tech:retrieval_augmented_generation",
          "label": "Retrieval-Augmented Generation",
          "type": "Tech",
          "aliases": [
            "RAG"
          ],
          "firstSeen": "2026-01-24",
          "lastSeen": "2026-01-25",
          "mentionCount7d": 8,
          "mentionCount30d": 78,
          "velocity": 0.55
        }
      },
      {
        "data": {
          "id": "tech:constitutional_ai",
          "label": "Constitutional AI",
          "type": "Tech",
          "aliases": [
            "CAI"
          ],
          "firstSeen": "2025-11-29",
          "lastSeen": "2025-12-17",
          "mentionCount7d": 2,
          "mentionCount30d": 14,
          "velocity": 0.16
        }
      },
      {
        "data": {
          "id": "model:gpt_5_mini",
          "label": "GPT-5 Mini",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-11-17",
          "lastSeen": "2025-12-03",
          "mentionCount7d": 19,
          "mentionCount30d": 58,
          "velocity": 0.75
        }
      },
      {
        "data": {
          "id": "tool:cursor_edge",
          "label": "Cursor Edge",
          "type": "Tool",
          "aliases": [],
          "firstSeen": "2025-11-12",
          "lastSeen": "2026-01-13",
          "mentionCount7d": 16,
          "mentionCount30d": 52,
          "velocity": 0.75
        }
      },
      {
        "data": {
          "id": "benchmark:lmsys_chatbot_arena",
          "label": "LMSYS Chatbot Arena",
          "type": "Benchmark",
          "aliases": [
            "Chatbot Arena"
          ],
          "firstSeen": "2025-12-09",
          "lastSeen": "2025-12-10",
          "mentionCount7d": 9,
          "mentionCount30d": 32,
          "velocity": 0.27
        }
      },
      {
        "data": {
          "id": "benchmark:gsm8k_core",
          "label": "GSM8K Core",
          "type": "Benchmark",
          "aliases": [],
          "firstSeen": "2026-01-15",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 9,
          "mentionCount30d": 35,
          "velocity": 0.43
        }
      },
      {
        "data": {
          "id": "tool:autogpt",
          "label": "AutoGPT",
          "type": "Tool",
          "aliases": [
            "Auto-GPT"
          ],
          "firstSeen": "2025-11-28",
          "lastSeen": "2026-01-21",
          "mentionCount7d": 13,
          "mentionCount30d": 36,
          "velocity": 0.98
        }
      },
      {
        "data": {
          "id": "model:yi_large_v2",
          "label": "Yi-Large v2",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2025-12-24",
          "lastSeen": "2026-01-14",
          "mentionCount7d": 30,
          "mentionCount30d": 65,
          "velocity": 0.23
        }
      },
      {
        "data": {
          "id": "paper:retrieval_augmented_generation_for_knowl",
          "label": "Retrieval-Augmented Generation for Knowledge-Intensive NLP",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-11-20",
          "lastSeen": "2025-12-25",
          "mentionCount7d": 5,
          "mentionCount30d": 19,
          "velocity": 0.65
        }
      },
      {
        "data": {
          "id": "paper:llm_agents:_a_survey",
          "label": "LLM Agents: A Survey",
          "type": "Paper",
          "aliases": [],
          "firstSeen": "2025-11-09",
          "lastSeen": "2026-01-22",
          "mentionCount7d": 11,
          "mentionCount30d": 38,
          "velocity": 0.9
        }
      },
      {
        "data": {
          "id": "repo:transformers",
          "label": "transformers",
          "type": "Repo",
          "aliases": [
            "huggingface/transformers"
          ],
          "firstSeen": "2025-12-09",
          "lastSeen": "2025-12-21",
          "mentionCount7d": 13,
          "mentionCount30d": 23,
          "velocity": 0.8
        }
      },
      {
        "data": {
          "id": "model:grok_3_plus",
          "label": "Grok-3 Plus",
          "type": "Model",
          "aliases": [],
          "firstSeen": "2026-01-11",
          "lastSeen": "2026-01-13",
          "mentionCount7d": 3,
          "mentionCount30d": 8,
          "velocity": 0.15
        }
      },
      {
        "data": {
          "id": "dataset:dolma_next",
          "label": "Dolma Next",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-04",
          "lastSeen": "2025-12-14",
          "mentionCount7d": 2,
          "mentionCount30d": 7,
          "velocity": 0.8
        }
      },
      {
        "data": {
          "id": "dataset:refinedweb",
          "label": "RefinedWeb",
          "type": "Dataset",
          "aliases": [],
          "firstSeen": "2025-12-20",
          "lastSeen": "2025-12-27",
          "mentionCount7d": 4,
          "mentionCount30d": 7,
          "velocity": 0.73
        }
      }
    ],
    "edges": [
      {
        "data": {
          "id": "e:langchain_plus_distillation_uses_tech",
          "source": "tool:langchain_plus",
          "target": "tech:distillation",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.65
        }
      },
      {
        "data": {
          "id": "e:fineweb_constitutional_ai_ultra_uses_tech",
          "source": "dataset:fineweb",
          "target": "tech:constitutional_ai_ultra",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.49
        }
      },
      {
        "data": {
          "id": "e:litellm_edge_cody_integrates_with",
          "source": "tool:litellm_edge",
          "target": "tool:cody",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:qwen_3_math_v2_evaluated_on",
          "source": "model:qwen_3",
          "target": "benchmark:math_v2",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2025-12-01_the_verge_3808",
              "url": "https://theverge.com/2025/12/01/qwen_3_math_v2",
              "published": "2025-12-01",
              "snippet": "On the MATH v2 benchmark, Qwen-3 scored 76%..."
            },
            {
              "docId": "2025-12-27_nextgov_5362",
              "url": "https://nextgov.com/2025/12/27/qwen_3_math_v2",
              "published": "2025-12-27",
              "snippet": "Qwen-3 achieves 98% on MATH v2, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:lora:_low_rank_adaptation_of_large_langu_midjourney_v7_edge_evaluated_on",
          "source": "paper:lora:_low_rank_adaptation_of_large_langu",
          "target": "model:midjourney_v7_edge",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.75
        }
      },
      {
        "data": {
          "id": "e:vllm_v2_mixtral_8x22b_edge_integrates_with",
          "source": "repo:vllm_v2",
          "target": "model:mixtral_8x22b_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:cody_pro_falcon_3_v2_integrates_with",
          "source": "tool:cody_pro",
          "target": "model:falcon_3_v2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-23_the_verge_8887",
              "url": "https://theverge.com/2026/01/23/cody_pro_falcon_3_v2",
              "published": "2026-01-23",
              "snippet": "The latest release of Cody Pro adds native Falcon 3 v2 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:phi_4_mini_palm_3_ultra_depends_on",
          "source": "model:phi_4_mini",
          "target": "model:palm_3_ultra",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.7
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_plus_rotary_position_embedding_v2_uses_tech",
          "source": "model:dall_e_4_plus",
          "target": "tech:rotary_position_embedding_v2",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.92
        }
      },
      {
        "data": {
          "id": "e:cursor_aya_3_integrates_with",
          "source": "tool:cursor",
          "target": "model:aya_3",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-22_langchain_blog_7917",
              "url": "https://blog.langchain.dev/2026/01/22/cursor_aya_3",
              "published": "2026-01-22",
              "snippet": "The latest release of Cursor adds native Aya 3 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:lmsys_chatbot_arena_lite_codex_2_ultra_measures",
          "source": "benchmark:lmsys_chatbot_arena_lite",
          "target": "model:codex_2_ultra",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.95,
          "evidence": [
            {
              "docId": "2026-01-14_google_ai_blog_1858",
              "url": "https://blog.google/technology/ai/2026/01/14/lmsys_chatbot_arena_lite_codex",
              "published": "2026-01-14",
              "snippet": "LMSYS Chatbot Arena Lite provides standardized evaluation of Codex 2 Ultra..."
            },
            {
              "docId": "2026-01-14_mit_technology__4557",
              "url": "https://technologyreview.com/2026/01/14/lmsys_chatbot_arena_lite_codex",
              "published": "2026-01-14",
              "snippet": "LMSYS Chatbot Arena Lite has become the standard for evaluating Codex 2 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:hellaswag_aya_3_v2_measures",
          "source": "benchmark:hellaswag",
          "target": "model:aya_3_v2",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-04_hugging_face_bl_7460",
              "url": "https://huggingface.co/blog/2026/01/04/hellaswag_aya_3_v2",
              "published": "2026-01-04",
              "snippet": "The HellaSwag benchmark measures Aya 3 v2 across multiple tasks..."
            },
            {
              "docId": "2026-01-18_meta_ai_blog_3392",
              "url": "https://ai.meta.com/blog/2026/01/18/hellaswag_aya_3_v2",
              "published": "2026-01-18",
              "snippet": "The HellaSwag benchmark measures Aya 3 v2 across multiple tasks..."
            },
            {
              "docId": "2026-01-24_arxiv_8210",
              "url": "https://arxiv.org/abs/2026/01/24/hellaswag_aya_3_v2",
              "published": "2026-01-24",
              "snippet": "The HellaSwag benchmark measures Aya 3 v2 across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamaindex_core_rotary_position_embedding_v2_uses_tech",
          "source": "tool:llamaindex_core",
          "target": "tech:rotary_position_embedding_v2",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.8
        }
      },
      {
        "data": {
          "id": "e:weights_and_biases_cody_pro_integrates_with",
          "source": "tool:weights_and_biases",
          "target": "tool:cody_pro",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.57,
          "evidence": [
            {
              "docId": "2026-01-23_meta_ai_blog_7684",
              "url": "https://ai.meta.com/blog/2026/01/23/weights_and_biases_cody_pro",
              "published": "2026-01-23",
              "snippet": "Weights & Biases announced official support for Cody Pro..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_whisper_v4_max_evaluated_on",
          "source": "paper:llm_agents:_a_survey",
          "target": "model:whisper_v4_max",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2025-11-20_google_ai_blog_2649",
              "url": "https://blog.google/technology/ai/2025/11/20/llm_agents:_a_survey_whisper_v",
              "published": "2025-11-20",
              "snippet": "On the Whisper v4 Max benchmark, LLM Agents: A Survey scored 70%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:haystack_core_mixture_of_experts_core_uses_tech",
          "source": "tool:haystack_core",
          "target": "tech:mixture_of_experts_core",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.85
        }
      },
      {
        "data": {
          "id": "e:semantic_kernel_edge_synthetic_data_generation_ultra_uses_tech",
          "source": "tool:semantic_kernel_edge",
          "target": "tech:synthetic_data_generation_ultra",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.89
        }
      },
      {
        "data": {
          "id": "e:mixtral_8x22b_dall_e_4_edge_depends_on",
          "source": "model:mixtral_8x22b",
          "target": "model:dall_e_4_edge",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_plus_phi_4_mini_depends_on",
          "source": "model:dall_e_4_plus",
          "target": "model:phi_4_mini",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:the_stack_v2_flash_attention_uses_tech",
          "source": "dataset:the_stack_v2",
          "target": "tech:flash_attention",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.49
        }
      },
      {
        "data": {
          "id": "e:llamaindex_llamaindex_core_integrates_with",
          "source": "tool:llamaindex",
          "target": "tool:llamaindex_core",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-22_nextgov_9263",
              "url": "https://nextgov.com/2026/01/22/llamaindex_llamaindex_core",
              "published": "2026-01-22",
              "snippet": "LlamaIndex announced official support for LlamaIndex Core..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:autogpt_max_copilot_integrates_with",
          "source": "tool:autogpt_max",
          "target": "tool:copilot",
          "rel": "INTEGRATES_WITH",
          "kind": "hypothesis",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:tree_of_thoughts:_deliberate_problem_sol_claude_opus_45_edge_evaluated_on",
          "source": "paper:tree_of_thoughts:_deliberate_problem_sol",
          "target": "model:claude_opus_45_edge",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.72,
          "evidence": [
            {
              "docId": "2026-01-02_reuters_4632",
              "url": "https://reuters.com/technology/2026/01/02/tree_of_thoughts:_deliberate_p",
              "published": "2026-01-02",
              "snippet": "On the Claude Opus 4.5 Edge benchmark, Tree of Thoughts: Deliberate Problem Solving with LLMs scored 85%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:roots_distillation_next_uses_tech",
          "source": "dataset:roots",
          "target": "tech:distillation_next",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.74
        }
      },
      {
        "data": {
          "id": "e:qwen_3_ultra_dall_e_4_depends_on",
          "source": "model:qwen_3_ultra",
          "target": "model:dall_e_4",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.58
        }
      },
      {
        "data": {
          "id": "e:langchain_rlhf_uses_tech",
          "source": "tool:langchain",
          "target": "tech:rlhf",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.77
        }
      },
      {
        "data": {
          "id": "e:autogpt_quantization_uses_tech",
          "source": "repo:autogpt",
          "target": "tech:quantization",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.8,
          "evidence": [
            {
              "docId": "2026-01-24_anthropic_blog_5789",
              "url": "https://anthropic.com/news/2026/01/24/autogpt_quantization",
              "published": "2026-01-24",
              "snippet": "Technical details reveal AutoGPT relies heavily on Quantization..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt_5_lmsys_chatbot_arena_lite_evaluated_on",
          "source": "model:gpt_5",
          "target": "benchmark:lmsys_chatbot_arena_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-12_arxiv_9148",
              "url": "https://arxiv.org/abs/2026/01/12/gpt_5_lmsys_chatbot_arena_lite",
              "published": "2026-01-12",
              "snippet": "Evaluation results show GPT-5 reaching 73% on LMSYS Chatbot Arena Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:cursor_edge_gpt_5_integrates_with",
          "source": "tool:cursor_edge",
          "target": "model:gpt_5",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2025-11-20_the_verge_9785",
              "url": "https://theverge.com/2025/11/20/cursor_edge_gpt_5",
              "published": "2025-11-20",
              "snippet": "Cursor Edge announced official support for GPT-5..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:hellaswag_phi_4_ultra_measures",
          "source": "benchmark:hellaswag",
          "target": "model:phi_4_ultra",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.86,
          "evidence": [
            {
              "docId": "2025-12-23_anthropic_blog_8274",
              "url": "https://anthropic.com/news/2025/12/23/hellaswag_phi_4_ultra",
              "published": "2025-12-23",
              "snippet": "HellaSwag provides standardized evaluation of Phi-4 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gradio_max_command_r_plus_plus_integrates_with",
          "source": "tool:gradio_max",
          "target": "model:command_r_plus_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.93
        }
      },
      {
        "data": {
          "id": "e:mmlu_mixtral_8x22b_core_measures",
          "source": "benchmark:mmlu",
          "target": "model:mixtral_8x22b_core",
          "rel": "MEASURES",
          "kind": "inferred",
          "confidence": 0.86
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_multimodal_fusion_plus_uses_tech",
          "source": "paper:direct_preference_optimization",
          "target": "tech:multimodal_fusion_plus",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.89
        }
      },
      {
        "data": {
          "id": "e:vllm_v2_distillation_uses_tech",
          "source": "repo:vllm_v2",
          "target": "tech:distillation",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:self_play_fine_tuning_for_language_model_qwen_3_next_evaluated_on",
          "source": "paper:self_play_fine_tuning_for_language_model",
          "target": "model:qwen_3_next",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.91
        }
      },
      {
        "data": {
          "id": "e:gpqa_aya_3_measures",
          "source": "benchmark:gpqa",
          "target": "model:aya_3",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-21_microsoft_resea_4426",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/21/gpqa_aya_3",
              "published": "2026-01-21",
              "snippet": "GPQA provides standardized evaluation of Aya 3..."
            },
            {
              "docId": "2026-01-23_reuters_1586",
              "url": "https://reuters.com/technology/2026/01/23/gpqa_aya_3",
              "published": "2026-01-23",
              "snippet": "GPQA has become the standard for evaluating Aya 3..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mmlu_aya_3_measures",
          "source": "benchmark:mmlu",
          "target": "model:aya_3",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-25_ars_technica_8981",
              "url": "https://arstechnica.com/2026/01/25/mmlu_aya_3",
              "published": "2026-01-25",
              "snippet": "MMLU provides standardized evaluation of Aya 3..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:weights_and_biases_plus_flash_attention_uses_tech",
          "source": "tool:weights_and_biases_plus",
          "target": "tech:flash_attention",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.86,
          "evidence": [
            {
              "docId": "2026-01-20_langchain_blog_1386",
              "url": "https://blog.langchain.dev/2026/01/20/weights_and_biases_plus_flash_",
              "published": "2026-01-20",
              "snippet": "Weights & Biases Plus leverages Flash Attention to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:sora_2_alpacaeval_2_lite_evaluated_on",
          "source": "model:sora_2",
          "target": "benchmark:alpacaeval_2_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.82,
          "evidence": [
            {
              "docId": "2026-01-22_the_gradient_5998",
              "url": "https://thegradient.pub/2026/01/22/sora_2_alpacaeval_2_lite",
              "published": "2026-01-22",
              "snippet": "Evaluation results show Sora 2 reaching 82% on AlpacaEval 2 Lite..."
            },
            {
              "docId": "2026-01-22_hugging_face_bl_1203",
              "url": "https://huggingface.co/blog/2026/01/22/sora_2_alpacaeval_2_lite",
              "published": "2026-01-22",
              "snippet": "Evaluation results show Sora 2 reaching 87% on AlpacaEval 2 Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_v2_llama_4_max_depends_on",
          "source": "model:palm_3_v2",
          "target": "model:llama_4_max",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:qwen_3_ultra_quantization_uses_tech",
          "source": "model:qwen_3_ultra",
          "target": "tech:quantization",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.55
        }
      },
      {
        "data": {
          "id": "e:yi_large_fineweb_trained_on",
          "source": "model:yi_large",
          "target": "dataset:fineweb",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-23_bloomberg_5808",
              "url": "https://bloomberg.com/technology/2026/01/23/yi_large_fineweb",
              "published": "2026-01-23",
              "snippet": "Yi-Large was trained on FineWeb comprising billions of tokens..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gemma_3_v2_mixtral_8x22b_edge_depends_on",
          "source": "model:gemma_3_v2",
          "target": "model:mixtral_8x22b_edge",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.45
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_pro_stable_diffusion_4_max_evaluated_on",
          "source": "paper:llm_agents:_a_survey_pro",
          "target": "model:stable_diffusion_4_max",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.8,
          "evidence": [
            {
              "docId": "2025-12-04_nvidia_blog_1639",
              "url": "https://blogs.nvidia.com/2025/12/04/llm_agents:_a_survey_pro_stabl",
              "published": "2025-12-04",
              "snippet": "Evaluation results show LLM Agents: A Survey Pro reaching 91% on Stable Diffusion 4 Max..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_next_dpo_lite_uses_tech",
          "source": "model:llama_4_next",
          "target": "tech:dpo_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.85
        }
      },
      {
        "data": {
          "id": "e:lmsys_chatbot_arena_qwen_3_next_measures",
          "source": "benchmark:lmsys_chatbot_arena",
          "target": "model:qwen_3_next",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-17_bloomberg_2128",
              "url": "https://bloomberg.com/technology/2026/01/17/lmsys_chatbot_arena_qwen_3_nex",
              "published": "2026-01-17",
              "snippet": "LMSYS Chatbot Arena has become the standard for evaluating Qwen-3 Next..."
            },
            {
              "docId": "2026-01-24_the_gradient_9921",
              "url": "https://thegradient.pub/2026/01/24/lmsys_chatbot_arena_qwen_3_nex",
              "published": "2026-01-24",
              "snippet": "The LMSYS Chatbot Arena benchmark measures Qwen-3 Next across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:attention_is_all_you_need_v2_rotary_position_embedding_pro_uses_tech",
          "source": "paper:attention_is_all_you_need_v2",
          "target": "tech:rotary_position_embedding_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.94
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_pro_whisper_v4_max_evaluated_on",
          "source": "paper:llm_agents:_a_survey_pro",
          "target": "model:whisper_v4_max",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.78,
          "evidence": [
            {
              "docId": "2025-12-27_google_ai_blog_4874",
              "url": "https://blog.google/technology/ai/2025/12/27/llm_agents:_a_survey_pro_whisp",
              "published": "2025-12-27",
              "snippet": "On the Whisper v4 Max benchmark, LLM Agents: A Survey Pro scored 73%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_ultra_command_r_plus_ultra_evaluated_on",
          "source": "paper:direct_preference_optimization_ultra",
          "target": "model:command_r_plus_ultra",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-09_anthropic_blog_6946",
              "url": "https://anthropic.com/news/2026/01/09/direct_preference_optimization",
              "published": "2026-01-09",
              "snippet": "On the Command R+ Ultra benchmark, Direct Preference Optimization Ultra scored 99%..."
            },
            {
              "docId": "2026-01-21_wired_5997",
              "url": "https://wired.com/2026/01/21/direct_preference_optimization",
              "published": "2026-01-21",
              "snippet": "Direct Preference Optimization Ultra achieves 75% on Command R+ Ultra, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:redpajama_v2_v2_dpo_plus_uses_tech",
          "source": "dataset:redpajama_v2_v2",
          "target": "tech:dpo_plus",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.67
        }
      },
      {
        "data": {
          "id": "e:chain_of_thought_prompting_elicits_reaso_dall_e_4_lite_evaluated_on",
          "source": "paper:chain_of_thought_prompting_elicits_reaso",
          "target": "model:dall_e_4_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-16_the_gradient_7025",
              "url": "https://thegradient.pub/2026/01/16/chain_of_thought_prompting_eli",
              "published": "2026-01-16",
              "snippet": "Chain-of-Thought Prompting Elicits Reasoning achieves 83% on DALL-E 4 Lite, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_max_the_stack_v2_ultra_trained_on",
          "source": "model:claude_opus_45_max",
          "target": "dataset:the_stack_v2_ultra",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.53,
          "evidence": [
            {
              "docId": "2026-01-04_bloomberg_5236",
              "url": "https://bloomberg.com/technology/2026/01/04/claude_opus_45_max_the_stack_v",
              "published": "2026-01-04",
              "snippet": "Claude Opus 4.5 Max was trained on The Stack v2 Ultra comprising billions of tokens..."
            },
            {
              "docId": "2026-01-08_nextgov_3127",
              "url": "https://nextgov.com/2026/01/08/claude_opus_45_max_the_stack_v",
              "published": "2026-01-08",
              "snippet": "The training corpus for Claude Opus 4.5 Max includes The Stack v2 Ultra..."
            },
            {
              "docId": "2026-01-13_bloomberg_3628",
              "url": "https://bloomberg.com/technology/2026/01/13/claude_opus_45_max_the_stack_v",
              "published": "2026-01-13",
              "snippet": "Claude Opus 4.5 Max utilized The Stack v2 Ultra as part of its pre-training data mix..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:swe_bench_jamba_2_measures",
          "source": "benchmark:swe_bench",
          "target": "model:jamba_2",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.97,
          "evidence": [
            {
              "docId": "2026-01-02_venturebeat_8342",
              "url": "https://venturebeat.com/2026/01/02/swe_bench_jamba_2",
              "published": "2026-01-02",
              "snippet": "The SWE-bench benchmark measures Jamba 2 across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:whisper_v4_max_gpt_5_depends_on",
          "source": "model:whisper_v4_max",
          "target": "model:gpt_5",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.73
        }
      },
      {
        "data": {
          "id": "e:llamacpp_whisper_v4_next_integrates_with",
          "source": "repo:llamacpp",
          "target": "model:whisper_v4_next",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.73
        }
      },
      {
        "data": {
          "id": "e:weights_and_biases_core_chain_of_thought_pro_uses_tech",
          "source": "tool:weights_and_biases_core",
          "target": "tech:chain_of_thought_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.81
        }
      },
      {
        "data": {
          "id": "e:attention_is_all_you_need_v2_gemma_3_evaluated_on",
          "source": "paper:attention_is_all_you_need_v2",
          "target": "model:gemma_3",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.91
        }
      },
      {
        "data": {
          "id": "e:llama_4_max_math_v2_evaluated_on",
          "source": "model:llama_4_max",
          "target": "benchmark:math_v2",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.96,
          "evidence": [
            {
              "docId": "2026-01-18_microsoft_resea_5750",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/18/llama_4_max_math_v2",
              "published": "2026-01-18",
              "snippet": "On the MATH v2 benchmark, Llama 4 Max scored 85%..."
            },
            {
              "docId": "2026-01-25_nvidia_blog_4612",
              "url": "https://blogs.nvidia.com/2026/01/25/llama_4_max_math_v2",
              "published": "2026-01-25",
              "snippet": "Llama 4 Max achieves 79% on MATH v2, setting a new record..."
            },
            {
              "docId": "2026-01-25_techcrunch_1454",
              "url": "https://techcrunch.com/2026/01/25/llama_4_max_math_v2",
              "published": "2026-01-25",
              "snippet": "Llama 4 Max achieves 91% on MATH v2, setting a new record..."
            },
            {
              "docId": "2026-01-25_techcrunch_1333",
              "url": "https://techcrunch.com/2026/01/25/llama_4_max_math_v2",
              "published": "2026-01-25",
              "snippet": "Evaluation results show Llama 4 Max reaching 79% on MATH v2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:whisper_v4_max_the_pile_trained_on",
          "source": "model:whisper_v4_max",
          "target": "dataset:the_pile",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.89
        }
      },
      {
        "data": {
          "id": "e:command_r_plus_ultra_transformer_architecture_uses_tech",
          "source": "model:command_r_plus_ultra",
          "target": "tech:transformer_architecture",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.55,
          "evidence": [
            {
              "docId": "2026-01-25_ars_technica_4572",
              "url": "https://arstechnica.com/2026/01/25/command_r_plus_ultra_transform",
              "published": "2026-01-25",
              "snippet": "Command R+ Ultra leverages Transformer Architecture to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:the_pile_core_rotary_position_embedding_pro_uses_tech",
          "source": "dataset:the_pile_core",
          "target": "tech:rotary_position_embedding_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.59
        }
      },
      {
        "data": {
          "id": "e:tensorrt_llm_next_gemma_3_lite_integrates_with",
          "source": "tool:tensorrt_llm_next",
          "target": "model:gemma_3_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.86,
          "evidence": [
            {
              "docId": "2026-01-09_google_ai_blog_5044",
              "url": "https://blog.google/technology/ai/2026/01/09/tensorrt_llm_next_gemma_3_lite",
              "published": "2026-01-09",
              "snippet": "TensorRT-LLM Next announced official support for Gemma 3 Lite..."
            },
            {
              "docId": "2026-01-09_google_ai_blog_6093",
              "url": "https://blog.google/technology/ai/2026/01/09/tensorrt_llm_next_gemma_3_lite",
              "published": "2026-01-09",
              "snippet": "The latest release of TensorRT-LLM Next adds native Gemma 3 Lite integration..."
            },
            {
              "docId": "2026-01-21_microsoft_resea_7817",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/21/tensorrt_llm_next_gemma_3_lite",
              "published": "2026-01-21",
              "snippet": "The latest release of TensorRT-LLM Next adds native Gemma 3 Lite integration..."
            },
            {
              "docId": "2026-01-24_arxiv_8042",
              "url": "https://arxiv.org/abs/2026/01/24/tensorrt_llm_next_gemma_3_lite",
              "published": "2026-01-24",
              "snippet": "TensorRT-LLM Next announced official support for Gemma 3 Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:litellm_rlhf_uses_tech",
          "source": "tool:litellm",
          "target": "tech:rlhf",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:gpqa_dall_e_4_plus_measures",
          "source": "benchmark:gpqa",
          "target": "model:dall_e_4_plus",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2025-12-31_techcrunch_3573",
              "url": "https://techcrunch.com/2025/12/31/gpqa_dall_e_4_plus",
              "published": "2025-12-31",
              "snippet": "GPQA has become the standard for evaluating DALL-E 4 Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:aya_3_edge_kv_cache_optimization_next_uses_tech",
          "source": "model:aya_3_edge",
          "target": "tech:kv_cache_optimization_next",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.64
        }
      },
      {
        "data": {
          "id": "e:streamlit_mixtral_8x22b_integrates_with",
          "source": "tool:streamlit",
          "target": "model:mixtral_8x22b",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-15_techcrunch_9561",
              "url": "https://techcrunch.com/2026/01/15/streamlit_mixtral_8x22b",
              "published": "2026-01-15",
              "snippet": "The latest release of Streamlit adds native Mixtral 8x22B integration..."
            },
            {
              "docId": "2026-01-16_weights_and_bia_8627",
              "url": "https://wandb.ai/articles/2026/01/16/streamlit_mixtral_8x22b",
              "published": "2026-01-16",
              "snippet": "Streamlit now supports Mixtral 8x22B with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_command_r_plus_plus_evaluated_on",
          "source": "paper:llm_agents:_a_survey",
          "target": "model:command_r_plus_plus",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.82,
          "evidence": [
            {
              "docId": "2026-01-12_nvidia_blog_2838",
              "url": "https://blogs.nvidia.com/2026/01/12/llm_agents:_a_survey_command_r",
              "published": "2026-01-12",
              "snippet": "On the Command R+ Plus benchmark, LLM Agents: A Survey scored 85%..."
            },
            {
              "docId": "2026-01-22_mit_technology__6773",
              "url": "https://technologyreview.com/2026/01/22/llm_agents:_a_survey_command_r",
              "published": "2026-01-22",
              "snippet": "On the Command R+ Plus benchmark, LLM Agents: A Survey scored 71%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mmlu_claude_sonnet_4_lite_measures",
          "source": "benchmark:mmlu",
          "target": "model:claude_sonnet_4_lite",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2025-12-28_mit_technology__1838",
              "url": "https://technologyreview.com/2025/12/28/mmlu_claude_sonnet_4_lite",
              "published": "2025-12-28",
              "snippet": "MMLU has become the standard for evaluating Claude Sonnet 4 Lite..."
            },
            {
              "docId": "2026-01-04_mit_technology__1607",
              "url": "https://technologyreview.com/2026/01/04/mmlu_claude_sonnet_4_lite",
              "published": "2026-01-04",
              "snippet": "The MMLU benchmark measures Claude Sonnet 4 Lite across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_plus_multimodal_fusion_lite_uses_tech",
          "source": "tool:langchain_plus",
          "target": "tech:multimodal_fusion_lite",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.69
        }
      },
      {
        "data": {
          "id": "e:mixture_of_experts_meets_instruction_tun_claude_opus_45_max_evaluated_on",
          "source": "paper:mixture_of_experts_meets_instruction_tun",
          "target": "model:claude_opus_45_max",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.9,
          "evidence": [
            {
              "docId": "2026-01-25_venturebeat_6474",
              "url": "https://venturebeat.com/2026/01/25/mixture_of_experts_meets_instr",
              "published": "2026-01-25",
              "snippet": "On the Claude Opus 4.5 Max benchmark, Mixture of Experts Meets Instruction Tuning scored 73%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:jamba_2_lite_hellaswag_evaluated_on",
          "source": "model:jamba_2_lite",
          "target": "benchmark:hellaswag",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.9,
          "evidence": [
            {
              "docId": "2026-01-21_the_gradient_9302",
              "url": "https://thegradient.pub/2026/01/21/jamba_2_lite_hellaswag",
              "published": "2026-01-21",
              "snippet": "Evaluation results show Jamba 2 Lite reaching 75% on HellaSwag..."
            },
            {
              "docId": "2026-01-24_meta_ai_blog_3613",
              "url": "https://ai.meta.com/blog/2026/01/24/jamba_2_lite_hellaswag",
              "published": "2026-01-24",
              "snippet": "Jamba 2 Lite achieves 84% on HellaSwag, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:vllm_edge_gemma_3_lite_integrates_with",
          "source": "tool:vllm_edge",
          "target": "model:gemma_3_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-11_google_ai_blog_7527",
              "url": "https://blog.google/technology/ai/2026/01/11/vllm_edge_gemma_3_lite",
              "published": "2026-01-11",
              "snippet": "vLLM Edge announced official support for Gemma 3 Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:lmsys_chatbot_arena_lite_jamba_2_edge_measures",
          "source": "benchmark:lmsys_chatbot_arena_lite",
          "target": "model:jamba_2_edge",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2026-01-25_venturebeat_3248",
              "url": "https://venturebeat.com/2026/01/25/lmsys_chatbot_arena_lite_jamba",
              "published": "2026-01-25",
              "snippet": "The LMSYS Chatbot Arena Lite benchmark measures Jamba 2 Edge across multiple tasks..."
            },
            {
              "docId": "2026-01-25_the_verge_4683",
              "url": "https://theverge.com/2026/01/25/lmsys_chatbot_arena_lite_jamba",
              "published": "2026-01-25",
              "snippet": "LMSYS Chatbot Arena Lite provides standardized evaluation of Jamba 2 Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:phi_4_mini_whisper_v4_depends_on",
          "source": "model:phi_4_mini",
          "target": "model:whisper_v4",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.68
        }
      },
      {
        "data": {
          "id": "e:ollama_gemini_ultra_2_max_integrates_with",
          "source": "tool:ollama",
          "target": "model:gemini_ultra_2_max",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.92
        }
      },
      {
        "data": {
          "id": "e:palm_3_v2_the_pile_core_trained_on",
          "source": "model:palm_3_v2",
          "target": "dataset:the_pile_core",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.83
        }
      },
      {
        "data": {
          "id": "e:falcon_3_pro_lmsys_chatbot_arena_lite_evaluated_on",
          "source": "model:falcon_3_pro",
          "target": "benchmark:lmsys_chatbot_arena_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-24_the_verge_1023",
              "url": "https://theverge.com/2026/01/24/falcon_3_pro_lmsys_chatbot_are",
              "published": "2026-01-24",
              "snippet": "Falcon 3 Pro achieves 77% on LMSYS Chatbot Arena Lite, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:text_generation_webui_mixtral_8x22b_edge_integrates_with",
          "source": "repo:text_generation_webui",
          "target": "model:mixtral_8x22b_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.78,
          "evidence": [
            {
              "docId": "2026-01-16_reuters_2482",
              "url": "https://reuters.com/technology/2026/01/16/text_generation_webui_mixtral_",
              "published": "2026-01-16",
              "snippet": "text-generation-webui now supports Mixtral 8x22B Edge with full feature parity..."
            },
            {
              "docId": "2026-01-16_arxiv_3829",
              "url": "https://arxiv.org/abs/2026/01/16/text_generation_webui_mixtral_",
              "published": "2026-01-16",
              "snippet": "The latest release of text-generation-webui adds native Mixtral 8x22B Edge integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:chain_of_thought_prompting_elicits_reaso_kv_cache_optimization_uses_tech",
          "source": "paper:chain_of_thought_prompting_elicits_reaso",
          "target": "tech:kv_cache_optimization",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-19_hugging_face_bl_6360",
              "url": "https://huggingface.co/blog/2026/01/19/chain_of_thought_prompting_eli",
              "published": "2026-01-19",
              "snippet": "Technical details reveal Chain-of-Thought Prompting Elicits Reasoning relies heavily on KV Cache Optimization..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:cody_pro_command_r_plus_ultra_integrates_with",
          "source": "tool:cody_pro",
          "target": "model:command_r_plus_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.75,
          "evidence": [
            {
              "docId": "2026-01-24_techcrunch_7987",
              "url": "https://techcrunch.com/2026/01/24/cody_pro_command_r_plus_ultra",
              "published": "2026-01-24",
              "snippet": "Cody Pro announced official support for Command R+ Ultra..."
            },
            {
              "docId": "2026-01-24_reuters_9243",
              "url": "https://reuters.com/technology/2026/01/24/cody_pro_command_r_plus_ultra",
              "published": "2026-01-24",
              "snippet": "The latest release of Cody Pro adds native Command R+ Ultra integration..."
            },
            {
              "docId": "2026-01-24_arxiv_9893",
              "url": "https://arxiv.org/abs/2026/01/24/cody_pro_command_r_plus_ultra",
              "published": "2026-01-24",
              "snippet": "The latest release of Cody Pro adds native Command R+ Ultra integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:tree_of_thoughts:_deliberate_problem_sol_rotary_position_embedding_uses_tech",
          "source": "paper:tree_of_thoughts:_deliberate_problem_sol",
          "target": "tech:rotary_position_embedding",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-01_mit_technology__3757",
              "url": "https://technologyreview.com/2026/01/01/tree_of_thoughts:_deliberate_p",
              "published": "2026-01-01",
              "snippet": "Tree of Thoughts: Deliberate Problem Solving with LLMs leverages Rotary Position Embedding to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-06_google_ai_blog_5398",
              "url": "https://blog.google/technology/ai/2026/01/06/tree_of_thoughts:_deliberate_p",
              "published": "2026-01-06",
              "snippet": "Technical details reveal Tree of Thoughts: Deliberate Problem Solving with LLMs relies heavily on Rotary Position Embedding..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:cursor_semantic_kernel_integrates_with",
          "source": "tool:cursor",
          "target": "tool:semantic_kernel",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.69,
          "evidence": [
            {
              "docId": "2026-01-15_meta_ai_blog_9414",
              "url": "https://ai.meta.com/blog/2026/01/15/cursor_semantic_kernel",
              "published": "2026-01-15",
              "snippet": "The latest release of Cursor adds native Semantic Kernel integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_gemma_3_lite_depends_on",
          "source": "model:palm_3",
          "target": "model:gemma_3_lite",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.73
        }
      },
      {
        "data": {
          "id": "e:palm_3_refinedweb_ultra_trained_on",
          "source": "model:palm_3",
          "target": "dataset:refinedweb_ultra",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:ollama_edge_tool_use_uses_tech",
          "source": "tool:ollama_edge",
          "target": "tech:tool_use",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.88
        }
      },
      {
        "data": {
          "id": "e:text_generation_webui_quantization_plus_uses_tech",
          "source": "repo:text_generation_webui",
          "target": "tech:quantization_plus",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.89
        }
      },
      {
        "data": {
          "id": "e:palm_3_ultra_arc_agi_evaluated_on",
          "source": "model:palm_3_ultra",
          "target": "benchmark:arc_agi",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.88
        }
      },
      {
        "data": {
          "id": "e:scaling_data_constrained_language_models_synthetic_data_generation_uses_tech",
          "source": "paper:scaling_data_constrained_language_models",
          "target": "tech:synthetic_data_generation",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.8,
          "evidence": [
            {
              "docId": "2026-01-18_openai_blog_4748",
              "url": "https://openai.com/blog/2026/01/18/scaling_data_constrained_langu",
              "published": "2026-01-18",
              "snippet": "Technical details reveal Scaling Data-Constrained Language Models relies heavily on Synthetic Data Generation..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:vllm_claude_sonnet_4_integrates_with",
          "source": "repo:vllm",
          "target": "model:claude_sonnet_4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.77,
          "evidence": [
            {
              "docId": "2026-01-23_mit_technology__7005",
              "url": "https://technologyreview.com/2026/01/23/vllm_claude_sonnet_4",
              "published": "2026-01-23",
              "snippet": "vllm now supports Claude Sonnet 4 with full feature parity..."
            },
            {
              "docId": "2026-01-23_anthropic_blog_1634",
              "url": "https://anthropic.com/news/2026/01/23/vllm_claude_sonnet_4",
              "published": "2026-01-23",
              "snippet": "vllm now supports Claude Sonnet 4 with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:transformers_dall_e_4_edge_integrates_with",
          "source": "repo:transformers",
          "target": "model:dall_e_4_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.92
        }
      },
      {
        "data": {
          "id": "e:cody_quantization_edge_uses_tech",
          "source": "tool:cody",
          "target": "tech:quantization_edge",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.84
        }
      },
      {
        "data": {
          "id": "e:laion_5b_edge_retrieval_augmented_generation_plus_uses_tech",
          "source": "dataset:laion_5b_edge",
          "target": "tech:retrieval_augmented_generation_plus",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:scaling_laws_for_neural_language_models__whisper_v4_evaluated_on",
          "source": "paper:scaling_laws_for_neural_language_models_",
          "target": "model:whisper_v4",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-23_techcrunch_8842",
              "url": "https://techcrunch.com/2026/01/23/scaling_laws_for_neural_langua",
              "published": "2026-01-23",
              "snippet": "Evaluation results show Scaling Laws for Neural Language Models (2025) reaching 94% on Whisper v4..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt_5_mini_redpajama_v2_v2_trained_on",
          "source": "model:gpt_5_mini",
          "target": "dataset:redpajama_v2_v2",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.81
        }
      },
      {
        "data": {
          "id": "e:dolma_next_dpo_lite_uses_tech",
          "source": "dataset:dolma_next",
          "target": "tech:dpo_lite",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.48
        }
      },
      {
        "data": {
          "id": "e:langchain_crewai_core_integrates_with",
          "source": "tool:langchain",
          "target": "tool:crewai_core",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:scaling_data_constrained_language_models_claude_opus_45_edge_evaluated_on",
          "source": "paper:scaling_data_constrained_language_models",
          "target": "model:claude_opus_45_edge",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.73,
          "evidence": [
            {
              "docId": "2026-01-22_openai_blog_7013",
              "url": "https://openai.com/blog/2026/01/22/scaling_data_constrained_langu",
              "published": "2026-01-22",
              "snippet": "Scaling Data-Constrained Language Models achieves 93% on Claude Opus 4.5 Edge, setting a new record..."
            },
            {
              "docId": "2026-01-24_hugging_face_bl_2169",
              "url": "https://huggingface.co/blog/2026/01/24/scaling_data_constrained_langu",
              "published": "2026-01-24",
              "snippet": "Scaling Data-Constrained Language Models achieves 94% on Claude Opus 4.5 Edge, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:open_interpreter_rlhf_mini_uses_tech",
          "source": "repo:open_interpreter",
          "target": "tech:rlhf_mini",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.71,
          "evidence": [
            {
              "docId": "2026-01-04_google_ai_blog_5418",
              "url": "https://blog.google/technology/ai/2026/01/04/open_interpreter_rlhf_mini",
              "published": "2026-01-04",
              "snippet": "Under the hood, open-interpreter implements RLHF Mini for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_max_stable_diffusion_4_mini_depends_on",
          "source": "model:llama_4_max",
          "target": "model:stable_diffusion_4_mini",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.57
        }
      },
      {
        "data": {
          "id": "e:ollama_edge_whisper_v4_integrates_with",
          "source": "tool:ollama_edge",
          "target": "model:whisper_v4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.9,
          "evidence": [
            {
              "docId": "2026-01-25_microsoft_resea_2250",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/25/ollama_edge_whisper_v4",
              "published": "2026-01-25",
              "snippet": "Ollama Edge now supports Whisper v4 with full feature parity..."
            },
            {
              "docId": "2026-01-25_weights_and_bia_7562",
              "url": "https://wandb.ai/articles/2026/01/25/ollama_edge_whisper_v4",
              "published": "2026-01-25",
              "snippet": "Ollama Edge now supports Whisper v4 with full feature parity..."
            },
            {
              "docId": "2026-01-25_the_verge_8615",
              "url": "https://theverge.com/2026/01/25/ollama_edge_whisper_v4",
              "published": "2026-01-25",
              "snippet": "The latest release of Ollama Edge adds native Whisper v4 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:redpajama_v2_v2_constitutional_ai_ultra_uses_tech",
          "source": "dataset:redpajama_v2_v2",
          "target": "tech:constitutional_ai_ultra",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.53
        }
      },
      {
        "data": {
          "id": "e:weights_and_biases_plus_transformer_architecture_edge_uses_tech",
          "source": "tool:weights_and_biases_plus",
          "target": "tech:transformer_architecture_edge",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.78,
          "evidence": [
            {
              "docId": "2026-01-25_meta_ai_blog_2438",
              "url": "https://ai.meta.com/blog/2026/01/25/weights_and_biases_plus_transf",
              "published": "2026-01-25",
              "snippet": "Technical details reveal Weights & Biases Plus relies heavily on Transformer Architecture Edge..."
            },
            {
              "docId": "2026-01-25_nvidia_blog_4889",
              "url": "https://blogs.nvidia.com/2026/01/25/weights_and_biases_plus_transf",
              "published": "2026-01-25",
              "snippet": "Under the hood, Weights & Biases Plus implements Transformer Architecture Edge for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:weights_and_biases_core_mixture_of_experts_max_uses_tech",
          "source": "tool:weights_and_biases_core",
          "target": "tech:mixture_of_experts_max",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:scaling_data_constrained_language_models_sparse_attention_lite_uses_tech",
          "source": "paper:scaling_data_constrained_language_models",
          "target": "tech:sparse_attention_lite",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.93,
          "evidence": [
            {
              "docId": "2026-01-21_the_verge_4709",
              "url": "https://theverge.com/2026/01/21/scaling_data_constrained_langu",
              "published": "2026-01-21",
              "snippet": "Scaling Data-Constrained Language Models leverages Sparse Attention Lite to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:deepseek_v3_edge_arc_agi_lite_evaluated_on",
          "source": "model:deepseek_v3_edge",
          "target": "benchmark:arc_agi_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.95,
          "evidence": [
            {
              "docId": "2026-01-13_techcrunch_7863",
              "url": "https://techcrunch.com/2026/01/13/deepseek_v3_edge_arc_agi_lite",
              "published": "2026-01-13",
              "snippet": "Evaluation results show DeepSeek-V3 Edge reaching 84% on ARC-AGI Lite..."
            },
            {
              "docId": "2026-01-20_reuters_2296",
              "url": "https://reuters.com/technology/2026/01/20/deepseek_v3_edge_arc_agi_lite",
              "published": "2026-01-20",
              "snippet": "Evaluation results show DeepSeek-V3 Edge reaching 70% on ARC-AGI Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_v2_truthfulqa_plus_evaluated_on",
          "source": "model:palm_3_v2",
          "target": "benchmark:truthfulqa_plus",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.93
        }
      },
      {
        "data": {
          "id": "e:tree_of_thoughts:_deliberate_problem_sol_gguf_ultra_uses_tech",
          "source": "paper:tree_of_thoughts:_deliberate_problem_sol",
          "target": "tech:gguf_ultra",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-16_nextgov_3012",
              "url": "https://nextgov.com/2026/01/16/tree_of_thoughts:_deliberate_p",
              "published": "2026-01-16",
              "snippet": "Under the hood, Tree of Thoughts: Deliberate Problem Solving with LLMs implements GGUF Ultra for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_max_command_r_plus_plus_depends_on",
          "source": "model:llama_4_max",
          "target": "model:command_r_plus_plus",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.47
        }
      },
      {
        "data": {
          "id": "e:fineweb_v2_lora_core_uses_tech",
          "source": "dataset:fineweb_v2",
          "target": "tech:lora_core",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.44
        }
      },
      {
        "data": {
          "id": "e:whisper_v4_midjourney_v7_edge_depends_on",
          "source": "model:whisper_v4",
          "target": "model:midjourney_v7_edge",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:common_crawl_sparse_attention_lite_uses_tech",
          "source": "dataset:common_crawl",
          "target": "tech:sparse_attention_lite",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.46
        }
      },
      {
        "data": {
          "id": "e:falcon_3_v2_lmsys_chatbot_arena_evaluated_on",
          "source": "model:falcon_3_v2",
          "target": "benchmark:lmsys_chatbot_arena",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.97,
          "evidence": [
            {
              "docId": "2026-01-25_anthropic_blog_1035",
              "url": "https://anthropic.com/news/2026/01/25/falcon_3_v2_lmsys_chatbot_aren",
              "published": "2026-01-25",
              "snippet": "Falcon 3 v2 achieves 82% on LMSYS Chatbot Arena, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamaindex_core_copilot_integrates_with",
          "source": "tool:llamaindex_core",
          "target": "tool:copilot",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.59
        }
      },
      {
        "data": {
          "id": "e:vllm_v2_command_r_plus_lite_integrates_with",
          "source": "repo:vllm_v2",
          "target": "model:command_r_plus_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.72,
          "evidence": [
            {
              "docId": "2026-01-23_the_verge_3096",
              "url": "https://theverge.com/2026/01/23/vllm_v2_command_r_plus_lite",
              "published": "2026-01-23",
              "snippet": "vllm v2 announced official support for Command R+ Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_claude_opus_45_edge_integrates_with",
          "source": "repo:langchain",
          "target": "model:claude_opus_45_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-06_the_verge_1265",
              "url": "https://theverge.com/2026/01/06/langchain_claude_opus_45_edge",
              "published": "2026-01-06",
              "snippet": "langchain now supports Claude Opus 4.5 Edge with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:toolformer:_language_models_can_teach_th_multimodal_fusion_lite_uses_tech",
          "source": "paper:toolformer:_language_models_can_teach_th",
          "target": "tech:multimodal_fusion_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:llamaindex_ultra_sora_2_max_integrates_with",
          "source": "tool:llamaindex_ultra",
          "target": "model:sora_2_max",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.77
        }
      },
      {
        "data": {
          "id": "e:flowise_tensorrt_llm_integrates_with",
          "source": "tool:flowise",
          "target": "tool:tensorrt_llm",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-23_the_gradient_5624",
              "url": "https://thegradient.pub/2026/01/23/flowise_tensorrt_llm",
              "published": "2026-01-23",
              "snippet": "The latest release of Flowise adds native TensorRT-LLM integration..."
            },
            {
              "docId": "2026-01-23_nextgov_3955",
              "url": "https://nextgov.com/2026/01/23/flowise_tensorrt_llm",
              "published": "2026-01-23",
              "snippet": "Flowise now supports TensorRT-LLM with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_max_redpajama_v2_trained_on",
          "source": "model:llama_4_max",
          "target": "dataset:redpajama_v2",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.68,
          "evidence": [
            {
              "docId": "2026-01-21_meta_ai_blog_6051",
              "url": "https://ai.meta.com/blog/2026/01/21/llama_4_max_redpajama_v2",
              "published": "2026-01-21",
              "snippet": "The training corpus for Llama 4 Max includes RedPajama v2..."
            },
            {
              "docId": "2026-01-24_weights_and_bia_6676",
              "url": "https://wandb.ai/articles/2026/01/24/llama_4_max_redpajama_v2",
              "published": "2026-01-24",
              "snippet": "Llama 4 Max was trained on RedPajama v2 comprising billions of tokens..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_v2_group_query_attention_v2_uses_tech",
          "source": "model:palm_3_v2",
          "target": "tech:group_query_attention_v2",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.57
        }
      },
      {
        "data": {
          "id": "e:textbooks_are_all_you_need_synthetic_data_generation_uses_tech",
          "source": "paper:textbooks_are_all_you_need",
          "target": "tech:synthetic_data_generation",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2026-01-25_nvidia_blog_7626",
              "url": "https://blogs.nvidia.com/2026/01/25/textbooks_are_all_you_need_syn",
              "published": "2026-01-25",
              "snippet": "Under the hood, Textbooks Are All You Need implements Synthetic Data Generation for improved efficiency..."
            },
            {
              "docId": "2026-01-25_reuters_7711",
              "url": "https://reuters.com/technology/2026/01/25/textbooks_are_all_you_need_syn",
              "published": "2026-01-25",
              "snippet": "Textbooks Are All You Need leverages Synthetic Data Generation to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:openwebtext2_mini_tokenizer_bpe_next_uses_tech",
          "source": "dataset:openwebtext2_mini",
          "target": "tech:tokenizer_bpe_next",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.64
        }
      },
      {
        "data": {
          "id": "e:langchain_stable_diffusion_4_max_integrates_with",
          "source": "repo:langchain",
          "target": "model:stable_diffusion_4_max",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2025-12-16_the_verge_2936",
              "url": "https://theverge.com/2025/12/16/langchain_stable_diffusion_4_m",
              "published": "2025-12-16",
              "snippet": "The latest release of langchain adds native Stable Diffusion 4 Max integration..."
            },
            {
              "docId": "2026-01-08_reuters_3769",
              "url": "https://reuters.com/technology/2026/01/08/langchain_stable_diffusion_4_m",
              "published": "2026-01-08",
              "snippet": "langchain now supports Stable Diffusion 4 Max with full feature parity..."
            },
            {
              "docId": "2026-01-25_langchain_blog_1409",
              "url": "https://blog.langchain.dev/2026/01/25/langchain_stable_diffusion_4_m",
              "published": "2026-01-25",
              "snippet": "langchain announced official support for Stable Diffusion 4 Max..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:falcon_3_mmlu_max_evaluated_on",
          "source": "model:falcon_3",
          "target": "benchmark:mmlu_max",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.97,
          "evidence": [
            {
              "docId": "2026-01-25_the_verge_8306",
              "url": "https://theverge.com/2026/01/25/falcon_3_mmlu_max",
              "published": "2026-01-25",
              "snippet": "On the MMLU Max benchmark, Falcon 3 scored 91%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:semantic_kernel_semantic_kernel_edge_integrates_with",
          "source": "tool:semantic_kernel",
          "target": "tool:semantic_kernel_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.71,
          "evidence": [
            {
              "docId": "2025-12-22_techcrunch_4380",
              "url": "https://techcrunch.com/2025/12/22/semantic_kernel_semantic_kerne",
              "published": "2025-12-22",
              "snippet": "The latest release of Semantic Kernel adds native Semantic Kernel Edge integration..."
            },
            {
              "docId": "2026-01-13_wired_1725",
              "url": "https://wired.com/2026/01/13/semantic_kernel_semantic_kerne",
              "published": "2026-01-13",
              "snippet": "Semantic Kernel announced official support for Semantic Kernel Edge..."
            },
            {
              "docId": "2026-01-22_the_gradient_9929",
              "url": "https://thegradient.pub/2026/01/22/semantic_kernel_semantic_kerne",
              "published": "2026-01-22",
              "snippet": "Semantic Kernel now supports Semantic Kernel Edge with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_pro_claude_opus_45_evaluated_on",
          "source": "paper:llm_agents:_a_survey_pro",
          "target": "model:claude_opus_45",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:copilot_ultra_llama_4_integrates_with",
          "source": "tool:copilot_ultra",
          "target": "model:llama_4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.76,
          "evidence": [
            {
              "docId": "2026-01-16_openai_blog_8401",
              "url": "https://openai.com/blog/2026/01/16/copilot_ultra_llama_4",
              "published": "2026-01-16",
              "snippet": "Copilot Ultra announced official support for Llama 4..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamaindex_command_r_plus_ultra_integrates_with",
          "source": "tool:llamaindex",
          "target": "model:command_r_plus_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.8,
          "evidence": [
            {
              "docId": "2026-01-17_techcrunch_8575",
              "url": "https://techcrunch.com/2026/01/17/llamaindex_command_r_plus_ultr",
              "published": "2026-01-17",
              "snippet": "LlamaIndex now supports Command R+ Ultra with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mt_bench_v2_claude_sonnet_4_measures",
          "source": "benchmark:mt_bench_v2",
          "target": "model:claude_sonnet_4",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-17_google_ai_blog_2109",
              "url": "https://blog.google/technology/ai/2026/01/17/mt_bench_v2_claude_sonnet_4",
              "published": "2026-01-17",
              "snippet": "MT-Bench v2 provides standardized evaluation of Claude Sonnet 4..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:localai_transformer_architecture_edge_uses_tech",
          "source": "repo:localai",
          "target": "tech:transformer_architecture_edge",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:truthfulqa_codex_2_ultra_measures",
          "source": "benchmark:truthfulqa",
          "target": "model:codex_2_ultra",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.95,
          "evidence": [
            {
              "docId": "2026-01-13_ars_technica_2135",
              "url": "https://arstechnica.com/2026/01/13/truthfulqa_codex_2_ultra",
              "published": "2026-01-13",
              "snippet": "The TruthfulQA benchmark measures Codex 2 Ultra across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:tensorrt_llm_next_multimodal_fusion_plus_uses_tech",
          "source": "tool:tensorrt_llm_next",
          "target": "tech:multimodal_fusion_plus",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.62,
          "evidence": [
            {
              "docId": "2026-01-17_venturebeat_6987",
              "url": "https://venturebeat.com/2026/01/17/tensorrt_llm_next_multimodal_f",
              "published": "2026-01-17",
              "snippet": "Under the hood, TensorRT-LLM Next implements Multimodal Fusion Plus for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:localai_next_claude_sonnet_4_integrates_with",
          "source": "tool:localai_next",
          "target": "model:claude_sonnet_4",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.91
        }
      },
      {
        "data": {
          "id": "e:vllm_edge_sparse_attention_uses_tech",
          "source": "tool:vllm_edge",
          "target": "tech:sparse_attention",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:dify_ultra_command_r_plus_ultra_integrates_with",
          "source": "tool:dify_ultra",
          "target": "model:command_r_plus_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-25_microsoft_resea_9642",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/25/dify_ultra_command_r_plus_ultr",
              "published": "2026-01-25",
              "snippet": "The latest release of Dify Ultra adds native Command R+ Ultra integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:phi_4_ultra_the_stack_v2_ultra_trained_on",
          "source": "model:phi_4_ultra",
          "target": "dataset:the_stack_v2_ultra",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.69
        }
      },
      {
        "data": {
          "id": "e:yi_large_lite_constitutional_ai_mini_uses_tech",
          "source": "model:yi_large_lite",
          "target": "tech:constitutional_ai_mini",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.81
        }
      },
      {
        "data": {
          "id": "e:gradio_synthetic_data_generation_uses_tech",
          "source": "tool:gradio",
          "target": "tech:synthetic_data_generation",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-04_bloomberg_4808",
              "url": "https://bloomberg.com/technology/2026/01/04/gradio_synthetic_data_generati",
              "published": "2026-01-04",
              "snippet": "Technical details reveal Gradio relies heavily on Synthetic Data Generation..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:dolma_dpo_uses_tech",
          "source": "dataset:dolma",
          "target": "tech:dpo",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.73
        }
      },
      {
        "data": {
          "id": "e:starcoder_data_pro_tree_of_thought_lite_uses_tech",
          "source": "dataset:starcoder_data_pro",
          "target": "tech:tree_of_thought_lite",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.72
        }
      },
      {
        "data": {
          "id": "e:open_interpreter_distillation_uses_tech",
          "source": "repo:open_interpreter",
          "target": "tech:distillation",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.85
        }
      },
      {
        "data": {
          "id": "e:tree_of_thoughts:_deliberate_problem_sol_rlhf_mini_uses_tech",
          "source": "paper:tree_of_thoughts:_deliberate_problem_sol",
          "target": "tech:rlhf_mini",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2025-12-27_the_verge_6876",
              "url": "https://theverge.com/2025/12/27/tree_of_thoughts:_deliberate_p",
              "published": "2025-12-27",
              "snippet": "Technical details reveal Tree of Thoughts: Deliberate Problem Solving with LLMs relies heavily on RLHF Mini..."
            },
            {
              "docId": "2026-01-22_arxiv_6639",
              "url": "https://arxiv.org/abs/2026/01/22/tree_of_thoughts:_deliberate_p",
              "published": "2026-01-22",
              "snippet": "Tree of Thoughts: Deliberate Problem Solving with LLMs leverages RLHF Mini to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:chain_of_thought_prompting_elicits_reaso_llama_4_evaluated_on",
          "source": "paper:chain_of_thought_prompting_elicits_reaso",
          "target": "model:llama_4",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.82,
          "evidence": [
            {
              "docId": "2026-01-08_openai_blog_8488",
              "url": "https://openai.com/blog/2026/01/08/chain_of_thought_prompting_eli",
              "published": "2026-01-08",
              "snippet": "On the Llama 4 benchmark, Chain-of-Thought Prompting Elicits Reasoning scored 81%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:tree_of_thoughts:_deliberate_problem_sol_dpo_lite_uses_tech",
          "source": "paper:tree_of_thoughts:_deliberate_problem_sol",
          "target": "tech:dpo_lite",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2025-12-15_arxiv_2887",
              "url": "https://arxiv.org/abs/2025/12/15/tree_of_thoughts:_deliberate_p",
              "published": "2025-12-15",
              "snippet": "Tree of Thoughts: Deliberate Problem Solving with LLMs leverages DPO Lite to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-16_the_gradient_8403",
              "url": "https://thegradient.pub/2026/01/16/tree_of_thoughts:_deliberate_p",
              "published": "2026-01-16",
              "snippet": "Technical details reveal Tree of Thoughts: Deliberate Problem Solving with LLMs relies heavily on DPO Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:haystack_mini_crewai_integrates_with",
          "source": "tool:haystack_mini",
          "target": "tool:crewai",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-03_nvidia_blog_3199",
              "url": "https://blogs.nvidia.com/2026/01/03/haystack_mini_crewai",
              "published": "2026-01-03",
              "snippet": "The latest release of Haystack Mini adds native CrewAI integration..."
            },
            {
              "docId": "2026-01-03_arxiv_7365",
              "url": "https://arxiv.org/abs/2026/01/03/haystack_mini_crewai",
              "published": "2026-01-03",
              "snippet": "Haystack Mini now supports CrewAI with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gemma_3_lite_bigbench_hard_evaluated_on",
          "source": "model:gemma_3_lite",
          "target": "benchmark:bigbench_hard",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-08_anthropic_blog_6545",
              "url": "https://anthropic.com/news/2026/01/08/gemma_3_lite_bigbench_hard",
              "published": "2026-01-08",
              "snippet": "Gemma 3 Lite achieves 84% on BigBench Hard, setting a new record..."
            },
            {
              "docId": "2026-01-11_wired_1567",
              "url": "https://wired.com/2026/01/11/gemma_3_lite_bigbench_hard",
              "published": "2026-01-11",
              "snippet": "Gemma 3 Lite achieves 78% on BigBench Hard, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:weights_and_biases_tool_use_v2_uses_tech",
          "source": "tool:weights_and_biases",
          "target": "tech:tool_use_v2",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.7
        }
      },
      {
        "data": {
          "id": "e:roots_core_quantization_plus_uses_tech",
          "source": "dataset:roots_core",
          "target": "tech:quantization_plus",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.55
        }
      },
      {
        "data": {
          "id": "e:haystack_mini_flash_attention_core_uses_tech",
          "source": "tool:haystack_mini",
          "target": "tech:flash_attention_core",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.75
        }
      },
      {
        "data": {
          "id": "e:phi_4_ultra_gguf_uses_tech",
          "source": "model:phi_4_ultra",
          "target": "tech:gguf",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.84
        }
      },
      {
        "data": {
          "id": "e:llama_4_max_gpqa_evaluated_on",
          "source": "model:llama_4_max",
          "target": "benchmark:gpqa",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.86,
          "evidence": [
            {
              "docId": "2026-01-20_mit_technology__9550",
              "url": "https://technologyreview.com/2026/01/20/llama_4_max_gpqa",
              "published": "2026-01-20",
              "snippet": "Evaluation results show Llama 4 Max reaching 77% on GPQA..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_max_stable_diffusion_4_mini_depends_on",
          "source": "model:claude_opus_45_max",
          "target": "model:stable_diffusion_4_mini",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.6
        }
      },
      {
        "data": {
          "id": "e:self_play_fine_tuning_for_language_model_jamba_2_edge_evaluated_on",
          "source": "paper:self_play_fine_tuning_for_language_model",
          "target": "model:jamba_2_edge",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:palm_3_max_slimpajama_edge_trained_on",
          "source": "model:palm_3_max",
          "target": "dataset:slimpajama_edge",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.45
        }
      },
      {
        "data": {
          "id": "e:llamaindex_midjourney_v7_plus_integrates_with",
          "source": "tool:llamaindex",
          "target": "model:midjourney_v7_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-17_meta_ai_blog_7023",
              "url": "https://ai.meta.com/blog/2026/01/17/llamaindex_midjourney_v7_plus",
              "published": "2026-01-17",
              "snippet": "LlamaIndex now supports Midjourney V7 Plus with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:arc_agi_gemini_ultra_2_measures",
          "source": "benchmark:arc_agi",
          "target": "model:gemini_ultra_2",
          "rel": "MEASURES",
          "kind": "inferred",
          "confidence": 0.92
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_pro_gemma_3_evaluated_on",
          "source": "paper:llm_agents:_a_survey_pro",
          "target": "model:gemma_3",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.72,
          "evidence": [
            {
              "docId": "2026-01-16_the_gradient_4103",
              "url": "https://thegradient.pub/2026/01/16/llm_agents:_a_survey_pro_gemma",
              "published": "2026-01-16",
              "snippet": "Evaluation results show LLM Agents: A Survey Pro reaching 95% on Gemma 3..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:claude_sonnet_4_edge_group_query_attention_v2_uses_tech",
          "source": "model:claude_sonnet_4_edge",
          "target": "tech:group_query_attention_v2",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.67
        }
      },
      {
        "data": {
          "id": "e:c4_kv_cache_optimization_next_uses_tech",
          "source": "dataset:c4",
          "target": "tech:kv_cache_optimization_next",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.46
        }
      },
      {
        "data": {
          "id": "e:lora:_low_rank_adaptation_of_large_langu_nemotron_5_evaluated_on",
          "source": "paper:lora:_low_rank_adaptation_of_large_langu",
          "target": "model:nemotron_5",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-15_anthropic_blog_6057",
              "url": "https://anthropic.com/news/2026/01/15/lora:_low_rank_adaptation_of_l",
              "published": "2026-01-15",
              "snippet": "Evaluation results show LoRA: Low-Rank Adaptation of Large Language Models reaching 85% on Nemotron-5..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_edge_nemotron_5_ultra_depends_on",
          "source": "model:dall_e_4_edge",
          "target": "model:nemotron_5_ultra",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.53
        }
      },
      {
        "data": {
          "id": "e:langchain_plus_whisper_v4_max_integrates_with",
          "source": "tool:langchain_plus",
          "target": "model:whisper_v4_max",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.86,
          "evidence": [
            {
              "docId": "2026-01-17_weights_and_bia_5405",
              "url": "https://wandb.ai/articles/2026/01/17/langchain_plus_whisper_v4_max",
              "published": "2026-01-17",
              "snippet": "The latest release of LangChain Plus adds native Whisper v4 Max integration..."
            },
            {
              "docId": "2026-01-23_the_verge_9909",
              "url": "https://theverge.com/2026/01/23/langchain_plus_whisper_v4_max",
              "published": "2026-01-23",
              "snippet": "LangChain Plus now supports Whisper v4 Max with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:aya_3_v2_the_stack_v2_ultra_trained_on",
          "source": "model:aya_3_v2",
          "target": "dataset:the_stack_v2_ultra",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.75
        }
      },
      {
        "data": {
          "id": "e:truthfulqa_plus_qwen_3_next_measures",
          "source": "benchmark:truthfulqa_plus",
          "target": "model:qwen_3_next",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-05_langchain_blog_2283",
              "url": "https://blog.langchain.dev/2026/01/05/truthfulqa_plus_qwen_3_next",
              "published": "2026-01-05",
              "snippet": "TruthfulQA Plus provides standardized evaluation of Qwen-3 Next..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt4all_sparse_attention_lite_uses_tech",
          "source": "repo:gpt4all",
          "target": "tech:sparse_attention_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:mixtral_8x22b_gemma_3_lite_depends_on",
          "source": "model:mixtral_8x22b",
          "target": "model:gemma_3_lite",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.54
        }
      },
      {
        "data": {
          "id": "e:sora_2_max_refinedweb_trained_on",
          "source": "model:sora_2_max",
          "target": "dataset:refinedweb",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.59
        }
      },
      {
        "data": {
          "id": "e:gemini_ultra_2_edge_mixture_of_experts_uses_tech",
          "source": "model:gemini_ultra_2_edge",
          "target": "tech:mixture_of_experts",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.83
        }
      },
      {
        "data": {
          "id": "e:truthfulqa_gpt_5_measures",
          "source": "benchmark:truthfulqa",
          "target": "model:gpt_5",
          "rel": "MEASURES",
          "kind": "inferred",
          "confidence": 0.96
        }
      },
      {
        "data": {
          "id": "e:dify_ultra_semantic_kernel_mini_integrates_with",
          "source": "tool:dify_ultra",
          "target": "tool:semantic_kernel_mini",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.58
        }
      },
      {
        "data": {
          "id": "e:nemotron_5_refinedweb_ultra_trained_on",
          "source": "model:nemotron_5",
          "target": "dataset:refinedweb_ultra",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.74
        }
      },
      {
        "data": {
          "id": "e:hellaswag_aya_3_measures",
          "source": "benchmark:hellaswag",
          "target": "model:aya_3",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.8,
          "evidence": [
            {
              "docId": "2026-01-22_venturebeat_6137",
              "url": "https://venturebeat.com/2026/01/22/hellaswag_aya_3",
              "published": "2026-01-22",
              "snippet": "HellaSwag has become the standard for evaluating Aya 3..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_next_sparse_attention_lite_uses_tech",
          "source": "model:llama_4_next",
          "target": "tech:sparse_attention_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:toolformer:_language_models_can_teach_th_claude_opus_45_evaluated_on",
          "source": "paper:toolformer:_language_models_can_teach_th",
          "target": "model:claude_opus_45",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.9
        }
      },
      {
        "data": {
          "id": "e:phi_4_lite_grok_3_ultra_depends_on",
          "source": "model:phi_4_lite",
          "target": "model:grok_3_ultra",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.72
        }
      },
      {
        "data": {
          "id": "e:falcon_3_grok_3_depends_on",
          "source": "model:falcon_3",
          "target": "model:grok_3",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.64
        }
      },
      {
        "data": {
          "id": "e:refinedweb_ultra_sliding_window_attention_uses_tech",
          "source": "dataset:refinedweb_ultra",
          "target": "tech:sliding_window_attention",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:palm_3_max_truthfulqa_plus_evaluated_on",
          "source": "model:palm_3_max",
          "target": "benchmark:truthfulqa_plus",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-20_microsoft_resea_1252",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/20/palm_3_max_truthfulqa_plus",
              "published": "2026-01-20",
              "snippet": "On the TruthfulQA Plus benchmark, PaLM 3 Max scored 75%..."
            },
            {
              "docId": "2026-01-22_nextgov_7796",
              "url": "https://nextgov.com/2026/01/22/palm_3_max_truthfulqa_plus",
              "published": "2026-01-22",
              "snippet": "Evaluation results show PaLM 3 Max reaching 88% on TruthfulQA Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:textbooks_are_all_you_need_qwen_3_evaluated_on",
          "source": "paper:textbooks_are_all_you_need",
          "target": "model:qwen_3",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.7
        }
      },
      {
        "data": {
          "id": "e:tensorrt_llm_claude_sonnet_4_edge_integrates_with",
          "source": "tool:tensorrt_llm",
          "target": "model:claude_sonnet_4_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.75,
          "evidence": [
            {
              "docId": "2025-12-31_the_gradient_9991",
              "url": "https://thegradient.pub/2025/12/31/tensorrt_llm_claude_sonnet_4_e",
              "published": "2025-12-31",
              "snippet": "TensorRT-LLM announced official support for Claude Sonnet 4 Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:localai_qlora_uses_tech",
          "source": "repo:localai",
          "target": "tech:qlora",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.86,
          "evidence": [
            {
              "docId": "2026-01-07_anthropic_blog_3423",
              "url": "https://anthropic.com/news/2026/01/07/localai_qlora",
              "published": "2026-01-07",
              "snippet": "LocalAI leverages QLoRA to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-14_arxiv_6261",
              "url": "https://arxiv.org/abs/2026/01/14/localai_qlora",
              "published": "2026-01-14",
              "snippet": "Under the hood, LocalAI implements QLoRA for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:nemotron_5_sparse_attention_uses_tech",
          "source": "model:nemotron_5",
          "target": "tech:sparse_attention",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.86
        }
      },
      {
        "data": {
          "id": "e:haystack_langchain_integrates_with",
          "source": "tool:haystack",
          "target": "tool:langchain",
          "rel": "INTEGRATES_WITH",
          "kind": "hypothesis",
          "confidence": 0.81
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_c4_trained_on",
          "source": "model:claude_opus_45",
          "target": "dataset:c4",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.82,
          "evidence": [
            {
              "docId": "2026-01-21_techcrunch_1876",
              "url": "https://techcrunch.com/2026/01/21/claude_opus_45_c4",
              "published": "2026-01-21",
              "snippet": "Claude Opus 4.5 was trained on C4 comprising billions of tokens..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:phi_4_ultra_qlora_pro_uses_tech",
          "source": "model:phi_4_ultra",
          "target": "tech:qlora_pro",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.65
        }
      },
      {
        "data": {
          "id": "e:text_generation_webui_deepseek_v3_plus_integrates_with",
          "source": "repo:text_generation_webui",
          "target": "model:deepseek_v3_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.7,
          "evidence": [
            {
              "docId": "2026-01-25_wired_5328",
              "url": "https://wired.com/2026/01/25/text_generation_webui_deepseek",
              "published": "2026-01-25",
              "snippet": "text-generation-webui now supports DeepSeek-V3 Plus with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:localai_transformer_architecture_uses_tech",
          "source": "repo:localai",
          "target": "tech:transformer_architecture",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-15_langchain_blog_2207",
              "url": "https://blog.langchain.dev/2026/01/15/localai_transformer_architectu",
              "published": "2026-01-15",
              "snippet": "LocalAI leverages Transformer Architecture to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-24_mit_technology__6415",
              "url": "https://technologyreview.com/2026/01/24/localai_transformer_architectu",
              "published": "2026-01-24",
              "snippet": "LocalAI leverages Transformer Architecture to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:midjourney_v7_edge_wikipedia_dump_2025_trained_on",
          "source": "model:midjourney_v7_edge",
          "target": "dataset:wikipedia_dump_2025",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-09_venturebeat_5462",
              "url": "https://venturebeat.com/2026/01/09/midjourney_v7_edge_wikipedia_d",
              "published": "2026-01-09",
              "snippet": "The training corpus for Midjourney V7 Edge includes Wikipedia Dump 2025..."
            },
            {
              "docId": "2026-01-22_google_ai_blog_8163",
              "url": "https://blog.google/technology/ai/2026/01/22/midjourney_v7_edge_wikipedia_d",
              "published": "2026-01-22",
              "snippet": "The training corpus for Midjourney V7 Edge includes Wikipedia Dump 2025..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_ultra_rlhf_uses_tech",
          "source": "paper:direct_preference_optimization_ultra",
          "target": "tech:rlhf",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.77,
          "evidence": [
            {
              "docId": "2026-01-07_the_gradient_2341",
              "url": "https://thegradient.pub/2026/01/07/direct_preference_optimization",
              "published": "2026-01-07",
              "snippet": "Under the hood, Direct Preference Optimization Ultra implements RLHF for improved efficiency..."
            },
            {
              "docId": "2026-01-24_mit_technology__8691",
              "url": "https://technologyreview.com/2026/01/24/direct_preference_optimization",
              "published": "2026-01-24",
              "snippet": "Direct Preference Optimization Ultra leverages RLHF to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:vllm_edge_lora_uses_tech",
          "source": "tool:vllm_edge",
          "target": "tech:lora",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.75
        }
      },
      {
        "data": {
          "id": "e:phi_4_lite_arc_agi_evaluated_on",
          "source": "model:phi_4_lite",
          "target": "benchmark:arc_agi",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2026-01-25_techcrunch_5588",
              "url": "https://techcrunch.com/2026/01/25/phi_4_lite_arc_agi",
              "published": "2026-01-25",
              "snippet": "Evaluation results show Phi-4 Lite reaching 93% on ARC-AGI..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:openwebtext2_transformer_architecture_pro_uses_tech",
          "source": "dataset:openwebtext2",
          "target": "tech:transformer_architecture_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.42
        }
      },
      {
        "data": {
          "id": "e:scaling_data_constrained_language_models_quantization_plus_uses_tech",
          "source": "paper:scaling_data_constrained_language_models",
          "target": "tech:quantization_plus",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-25_microsoft_resea_2566",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/25/scaling_data_constrained_langu",
              "published": "2026-01-25",
              "snippet": "Under the hood, Scaling Data-Constrained Language Models implements Quantization Plus for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:tensorrt_llm_next_mlflow_integrates_with",
          "source": "tool:tensorrt_llm_next",
          "target": "tool:mlflow",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.59,
          "evidence": [
            {
              "docId": "2026-01-25_nextgov_1010",
              "url": "https://nextgov.com/2026/01/25/tensorrt_llm_next_mlflow",
              "published": "2026-01-25",
              "snippet": "TensorRT-LLM Next announced official support for MLflow..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:falcon_3_distillation_uses_tech",
          "source": "model:falcon_3",
          "target": "tech:distillation",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.74
        }
      },
      {
        "data": {
          "id": "e:flowise_gradio_max_integrates_with",
          "source": "tool:flowise",
          "target": "tool:gradio_max",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.68,
          "evidence": [
            {
              "docId": "2026-01-25_bloomberg_9239",
              "url": "https://bloomberg.com/technology/2026/01/25/flowise_gradio_max",
              "published": "2026-01-25",
              "snippet": "The latest release of Flowise adds native Gradio Max integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_next_starcoder_data_pro_trained_on",
          "source": "model:llama_4_next",
          "target": "dataset:starcoder_data_pro",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.66,
          "evidence": [
            {
              "docId": "2026-01-25_microsoft_resea_4609",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/25/llama_4_next_starcoder_data_pr",
              "published": "2026-01-25",
              "snippet": "Llama 4 Next was trained on StarCoder Data Pro comprising billions of tokens..."
            },
            {
              "docId": "2026-01-25_bloomberg_1757",
              "url": "https://bloomberg.com/technology/2026/01/25/llama_4_next_starcoder_data_pr",
              "published": "2026-01-25",
              "snippet": "The training corpus for Llama 4 Next includes StarCoder Data Pro..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:haystack_dall_e_4_edge_integrates_with",
          "source": "tool:haystack",
          "target": "model:dall_e_4_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2026-01-24_the_gradient_7796",
              "url": "https://thegradient.pub/2026/01/24/haystack_dall_e_4_edge",
              "published": "2026-01-24",
              "snippet": "The latest release of Haystack adds native DALL-E 4 Edge integration..."
            },
            {
              "docId": "2026-01-24_the_verge_1715",
              "url": "https://theverge.com/2026/01/24/haystack_dall_e_4_edge",
              "published": "2026-01-24",
              "snippet": "Haystack announced official support for DALL-E 4 Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gemma_3_v2_arc_agi_evaluated_on",
          "source": "model:gemma_3_v2",
          "target": "benchmark:arc_agi",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-20_langchain_blog_3278",
              "url": "https://blog.langchain.dev/2026/01/20/gemma_3_v2_arc_agi",
              "published": "2026-01-20",
              "snippet": "Gemma 3 v2 achieves 98% on ARC-AGI, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:autogpt_falcon_3_integrates_with",
          "source": "repo:autogpt",
          "target": "model:falcon_3",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:toolformer:_language_models_can_teach_th_rotary_position_embedding_uses_tech",
          "source": "paper:toolformer:_language_models_can_teach_th",
          "target": "tech:rotary_position_embedding",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2026-01-08_hugging_face_bl_7036",
              "url": "https://huggingface.co/blog/2026/01/08/toolformer:_language_models_ca",
              "published": "2026-01-08",
              "snippet": "Technical details reveal Toolformer: Language Models Can Teach Themselves to Use Tools relies heavily on Rotary Position Embedding..."
            },
            {
              "docId": "2026-01-18_hugging_face_bl_7059",
              "url": "https://huggingface.co/blog/2026/01/18/toolformer:_language_models_ca",
              "published": "2026-01-18",
              "snippet": "Toolformer: Language Models Can Teach Themselves to Use Tools leverages Rotary Position Embedding to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-22_reuters_3887",
              "url": "https://reuters.com/technology/2026/01/22/toolformer:_language_models_ca",
              "published": "2026-01-22",
              "snippet": "Technical details reveal Toolformer: Language Models Can Teach Themselves to Use Tools relies heavily on Rotary Position Embedding..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_lite_dall_e_4_edge_integrates_with",
          "source": "repo:langchain_lite",
          "target": "model:dall_e_4_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-21_wired_8460",
              "url": "https://wired.com/2026/01/21/langchain_lite_dall_e_4_edge",
              "published": "2026-01-21",
              "snippet": "The latest release of langchain Lite adds native DALL-E 4 Edge integration..."
            },
            {
              "docId": "2026-01-24_techcrunch_9231",
              "url": "https://techcrunch.com/2026/01/24/langchain_lite_dall_e_4_edge",
              "published": "2026-01-24",
              "snippet": "langchain Lite announced official support for DALL-E 4 Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:transformers_next_claude_sonnet_4_edge_integrates_with",
          "source": "repo:transformers_next",
          "target": "model:claude_sonnet_4_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.78,
          "evidence": [
            {
              "docId": "2026-01-24_microsoft_resea_3202",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/24/transformers_next_claude_sonne",
              "published": "2026-01-24",
              "snippet": "The latest release of transformers Next adds native Claude Sonnet 4 Edge integration..."
            },
            {
              "docId": "2026-01-25_nvidia_blog_4059",
              "url": "https://blogs.nvidia.com/2026/01/25/transformers_next_claude_sonne",
              "published": "2026-01-25",
              "snippet": "transformers Next now supports Claude Sonnet 4 Edge with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:chain_of_thought_prompting_elicits_reaso_rotary_position_embedding_uses_tech",
          "source": "paper:chain_of_thought_prompting_elicits_reaso",
          "target": "tech:rotary_position_embedding",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.86,
          "evidence": [
            {
              "docId": "2026-01-08_anthropic_blog_2668",
              "url": "https://anthropic.com/news/2026/01/08/chain_of_thought_prompting_eli",
              "published": "2026-01-08",
              "snippet": "Chain-of-Thought Prompting Elicits Reasoning leverages Rotary Position Embedding to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-16_nextgov_3168",
              "url": "https://nextgov.com/2026/01/16/chain_of_thought_prompting_eli",
              "published": "2026-01-16",
              "snippet": "Chain-of-Thought Prompting Elicits Reasoning leverages Rotary Position Embedding to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-19_hugging_face_bl_1946",
              "url": "https://huggingface.co/blog/2026/01/19/chain_of_thought_prompting_eli",
              "published": "2026-01-19",
              "snippet": "Under the hood, Chain-of-Thought Prompting Elicits Reasoning implements Rotary Position Embedding for improved efficiency..."
            },
            {
              "docId": "2026-01-22_techcrunch_7920",
              "url": "https://techcrunch.com/2026/01/22/chain_of_thought_prompting_eli",
              "published": "2026-01-22",
              "snippet": "Chain-of-Thought Prompting Elicits Reasoning leverages Rotary Position Embedding to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:whisper_v4_max_speculative_decoding_uses_tech",
          "source": "model:whisper_v4_max",
          "target": "tech:speculative_decoding",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.57
        }
      },
      {
        "data": {
          "id": "e:math_deepseek_v3_plus_measures",
          "source": "benchmark:math",
          "target": "model:deepseek_v3_plus",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2026-01-21_wired_7193",
              "url": "https://wired.com/2026/01/21/math_deepseek_v3_plus",
              "published": "2026-01-21",
              "snippet": "The MATH benchmark measures DeepSeek-V3 Plus across multiple tasks..."
            },
            {
              "docId": "2026-01-22_the_verge_4912",
              "url": "https://theverge.com/2026/01/22/math_deepseek_v3_plus",
              "published": "2026-01-22",
              "snippet": "MATH provides standardized evaluation of DeepSeek-V3 Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_falcon_3_integrates_with",
          "source": "repo:langchain",
          "target": "model:falcon_3",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.75,
          "evidence": [
            {
              "docId": "2026-01-25_microsoft_resea_3457",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/25/langchain_falcon_3",
              "published": "2026-01-25",
              "snippet": "The latest release of langchain adds native Falcon 3 integration..."
            },
            {
              "docId": "2026-01-25_meta_ai_blog_1227",
              "url": "https://ai.meta.com/blog/2026/01/25/langchain_falcon_3",
              "published": "2026-01-25",
              "snippet": "langchain announced official support for Falcon 3..."
            },
            {
              "docId": "2026-01-25_google_ai_blog_3877",
              "url": "https://blog.google/technology/ai/2026/01/25/langchain_falcon_3",
              "published": "2026-01-25",
              "snippet": "langchain announced official support for Falcon 3..."
            },
            {
              "docId": "2026-01-25_nvidia_blog_2885",
              "url": "https://blogs.nvidia.com/2026/01/25/langchain_falcon_3",
              "published": "2026-01-25",
              "snippet": "The latest release of langchain adds native Falcon 3 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:transformers_qwen_3_ultra_integrates_with",
          "source": "repo:transformers",
          "target": "model:qwen_3_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2026-01-19_langchain_blog_6133",
              "url": "https://blog.langchain.dev/2026/01/19/transformers_qwen_3_ultra",
              "published": "2026-01-19",
              "snippet": "transformers announced official support for Qwen-3 Ultra..."
            },
            {
              "docId": "2026-01-21_mit_technology__6181",
              "url": "https://technologyreview.com/2026/01/21/transformers_qwen_3_ultra",
              "published": "2026-01-21",
              "snippet": "transformers now supports Qwen-3 Ultra with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:crewai_core_litellm_integrates_with",
          "source": "tool:crewai_core",
          "target": "tool:litellm",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-24_hugging_face_bl_2569",
              "url": "https://huggingface.co/blog/2026/01/24/crewai_core_litellm",
              "published": "2026-01-24",
              "snippet": "CrewAI Core now supports LiteLLM with full feature parity..."
            },
            {
              "docId": "2026-01-24_the_gradient_5056",
              "url": "https://thegradient.pub/2026/01/24/crewai_core_litellm",
              "published": "2026-01-24",
              "snippet": "CrewAI Core announced official support for LiteLLM..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:textbooks_are_all_you_need_yi_large_evaluated_on",
          "source": "paper:textbooks_are_all_you_need",
          "target": "model:yi_large",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-25_the_verge_3521",
              "url": "https://theverge.com/2026/01/25/textbooks_are_all_you_need_yi_",
              "published": "2026-01-25",
              "snippet": "On the Yi-Large benchmark, Textbooks Are All You Need scored 90%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:the_stack_v2_rotary_position_embedding_uses_tech",
          "source": "dataset:the_stack_v2",
          "target": "tech:rotary_position_embedding",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:chain_of_thought_prompting_elicits_reaso_command_r_plus_plus_evaluated_on",
          "source": "paper:chain_of_thought_prompting_elicits_reaso",
          "target": "model:command_r_plus_plus",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.72,
          "evidence": [
            {
              "docId": "2026-01-12_anthropic_blog_4470",
              "url": "https://anthropic.com/news/2026/01/12/chain_of_thought_prompting_eli",
              "published": "2026-01-12",
              "snippet": "Evaluation results show Chain-of-Thought Prompting Elicits Reasoning reaching 75% on Command R+ Plus..."
            },
            {
              "docId": "2026-01-20_weights_and_bia_4732",
              "url": "https://wandb.ai/articles/2026/01/20/chain_of_thought_prompting_eli",
              "published": "2026-01-20",
              "snippet": "Evaluation results show Chain-of-Thought Prompting Elicits Reasoning reaching 88% on Command R+ Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:redpajama_v2_v2_sparse_attention_lite_uses_tech",
          "source": "dataset:redpajama_v2_v2",
          "target": "tech:sparse_attention_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:lora:_low_rank_adaptation_of_large_langu_midjourney_v7_evaluated_on",
          "source": "paper:lora:_low_rank_adaptation_of_large_langu",
          "target": "model:midjourney_v7",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.86,
          "evidence": [
            {
              "docId": "2026-01-03_openai_blog_5461",
              "url": "https://openai.com/blog/2026/01/03/lora:_low_rank_adaptation_of_l",
              "published": "2026-01-03",
              "snippet": "On the Midjourney V7 benchmark, LoRA: Low-Rank Adaptation of Large Language Models scored 92%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:transformers_chain_of_thought_uses_tech",
          "source": "repo:transformers",
          "target": "tech:chain_of_thought",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.7
        }
      },
      {
        "data": {
          "id": "e:gemma_3_lite_starcoder_data_pro_trained_on",
          "source": "model:gemma_3_lite",
          "target": "dataset:starcoder_data_pro",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.72,
          "evidence": [
            {
              "docId": "2026-01-12_the_verge_6918",
              "url": "https://theverge.com/2026/01/12/gemma_3_lite_starcoder_data_pr",
              "published": "2026-01-12",
              "snippet": "The training corpus for Gemma 3 Lite includes StarCoder Data Pro..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_lite_claude_opus_45_edge_integrates_with",
          "source": "repo:langchain_lite",
          "target": "model:claude_opus_45_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.88
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_deepseek_v3_plus_evaluated_on",
          "source": "paper:llm_agents:_a_survey",
          "target": "model:deepseek_v3_plus",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.73,
          "evidence": [
            {
              "docId": "2026-01-01_the_gradient_2045",
              "url": "https://thegradient.pub/2026/01/01/llm_agents:_a_survey_deepseek_",
              "published": "2026-01-01",
              "snippet": "Evaluation results show LLM Agents: A Survey reaching 98% on DeepSeek-V3 Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gemini_ultra_2_edge_qlora_pro_uses_tech",
          "source": "model:gemini_ultra_2_edge",
          "target": "tech:qlora_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.9
        }
      },
      {
        "data": {
          "id": "e:gpt4all_retrieval_augmented_generation_uses_tech",
          "source": "repo:gpt4all",
          "target": "tech:retrieval_augmented_generation",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.7,
          "evidence": [
            {
              "docId": "2026-01-25_the_verge_8212",
              "url": "https://theverge.com/2026/01/25/gpt4all_retrieval_augmented_ge",
              "published": "2026-01-25",
              "snippet": "Under the hood, gpt4all implements Retrieval-Augmented Generation for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:aya_3_edge_the_stack_v2_trained_on",
          "source": "model:aya_3_edge",
          "target": "dataset:the_stack_v2",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.61,
          "evidence": [
            {
              "docId": "2026-01-11_the_verge_9880",
              "url": "https://theverge.com/2026/01/11/aya_3_edge_the_stack_v2",
              "published": "2026-01-11",
              "snippet": "Aya 3 Edge utilized The Stack v2 as part of its pre-training data mix..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:grok_3_plus_gpt_5_mini_depends_on",
          "source": "model:grok_3_plus",
          "target": "model:gpt_5_mini",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.61
        }
      },
      {
        "data": {
          "id": "e:localai_semantic_kernel_edge_integrates_with",
          "source": "tool:localai",
          "target": "tool:semantic_kernel_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.63,
          "evidence": [
            {
              "docId": "2025-12-06_hugging_face_bl_1314",
              "url": "https://huggingface.co/blog/2025/12/06/localai_semantic_kernel_edge",
              "published": "2025-12-06",
              "snippet": "LocalAI announced official support for Semantic Kernel Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_edge_bigbench_hard_evaluated_on",
          "source": "model:dall_e_4_edge",
          "target": "benchmark:bigbench_hard",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2025-12-21_reuters_6379",
              "url": "https://reuters.com/technology/2025/12/21/dall_e_4_edge_bigbench_hard",
              "published": "2025-12-21",
              "snippet": "DALL-E 4 Edge achieves 96% on BigBench Hard, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_v2_the_stack_v2_ultra_trained_on",
          "source": "model:palm_3_v2",
          "target": "dataset:the_stack_v2_ultra",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:the_pile_core_dpo_uses_tech",
          "source": "dataset:the_pile_core",
          "target": "tech:dpo",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.43
        }
      },
      {
        "data": {
          "id": "e:langchain_lite_claude_opus_45_pro_integrates_with",
          "source": "repo:langchain_lite",
          "target": "model:claude_opus_45_pro",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.87
        }
      },
      {
        "data": {
          "id": "e:roots_flash_attention_core_uses_tech",
          "source": "dataset:roots",
          "target": "tech:flash_attention_core",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:langchain_whisper_v4_integrates_with",
          "source": "tool:langchain",
          "target": "model:whisper_v4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-24_openai_blog_3812",
              "url": "https://openai.com/blog/2026/01/24/langchain_whisper_v4",
              "published": "2026-01-24",
              "snippet": "LangChain now supports Whisper v4 with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:grok_3_ultra_slimpajama_trained_on",
          "source": "model:grok_3_ultra",
          "target": "dataset:slimpajama",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.88
        }
      },
      {
        "data": {
          "id": "e:localai_mlflow_next_integrates_with",
          "source": "tool:localai",
          "target": "tool:mlflow_next",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.65,
          "evidence": [
            {
              "docId": "2025-12-22_langchain_blog_2566",
              "url": "https://blog.langchain.dev/2025/12/22/localai_mlflow_next",
              "published": "2025-12-22",
              "snippet": "LocalAI now supports MLflow Next with full feature parity..."
            },
            {
              "docId": "2025-12-27_venturebeat_9407",
              "url": "https://venturebeat.com/2025/12/27/localai_mlflow_next",
              "published": "2025-12-27",
              "snippet": "The latest release of LocalAI adds native MLflow Next integration..."
            },
            {
              "docId": "2026-01-22_hugging_face_bl_9345",
              "url": "https://huggingface.co/blog/2026/01/22/localai_mlflow_next",
              "published": "2026-01-22",
              "snippet": "LocalAI announced official support for MLflow Next..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:cody_codex_2_pro_integrates_with",
          "source": "tool:cody",
          "target": "model:codex_2_pro",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.95,
          "evidence": [
            {
              "docId": "2025-12-28_nvidia_blog_5255",
              "url": "https://blogs.nvidia.com/2025/12/28/cody_codex_2_pro",
              "published": "2025-12-28",
              "snippet": "Cody announced official support for Codex 2 Pro..."
            },
            {
              "docId": "2025-12-29_google_ai_blog_2604",
              "url": "https://blog.google/technology/ai/2025/12/29/cody_codex_2_pro",
              "published": "2025-12-29",
              "snippet": "Cody now supports Codex 2 Pro with full feature parity..."
            },
            {
              "docId": "2026-01-05_langchain_blog_7574",
              "url": "https://blog.langchain.dev/2026/01/05/cody_codex_2_pro",
              "published": "2026-01-05",
              "snippet": "Cody announced official support for Codex 2 Pro..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_lite_sora_2_max_integrates_with",
          "source": "repo:langchain_lite",
          "target": "model:sora_2_max",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-19_reuters_3910",
              "url": "https://reuters.com/technology/2026/01/19/langchain_lite_sora_2_max",
              "published": "2026-01-19",
              "snippet": "The latest release of langchain Lite adds native Sora 2 Max integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:haystack_dify_integrates_with",
          "source": "tool:haystack",
          "target": "tool:dify",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.8
        }
      },
      {
        "data": {
          "id": "e:gemma_3_lite_openwebtext2_trained_on",
          "source": "model:gemma_3_lite",
          "target": "dataset:openwebtext2",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.63,
          "evidence": [
            {
              "docId": "2026-01-20_google_ai_blog_8257",
              "url": "https://blog.google/technology/ai/2026/01/20/gemma_3_lite_openwebtext2",
              "published": "2026-01-20",
              "snippet": "Gemma 3 Lite utilized OpenWebText2 as part of its pre-training data mix..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamaindex_ultra_kv_cache_optimization_next_uses_tech",
          "source": "tool:llamaindex_ultra",
          "target": "tech:kv_cache_optimization_next",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-25_weights_and_bia_2175",
              "url": "https://wandb.ai/articles/2026/01/25/llamaindex_ultra_kv_cache_opti",
              "published": "2026-01-25",
              "snippet": "Technical details reveal LlamaIndex Ultra relies heavily on KV Cache Optimization Next..."
            },
            {
              "docId": "2026-01-25_mit_technology__5353",
              "url": "https://technologyreview.com/2026/01/25/llamaindex_ultra_kv_cache_opti",
              "published": "2026-01-25",
              "snippet": "Technical details reveal LlamaIndex Ultra relies heavily on KV Cache Optimization Next..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:common_crawl_plus_qlora_uses_tech",
          "source": "dataset:common_crawl_plus",
          "target": "tech:qlora",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.45
        }
      },
      {
        "data": {
          "id": "e:scaling_laws_for_neural_language_models__midjourney_v7_edge_evaluated_on",
          "source": "paper:scaling_laws_for_neural_language_models_",
          "target": "model:midjourney_v7_edge",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:streamlit_qwen_3_ultra_integrates_with",
          "source": "tool:streamlit",
          "target": "model:qwen_3_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.77,
          "evidence": [
            {
              "docId": "2026-01-16_weights_and_bia_5012",
              "url": "https://wandb.ai/articles/2026/01/16/streamlit_qwen_3_ultra",
              "published": "2026-01-16",
              "snippet": "Streamlit announced official support for Qwen-3 Ultra..."
            },
            {
              "docId": "2026-01-25_bloomberg_9970",
              "url": "https://bloomberg.com/technology/2026/01/25/streamlit_qwen_3_ultra",
              "published": "2026-01-25",
              "snippet": "Streamlit announced official support for Qwen-3 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_edge_distillation_next_uses_tech",
          "source": "model:claude_opus_45_edge",
          "target": "tech:distillation_next",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:qwen_3_ultra_stable_diffusion_4_max_depends_on",
          "source": "model:qwen_3_ultra",
          "target": "model:stable_diffusion_4_max",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.48
        }
      },
      {
        "data": {
          "id": "e:langchain_gradio_integrates_with",
          "source": "tool:langchain",
          "target": "tool:gradio",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2025-12-31_techcrunch_1388",
              "url": "https://techcrunch.com/2025/12/31/langchain_gradio",
              "published": "2025-12-31",
              "snippet": "LangChain announced official support for Gradio..."
            },
            {
              "docId": "2026-01-24_anthropic_blog_7464",
              "url": "https://anthropic.com/news/2026/01/24/langchain_gradio",
              "published": "2026-01-24",
              "snippet": "The latest release of LangChain adds native Gradio integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:codex_2_sora_2_ultra_depends_on",
          "source": "model:codex_2",
          "target": "model:sora_2_ultra",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.52
        }
      },
      {
        "data": {
          "id": "e:gpqa_next_dall_e_4_edge_measures",
          "source": "benchmark:gpqa_next",
          "target": "model:dall_e_4_edge",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2026-01-21_openai_blog_7991",
              "url": "https://openai.com/blog/2026/01/21/gpqa_next_dall_e_4_edge",
              "published": "2026-01-21",
              "snippet": "The GPQA Next benchmark measures DALL-E 4 Edge across multiple tasks..."
            },
            {
              "docId": "2026-01-21_hugging_face_bl_8719",
              "url": "https://huggingface.co/blog/2026/01/21/gpqa_next_dall_e_4_edge",
              "published": "2026-01-21",
              "snippet": "GPQA Next has become the standard for evaluating DALL-E 4 Edge..."
            },
            {
              "docId": "2026-01-21_mit_technology__6008",
              "url": "https://technologyreview.com/2026/01/21/gpqa_next_dall_e_4_edge",
              "published": "2026-01-21",
              "snippet": "GPQA Next has become the standard for evaluating DALL-E 4 Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:flash_attention:_fast_and_memory_efficie_nemotron_5_evaluated_on",
          "source": "paper:flash_attention:_fast_and_memory_efficie",
          "target": "model:nemotron_5",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-06_arxiv_3122",
              "url": "https://arxiv.org/abs/2026/01/06/flash_attention:_fast_and_memo",
              "published": "2026-01-06",
              "snippet": "On the Nemotron-5 benchmark, Flash Attention: Fast and Memory-Efficient Attention scored 81%..."
            },
            {
              "docId": "2026-01-14_mit_technology__8073",
              "url": "https://technologyreview.com/2026/01/14/flash_attention:_fast_and_memo",
              "published": "2026-01-14",
              "snippet": "On the Nemotron-5 benchmark, Flash Attention: Fast and Memory-Efficient Attention scored 80%..."
            },
            {
              "docId": "2026-01-20_nvidia_blog_9468",
              "url": "https://blogs.nvidia.com/2026/01/20/flash_attention:_fast_and_memo",
              "published": "2026-01-20",
              "snippet": "Flash Attention: Fast and Memory-Efficient Attention achieves 74% on Nemotron-5, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:autogpt_gpt_4o_mini_2_ultra_integrates_with",
          "source": "repo:autogpt",
          "target": "model:gpt_4o_mini_2_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.76,
          "evidence": [
            {
              "docId": "2026-01-14_techcrunch_1388",
              "url": "https://techcrunch.com/2026/01/14/autogpt_gpt_4o_mini_2_ultra",
              "published": "2026-01-14",
              "snippet": "AutoGPT announced official support for GPT-4o Mini 2 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_pro_mixtral_8x22b_core_evaluated_on",
          "source": "paper:llm_agents:_a_survey_pro",
          "target": "model:mixtral_8x22b_core",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-02_microsoft_resea_9106",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/02/llm_agents:_a_survey_pro_mixtr",
              "published": "2026-01-02",
              "snippet": "On the Mixtral 8x22B Core benchmark, LLM Agents: A Survey Pro scored 73%..."
            },
            {
              "docId": "2026-01-25_microsoft_resea_5682",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/25/llm_agents:_a_survey_pro_mixtr",
              "published": "2026-01-25",
              "snippet": "Evaluation results show LLM Agents: A Survey Pro reaching 98% on Mixtral 8x22B Core..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:attention_is_all_you_need_v2_v2_dall_e_4_edge_evaluated_on",
          "source": "paper:attention_is_all_you_need_v2_v2",
          "target": "model:dall_e_4_edge",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.72
        }
      },
      {
        "data": {
          "id": "e:langchain_tokenizer_bpe_uses_tech",
          "source": "tool:langchain",
          "target": "tech:tokenizer_bpe",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.81
        }
      },
      {
        "data": {
          "id": "e:litellm_edge_localai_integrates_with",
          "source": "tool:litellm_edge",
          "target": "tool:localai",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.79
        }
      },
      {
        "data": {
          "id": "e:chain_of_thought_prompting_elicits_reaso_codex_2_pro_evaluated_on",
          "source": "paper:chain_of_thought_prompting_elicits_reaso",
          "target": "model:codex_2_pro",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-14_langchain_blog_4415",
              "url": "https://blog.langchain.dev/2026/01/14/chain_of_thought_prompting_eli",
              "published": "2026-01-14",
              "snippet": "Evaluation results show Chain-of-Thought Prompting Elicits Reasoning reaching 87% on Codex 2 Pro..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt4all_jamba_2_integrates_with",
          "source": "repo:gpt4all",
          "target": "model:jamba_2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.73,
          "evidence": [
            {
              "docId": "2025-12-20_hugging_face_bl_7098",
              "url": "https://huggingface.co/blog/2025/12/20/gpt4all_jamba_2",
              "published": "2025-12-20",
              "snippet": "The latest release of gpt4all adds native Jamba 2 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:tree_of_thoughts:_deliberate_problem_sol_deepseek_v3_edge_evaluated_on",
          "source": "paper:tree_of_thoughts:_deliberate_problem_sol",
          "target": "model:deepseek_v3_edge",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.85
        }
      },
      {
        "data": {
          "id": "e:transformers_next_dpo_plus_uses_tech",
          "source": "repo:transformers_next",
          "target": "tech:dpo_plus",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.87
        }
      },
      {
        "data": {
          "id": "e:gpt4all_codex_2_ultra_integrates_with",
          "source": "repo:gpt4all",
          "target": "model:codex_2_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.77,
          "evidence": [
            {
              "docId": "2026-01-16_wired_1948",
              "url": "https://wired.com/2026/01/16/gpt4all_codex_2_ultra",
              "published": "2026-01-16",
              "snippet": "The latest release of gpt4all adds native Codex 2 Ultra integration..."
            },
            {
              "docId": "2026-01-22_ars_technica_8783",
              "url": "https://arstechnica.com/2026/01/22/gpt4all_codex_2_ultra",
              "published": "2026-01-22",
              "snippet": "The latest release of gpt4all adds native Codex 2 Ultra integration..."
            },
            {
              "docId": "2026-01-24_venturebeat_5999",
              "url": "https://venturebeat.com/2026/01/24/gpt4all_codex_2_ultra",
              "published": "2026-01-24",
              "snippet": "gpt4all announced official support for Codex 2 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:toolformer:_language_models_can_teach_th_group_query_attention_core_uses_tech",
          "source": "paper:toolformer:_language_models_can_teach_th",
          "target": "tech:group_query_attention_core",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-03_meta_ai_blog_1132",
              "url": "https://ai.meta.com/blog/2026/01/03/toolformer:_language_models_ca",
              "published": "2026-01-03",
              "snippet": "Technical details reveal Toolformer: Language Models Can Teach Themselves to Use Tools relies heavily on Group Query Attention Core..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:the_stack_v2_transformer_architecture_edge_uses_tech",
          "source": "dataset:the_stack_v2",
          "target": "tech:transformer_architecture_edge",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.48
        }
      },
      {
        "data": {
          "id": "e:mmlu_max_midjourney_v7_plus_measures",
          "source": "benchmark:mmlu_max",
          "target": "model:midjourney_v7_plus",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-24_ars_technica_9787",
              "url": "https://arstechnica.com/2026/01/24/mmlu_max_midjourney_v7_plus",
              "published": "2026-01-24",
              "snippet": "The MMLU Max benchmark measures Midjourney V7 Plus across multiple tasks..."
            },
            {
              "docId": "2026-01-25_ars_technica_7921",
              "url": "https://arstechnica.com/2026/01/25/mmlu_max_midjourney_v7_plus",
              "published": "2026-01-25",
              "snippet": "MMLU Max has become the standard for evaluating Midjourney V7 Plus..."
            },
            {
              "docId": "2026-01-25_ars_technica_2675",
              "url": "https://arstechnica.com/2026/01/25/mmlu_max_midjourney_v7_plus",
              "published": "2026-01-25",
              "snippet": "MMLU Max provides standardized evaluation of Midjourney V7 Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_sparse_attention_uses_tech",
          "source": "repo:langchain",
          "target": "tech:sparse_attention",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-25_anthropic_blog_6826",
              "url": "https://anthropic.com/news/2026/01/25/langchain_sparse_attention",
              "published": "2026-01-25",
              "snippet": "Technical details reveal langchain relies heavily on Sparse Attention..."
            },
            {
              "docId": "2026-01-25_techcrunch_2401",
              "url": "https://techcrunch.com/2026/01/25/langchain_sparse_attention",
              "published": "2026-01-25",
              "snippet": "Technical details reveal langchain relies heavily on Sparse Attention..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:command_r_plus_plus_mt_bench_v2_evaluated_on",
          "source": "model:command_r_plus_plus",
          "target": "benchmark:mt_bench_v2",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.97
        }
      },
      {
        "data": {
          "id": "e:lmsys_chatbot_arena_lite_palm_3_v2_measures",
          "source": "benchmark:lmsys_chatbot_arena_lite",
          "target": "model:palm_3_v2",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-11_reuters_5590",
              "url": "https://reuters.com/technology/2026/01/11/lmsys_chatbot_arena_lite_palm_",
              "published": "2026-01-11",
              "snippet": "The LMSYS Chatbot Arena Lite benchmark measures PaLM 3 v2 across multiple tasks..."
            },
            {
              "docId": "2026-01-11_google_ai_blog_7479",
              "url": "https://blog.google/technology/ai/2026/01/11/lmsys_chatbot_arena_lite_palm_",
              "published": "2026-01-11",
              "snippet": "The LMSYS Chatbot Arena Lite benchmark measures PaLM 3 v2 across multiple tasks..."
            },
            {
              "docId": "2026-01-14_google_ai_blog_3034",
              "url": "https://blog.google/technology/ai/2026/01/14/lmsys_chatbot_arena_lite_palm_",
              "published": "2026-01-14",
              "snippet": "The LMSYS Chatbot Arena Lite benchmark measures PaLM 3 v2 across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:ollama_jamba_2_integrates_with",
          "source": "repo:ollama",
          "target": "model:jamba_2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.76,
          "evidence": [
            {
              "docId": "2025-12-15_mit_technology__3526",
              "url": "https://technologyreview.com/2025/12/15/ollama_jamba_2",
              "published": "2025-12-15",
              "snippet": "ollama now supports Jamba 2 with full feature parity..."
            },
            {
              "docId": "2025-12-16_ars_technica_4637",
              "url": "https://arstechnica.com/2025/12/16/ollama_jamba_2",
              "published": "2025-12-16",
              "snippet": "ollama announced official support for Jamba 2..."
            },
            {
              "docId": "2026-01-25_venturebeat_7345",
              "url": "https://venturebeat.com/2026/01/25/ollama_jamba_2",
              "published": "2026-01-25",
              "snippet": "ollama now supports Jamba 2 with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_flash_attention_core_uses_tech",
          "source": "paper:llm_agents:_a_survey",
          "target": "tech:flash_attention_core",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2025-12-28_openai_blog_2892",
              "url": "https://openai.com/blog/2025/12/28/llm_agents:_a_survey_flash_att",
              "published": "2025-12-28",
              "snippet": "Technical details reveal LLM Agents: A Survey relies heavily on Flash Attention Core..."
            },
            {
              "docId": "2026-01-11_mit_technology__1225",
              "url": "https://technologyreview.com/2026/01/11/llm_agents:_a_survey_flash_att",
              "published": "2026-01-11",
              "snippet": "LLM Agents: A Survey leverages Flash Attention Core to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt_5_lora_core_uses_tech",
          "source": "model:gpt_5",
          "target": "tech:lora_core",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.55,
          "evidence": [
            {
              "docId": "2025-12-21_ars_technica_7196",
              "url": "https://arstechnica.com/2025/12/21/gpt_5_lora_core",
              "published": "2025-12-21",
              "snippet": "GPT-5 leverages LoRA Core to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-10_arxiv_3565",
              "url": "https://arxiv.org/abs/2026/01/10/gpt_5_lora_core",
              "published": "2026-01-10",
              "snippet": "GPT-5 leverages LoRA Core to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:grok_3_plus_gpqa_evaluated_on",
          "source": "model:grok_3_plus",
          "target": "benchmark:gpqa",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.98,
          "evidence": [
            {
              "docId": "2026-01-14_reuters_9340",
              "url": "https://reuters.com/technology/2026/01/14/grok_3_plus_gpqa",
              "published": "2026-01-14",
              "snippet": "Evaluation results show Grok-3 Plus reaching 99% on GPQA..."
            },
            {
              "docId": "2026-01-20_nextgov_9354",
              "url": "https://nextgov.com/2026/01/20/grok_3_plus_gpqa",
              "published": "2026-01-20",
              "snippet": "On the GPQA benchmark, Grok-3 Plus scored 92%..."
            },
            {
              "docId": "2026-01-20_meta_ai_blog_4461",
              "url": "https://ai.meta.com/blog/2026/01/20/grok_3_plus_gpqa",
              "published": "2026-01-20",
              "snippet": "On the GPQA benchmark, Grok-3 Plus scored 70%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mixtral_8x22b_starcoder_data_trained_on",
          "source": "model:mixtral_8x22b",
          "target": "dataset:starcoder_data",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:vllm_v2_kv_cache_optimization_next_uses_tech",
          "source": "repo:vllm_v2",
          "target": "tech:kv_cache_optimization_next",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2026-01-24_arxiv_3839",
              "url": "https://arxiv.org/abs/2026/01/24/vllm_v2_kv_cache_optimization_",
              "published": "2026-01-24",
              "snippet": "vllm v2 leverages KV Cache Optimization Next to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-24_anthropic_blog_6947",
              "url": "https://anthropic.com/news/2026/01/24/vllm_v2_kv_cache_optimization_",
              "published": "2026-01-24",
              "snippet": "Under the hood, vllm v2 implements KV Cache Optimization Next for improved efficiency..."
            },
            {
              "docId": "2026-01-25_google_ai_blog_9031",
              "url": "https://blog.google/technology/ai/2026/01/25/vllm_v2_kv_cache_optimization_",
              "published": "2026-01-25",
              "snippet": "vllm v2 leverages KV Cache Optimization Next to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_next_mt_bench_evaluated_on",
          "source": "model:llama_4_next",
          "target": "benchmark:mt_bench",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.97,
          "evidence": [
            {
              "docId": "2026-01-25_nextgov_1913",
              "url": "https://nextgov.com/2026/01/25/llama_4_next_mt_bench",
              "published": "2026-01-25",
              "snippet": "Evaluation results show Llama 4 Next reaching 78% on MT-Bench..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_chain_of_thought_pro_uses_tech",
          "source": "repo:langchain",
          "target": "tech:chain_of_thought_pro",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.8,
          "evidence": [
            {
              "docId": "2025-12-20_google_ai_blog_3203",
              "url": "https://blog.google/technology/ai/2025/12/20/langchain_chain_of_thought_pro",
              "published": "2025-12-20",
              "snippet": "Under the hood, langchain implements Chain-of-Thought Pro for improved efficiency..."
            },
            {
              "docId": "2026-01-08_meta_ai_blog_2563",
              "url": "https://ai.meta.com/blog/2026/01/08/langchain_chain_of_thought_pro",
              "published": "2026-01-08",
              "snippet": "Under the hood, langchain implements Chain-of-Thought Pro for improved efficiency..."
            },
            {
              "docId": "2026-01-11_wired_2441",
              "url": "https://wired.com/2026/01/11/langchain_chain_of_thought_pro",
              "published": "2026-01-11",
              "snippet": "langchain leverages Chain-of-Thought Pro to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:command_r_plus_starcoder_data_trained_on",
          "source": "model:command_r_plus",
          "target": "dataset:starcoder_data",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.8
        }
      },
      {
        "data": {
          "id": "e:cody_haystack_integrates_with",
          "source": "tool:cody",
          "target": "tool:haystack",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.58
        }
      },
      {
        "data": {
          "id": "e:gsm8k_gpt_5_measures",
          "source": "benchmark:gsm8k",
          "target": "model:gpt_5",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-03_reuters_4182",
              "url": "https://reuters.com/technology/2026/01/03/gsm8k_gpt_5",
              "published": "2026-01-03",
              "snippet": "GSM8K has become the standard for evaluating GPT-5..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:autogpt_crewai_core_integrates_with",
          "source": "tool:autogpt",
          "target": "tool:crewai_core",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.87
        }
      },
      {
        "data": {
          "id": "e:gpqa_gpt_5_v2_measures",
          "source": "benchmark:gpqa",
          "target": "model:gpt_5_v2",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-18_nextgov_3107",
              "url": "https://nextgov.com/2026/01/18/gpqa_gpt_5_v2",
              "published": "2026-01-18",
              "snippet": "The GPQA benchmark measures GPT-5 v2 across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:constitutional_ai:_harmlessness_from_ai__whisper_v4_next_evaluated_on",
          "source": "paper:constitutional_ai:_harmlessness_from_ai_",
          "target": "model:whisper_v4_next",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-22_ars_technica_6271",
              "url": "https://arstechnica.com/2026/01/22/constitutional_ai:_harmlessnes",
              "published": "2026-01-22",
              "snippet": "On the Whisper v4 Next benchmark, Constitutional AI: Harmlessness from AI Feedback scored 92%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:retrieval_augmented_generation_for_knowl_distillation_next_uses_tech",
          "source": "paper:retrieval_augmented_generation_for_knowl",
          "target": "tech:distillation_next",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-21_meta_ai_blog_5947",
              "url": "https://ai.meta.com/blog/2026/01/21/retrieval_augmented_generation",
              "published": "2026-01-21",
              "snippet": "Retrieval-Augmented Generation for Knowledge-Intensive NLP leverages Distillation Next to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-24_bloomberg_8427",
              "url": "https://bloomberg.com/technology/2026/01/24/retrieval_augmented_generation",
              "published": "2026-01-24",
              "snippet": "Retrieval-Augmented Generation for Knowledge-Intensive NLP leverages Distillation Next to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:jamba_2_truthfulqa_evaluated_on",
          "source": "model:jamba_2",
          "target": "benchmark:truthfulqa",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:nemotron_5_arc_agi_lite_evaluated_on",
          "source": "model:nemotron_5",
          "target": "benchmark:arc_agi_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-25_openai_blog_7731",
              "url": "https://openai.com/blog/2026/01/25/nemotron_5_arc_agi_lite",
              "published": "2026-01-25",
              "snippet": "Nemotron-5 achieves 73% on ARC-AGI Lite, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:grok_3_plus_lora_ultra_uses_tech",
          "source": "model:grok_3_plus",
          "target": "tech:lora_ultra",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.86
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_gemini_ultra_2_max_evaluated_on",
          "source": "paper:direct_preference_optimization",
          "target": "model:gemini_ultra_2_max",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.73,
          "evidence": [
            {
              "docId": "2026-01-18_hugging_face_bl_6451",
              "url": "https://huggingface.co/blog/2026/01/18/direct_preference_optimization",
              "published": "2026-01-18",
              "snippet": "Direct Preference Optimization achieves 98% on Gemini Ultra 2 Max, setting a new record..."
            },
            {
              "docId": "2026-01-19_the_gradient_2682",
              "url": "https://thegradient.pub/2026/01/19/direct_preference_optimization",
              "published": "2026-01-19",
              "snippet": "On the Gemini Ultra 2 Max benchmark, Direct Preference Optimization scored 76%..."
            },
            {
              "docId": "2026-01-24_techcrunch_6530",
              "url": "https://techcrunch.com/2026/01/24/direct_preference_optimization",
              "published": "2026-01-24",
              "snippet": "On the Gemini Ultra 2 Max benchmark, Direct Preference Optimization scored 78%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_ultra_bigbench_hard_plus_evaluated_on",
          "source": "model:palm_3_ultra",
          "target": "benchmark:bigbench_hard_plus",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.81
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_jamba_2_evaluated_on",
          "source": "paper:llm_agents:_a_survey",
          "target": "model:jamba_2",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.79
        }
      },
      {
        "data": {
          "id": "e:mixtral_8x22b_gemma_3_v2_depends_on",
          "source": "model:mixtral_8x22b",
          "target": "model:gemma_3_v2",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.58
        }
      },
      {
        "data": {
          "id": "e:mixtral_8x22b_deepseek_v3_edge_depends_on",
          "source": "model:mixtral_8x22b",
          "target": "model:deepseek_v3_edge",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.65
        }
      },
      {
        "data": {
          "id": "e:self_play_fine_tuning_for_language_model_stable_diffusion_4_max_evaluated_on",
          "source": "paper:self_play_fine_tuning_for_language_model",
          "target": "model:stable_diffusion_4_max",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.71,
          "evidence": [
            {
              "docId": "2026-01-03_techcrunch_4144",
              "url": "https://techcrunch.com/2026/01/03/self_play_fine_tuning_for_lang",
              "published": "2026-01-03",
              "snippet": "Self-Play Fine-Tuning for Language Models achieves 93% on Stable Diffusion 4 Max, setting a new record..."
            },
            {
              "docId": "2026-01-10_openai_blog_9331",
              "url": "https://openai.com/blog/2026/01/10/self_play_fine_tuning_for_lang",
              "published": "2026-01-10",
              "snippet": "Self-Play Fine-Tuning for Language Models achieves 90% on Stable Diffusion 4 Max, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_gsm8k_core_evaluated_on",
          "source": "model:claude_opus_45",
          "target": "benchmark:gsm8k_core",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-18_google_ai_blog_5419",
              "url": "https://blog.google/technology/ai/2026/01/18/claude_opus_45_gsm8k_core",
              "published": "2026-01-18",
              "snippet": "On the GSM8K Core benchmark, Claude Opus 4.5 scored 86%..."
            },
            {
              "docId": "2026-01-22_meta_ai_blog_8868",
              "url": "https://ai.meta.com/blog/2026/01/22/claude_opus_45_gsm8k_core",
              "published": "2026-01-22",
              "snippet": "On the GSM8K Core benchmark, Claude Opus 4.5 scored 98%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:command_r_plus_lite_chain_of_thought_pro_uses_tech",
          "source": "model:command_r_plus_lite",
          "target": "tech:chain_of_thought_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.89
        }
      },
      {
        "data": {
          "id": "e:gpt4all_midjourney_v7_integrates_with",
          "source": "repo:gpt4all",
          "target": "model:midjourney_v7",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.81
        }
      },
      {
        "data": {
          "id": "e:midjourney_v7_plus_whisper_v4_v2_depends_on",
          "source": "model:midjourney_v7_plus",
          "target": "model:whisper_v4_v2",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.47
        }
      },
      {
        "data": {
          "id": "e:alpacaeval_2_lite_command_r_plus_measures",
          "source": "benchmark:alpacaeval_2_lite",
          "target": "model:command_r_plus",
          "rel": "MEASURES",
          "kind": "inferred",
          "confidence": 0.97
        }
      },
      {
        "data": {
          "id": "e:dolma_distillation_uses_tech",
          "source": "dataset:dolma",
          "target": "tech:distillation",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.73
        }
      },
      {
        "data": {
          "id": "e:gpqa_falcon_3_measures",
          "source": "benchmark:gpqa",
          "target": "model:falcon_3",
          "rel": "MEASURES",
          "kind": "inferred",
          "confidence": 0.88
        }
      },
      {
        "data": {
          "id": "e:codex_2_lite_command_r_plus_lite_depends_on",
          "source": "model:codex_2_lite",
          "target": "model:command_r_plus_lite",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.63
        }
      },
      {
        "data": {
          "id": "e:mmlu_sora_2_max_measures",
          "source": "benchmark:mmlu",
          "target": "model:sora_2_max",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.93,
          "evidence": [
            {
              "docId": "2025-12-18_nvidia_blog_4376",
              "url": "https://blogs.nvidia.com/2025/12/18/mmlu_sora_2_max",
              "published": "2025-12-18",
              "snippet": "The MMLU benchmark measures Sora 2 Max across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamaindex_langchain_plus_integrates_with",
          "source": "tool:llamaindex",
          "target": "tool:langchain_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.58,
          "evidence": [
            {
              "docId": "2026-01-19_mit_technology__7842",
              "url": "https://technologyreview.com/2026/01/19/llamaindex_langchain_plus",
              "published": "2026-01-19",
              "snippet": "LlamaIndex announced official support for LangChain Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:falcon_3_slimpajama_edge_trained_on",
          "source": "model:falcon_3",
          "target": "dataset:slimpajama_edge",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:deepseek_v3_plus_mbpp_evaluated_on",
          "source": "model:deepseek_v3_plus",
          "target": "benchmark:mbpp",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.82,
          "evidence": [
            {
              "docId": "2026-01-08_mit_technology__9809",
              "url": "https://technologyreview.com/2026/01/08/deepseek_v3_plus_mbpp",
              "published": "2026-01-08",
              "snippet": "DeepSeek-V3 Plus achieves 70% on MBPP, setting a new record..."
            },
            {
              "docId": "2026-01-17_meta_ai_blog_4240",
              "url": "https://ai.meta.com/blog/2026/01/17/deepseek_v3_plus_mbpp",
              "published": "2026-01-17",
              "snippet": "Evaluation results show DeepSeek-V3 Plus reaching 83% on MBPP..."
            },
            {
              "docId": "2026-01-24_mit_technology__2472",
              "url": "https://technologyreview.com/2026/01/24/deepseek_v3_plus_mbpp",
              "published": "2026-01-24",
              "snippet": "Evaluation results show DeepSeek-V3 Plus reaching 77% on MBPP..."
            },
            {
              "docId": "2026-01-25_anthropic_blog_1004",
              "url": "https://anthropic.com/news/2026/01/25/deepseek_v3_plus_mbpp",
              "published": "2026-01-25",
              "snippet": "DeepSeek-V3 Plus achieves 84% on MBPP, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:codex_2_pro_common_crawl_plus_trained_on",
          "source": "model:codex_2_pro",
          "target": "dataset:common_crawl_plus",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.68,
          "evidence": [
            {
              "docId": "2026-01-03_weights_and_bia_6166",
              "url": "https://wandb.ai/articles/2026/01/03/codex_2_pro_common_crawl_plus",
              "published": "2026-01-03",
              "snippet": "Codex 2 Pro was trained on Common Crawl Plus comprising billions of tokens..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt_5_v2_common_crawl_plus_trained_on",
          "source": "model:gpt_5_v2",
          "target": "dataset:common_crawl_plus",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.87
        }
      },
      {
        "data": {
          "id": "e:falcon_3_winogrande_evaluated_on",
          "source": "model:falcon_3",
          "target": "benchmark:winogrande",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.89
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_max_nemotron_5_depends_on",
          "source": "model:claude_opus_45_max",
          "target": "model:nemotron_5",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.7
        }
      },
      {
        "data": {
          "id": "e:aya_3_edge_refinedweb_ultra_trained_on",
          "source": "model:aya_3_edge",
          "target": "dataset:refinedweb_ultra",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.6
        }
      },
      {
        "data": {
          "id": "e:mixture_of_experts_meets_instruction_tun_codex_2_pro_evaluated_on",
          "source": "paper:mixture_of_experts_meets_instruction_tun",
          "target": "model:codex_2_pro",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.76,
          "evidence": [
            {
              "docId": "2026-01-10_venturebeat_1414",
              "url": "https://venturebeat.com/2026/01/10/mixture_of_experts_meets_instr",
              "published": "2026-01-10",
              "snippet": "Evaluation results show Mixture of Experts Meets Instruction Tuning reaching 91% on Codex 2 Pro..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:refinedweb_lora_ultra_uses_tech",
          "source": "dataset:refinedweb",
          "target": "tech:lora_ultra",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:crewai_autogpt_max_integrates_with",
          "source": "tool:crewai",
          "target": "tool:autogpt_max",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:ollama_edge_claude_sonnet_4_integrates_with",
          "source": "tool:ollama_edge",
          "target": "model:claude_sonnet_4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-24_bloomberg_7065",
              "url": "https://bloomberg.com/technology/2026/01/24/ollama_edge_claude_sonnet_4",
              "published": "2026-01-24",
              "snippet": "Ollama Edge announced official support for Claude Sonnet 4..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamacpp_dall_e_4_edge_integrates_with",
          "source": "repo:llamacpp",
          "target": "model:dall_e_4_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.78,
          "evidence": [
            {
              "docId": "2026-01-21_the_gradient_7888",
              "url": "https://thegradient.pub/2026/01/21/llamacpp_dall_e_4_edge",
              "published": "2026-01-21",
              "snippet": "llama.cpp announced official support for DALL-E 4 Edge..."
            },
            {
              "docId": "2026-01-22_langchain_blog_5215",
              "url": "https://blog.langchain.dev/2026/01/22/llamacpp_dall_e_4_edge",
              "published": "2026-01-22",
              "snippet": "The latest release of llama.cpp adds native DALL-E 4 Edge integration..."
            },
            {
              "docId": "2026-01-24_meta_ai_blog_2513",
              "url": "https://ai.meta.com/blog/2026/01/24/llamacpp_dall_e_4_edge",
              "published": "2026-01-24",
              "snippet": "llama.cpp now supports DALL-E 4 Edge with full feature parity..."
            },
            {
              "docId": "2026-01-24_weights_and_bia_6454",
              "url": "https://wandb.ai/articles/2026/01/24/llamacpp_dall_e_4_edge",
              "published": "2026-01-24",
              "snippet": "llama.cpp announced official support for DALL-E 4 Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mlflow_next_llamaindex_core_integrates_with",
          "source": "tool:mlflow_next",
          "target": "tool:llamaindex_core",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.75
        }
      },
      {
        "data": {
          "id": "e:scaling_data_constrained_language_models_lora_ultra_uses_tech",
          "source": "paper:scaling_data_constrained_language_models",
          "target": "tech:lora_ultra",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-25_weights_and_bia_6409",
              "url": "https://wandb.ai/articles/2026/01/25/scaling_data_constrained_langu",
              "published": "2026-01-25",
              "snippet": "Under the hood, Scaling Data-Constrained Language Models implements LoRA Ultra for improved efficiency..."
            },
            {
              "docId": "2026-01-25_arxiv_4610",
              "url": "https://arxiv.org/abs/2026/01/25/scaling_data_constrained_langu",
              "published": "2026-01-25",
              "snippet": "Scaling Data-Constrained Language Models leverages LoRA Ultra to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:jamba_2_lmsys_chatbot_arena_evaluated_on",
          "source": "model:jamba_2",
          "target": "benchmark:lmsys_chatbot_arena",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.86,
          "evidence": [
            {
              "docId": "2025-12-16_google_ai_blog_8078",
              "url": "https://blog.google/technology/ai/2025/12/16/jamba_2_lmsys_chatbot_arena",
              "published": "2025-12-16",
              "snippet": "On the LMSYS Chatbot Arena benchmark, Jamba 2 scored 86%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamaindex_ultra_claude_opus_45_max_integrates_with",
          "source": "tool:llamaindex_ultra",
          "target": "model:claude_opus_45_max",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2026-01-22_wired_3959",
              "url": "https://wired.com/2026/01/22/llamaindex_ultra_claude_opus_4",
              "published": "2026-01-22",
              "snippet": "LlamaIndex Ultra announced official support for Claude Opus 4.5 Max..."
            },
            {
              "docId": "2026-01-24_openai_blog_8443",
              "url": "https://openai.com/blog/2026/01/24/llamaindex_ultra_claude_opus_4",
              "published": "2026-01-24",
              "snippet": "LlamaIndex Ultra announced official support for Claude Opus 4.5 Max..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:stable_diffusion_4_max_mbpp_evaluated_on",
          "source": "model:stable_diffusion_4_max",
          "target": "benchmark:mbpp",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-18_ars_technica_4131",
              "url": "https://arstechnica.com/2026/01/18/stable_diffusion_4_max_mbpp",
              "published": "2026-01-18",
              "snippet": "Evaluation results show Stable Diffusion 4 Max reaching 82% on MBPP..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gemini_ultra_2_max_starcoder_data_pro_trained_on",
          "source": "model:gemini_ultra_2_max",
          "target": "dataset:starcoder_data_pro",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.5
        }
      },
      {
        "data": {
          "id": "e:vllm_qwen_3_integrates_with",
          "source": "tool:vllm",
          "target": "model:qwen_3",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.89
        }
      },
      {
        "data": {
          "id": "e:vllm_v2_stable_diffusion_4_max_integrates_with",
          "source": "repo:vllm_v2",
          "target": "model:stable_diffusion_4_max",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-22_weights_and_bia_3538",
              "url": "https://wandb.ai/articles/2026/01/22/vllm_v2_stable_diffusion_4_max",
              "published": "2026-01-22",
              "snippet": "The latest release of vllm v2 adds native Stable Diffusion 4 Max integration..."
            },
            {
              "docId": "2026-01-23_openai_blog_4149",
              "url": "https://openai.com/blog/2026/01/23/vllm_v2_stable_diffusion_4_max",
              "published": "2026-01-23",
              "snippet": "The latest release of vllm v2 adds native Stable Diffusion 4 Max integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mbpp_sora_2_ultra_measures",
          "source": "benchmark:mbpp",
          "target": "model:sora_2_ultra",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2025-12-18_openai_blog_7587",
              "url": "https://openai.com/blog/2025/12/18/mbpp_sora_2_ultra",
              "published": "2025-12-18",
              "snippet": "MBPP has become the standard for evaluating Sora 2 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:vllm_core_streamlit_integrates_with",
          "source": "tool:vllm_core",
          "target": "tool:streamlit",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:dolma_transformer_architecture_pro_uses_tech",
          "source": "dataset:dolma",
          "target": "tech:transformer_architecture_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:ollama_edge_semantic_kernel_integrates_with",
          "source": "tool:ollama_edge",
          "target": "tool:semantic_kernel",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.78,
          "evidence": [
            {
              "docId": "2026-01-11_anthropic_blog_1857",
              "url": "https://anthropic.com/news/2026/01/11/ollama_edge_semantic_kernel",
              "published": "2026-01-11",
              "snippet": "Ollama Edge now supports Semantic Kernel with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:grok_3_ultra_humaneval_evaluated_on",
          "source": "model:grok_3_ultra",
          "target": "benchmark:humaneval",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.9,
          "evidence": [
            {
              "docId": "2025-12-20_openai_blog_5394",
              "url": "https://openai.com/blog/2025/12/20/grok_3_ultra_humaneval",
              "published": "2025-12-20",
              "snippet": "Evaluation results show Grok-3 Ultra reaching 85% on HumanEval..."
            },
            {
              "docId": "2026-01-03_wired_2357",
              "url": "https://wired.com/2026/01/03/grok_3_ultra_humaneval",
              "published": "2026-01-03",
              "snippet": "Evaluation results show Grok-3 Ultra reaching 98% on HumanEval..."
            },
            {
              "docId": "2026-01-16_arxiv_6883",
              "url": "https://arxiv.org/abs/2026/01/16/grok_3_ultra_humaneval",
              "published": "2026-01-16",
              "snippet": "Grok-3 Ultra achieves 82% on HumanEval, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:toolformer:_language_models_can_teach_th_gemini_ultra_2_lite_evaluated_on",
          "source": "paper:toolformer:_language_models_can_teach_th",
          "target": "model:gemini_ultra_2_lite",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.75
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_claude_sonnet_4_lite_evaluated_on",
          "source": "paper:llm_agents:_a_survey",
          "target": "model:claude_sonnet_4_lite",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.86
        }
      },
      {
        "data": {
          "id": "e:litellm_edge_claude_sonnet_4_lite_integrates_with",
          "source": "tool:litellm_edge",
          "target": "model:claude_sonnet_4_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-20_arxiv_9023",
              "url": "https://arxiv.org/abs/2026/01/20/litellm_edge_claude_sonnet_4_l",
              "published": "2026-01-20",
              "snippet": "LiteLLM Edge now supports Claude Sonnet 4 Lite with full feature parity..."
            },
            {
              "docId": "2026-01-22_hugging_face_bl_8100",
              "url": "https://huggingface.co/blog/2026/01/22/litellm_edge_claude_sonnet_4_l",
              "published": "2026-01-22",
              "snippet": "LiteLLM Edge now supports Claude Sonnet 4 Lite with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gradio_max_multimodal_fusion_plus_uses_tech",
          "source": "tool:gradio_max",
          "target": "tech:multimodal_fusion_plus",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.74
        }
      },
      {
        "data": {
          "id": "e:alpacaeval_2_lite_phi_4_mini_measures",
          "source": "benchmark:alpacaeval_2_lite",
          "target": "model:phi_4_mini",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2025-12-27_the_gradient_9120",
              "url": "https://thegradient.pub/2025/12/27/alpacaeval_2_lite_phi_4_mini",
              "published": "2025-12-27",
              "snippet": "AlpacaEval 2 Lite has become the standard for evaluating Phi-4 Mini..."
            },
            {
              "docId": "2025-12-29_techcrunch_4230",
              "url": "https://techcrunch.com/2025/12/29/alpacaeval_2_lite_phi_4_mini",
              "published": "2025-12-29",
              "snippet": "AlpacaEval 2 Lite provides standardized evaluation of Phi-4 Mini..."
            },
            {
              "docId": "2026-01-11_nvidia_blog_9549",
              "url": "https://blogs.nvidia.com/2026/01/11/alpacaeval_2_lite_phi_4_mini",
              "published": "2026-01-11",
              "snippet": "AlpacaEval 2 Lite has become the standard for evaluating Phi-4 Mini..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:grok_3_plus_c4_trained_on",
          "source": "model:grok_3_plus",
          "target": "dataset:c4",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2026-01-15_google_ai_blog_5583",
              "url": "https://blog.google/technology/ai/2026/01/15/grok_3_plus_c4",
              "published": "2026-01-15",
              "snippet": "Grok-3 Plus utilized C4 as part of its pre-training data mix..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_max_quantization_edge_uses_tech",
          "source": "model:llama_4_max",
          "target": "tech:quantization_edge",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.71,
          "evidence": [
            {
              "docId": "2026-01-18_bloomberg_3595",
              "url": "https://bloomberg.com/technology/2026/01/18/llama_4_max_quantization_edge",
              "published": "2026-01-18",
              "snippet": "Llama 4 Max leverages Quantization Edge to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:aya_3_v2_math_v2_evaluated_on",
          "source": "model:aya_3_v2",
          "target": "benchmark:math_v2",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-20_google_ai_blog_7468",
              "url": "https://blog.google/technology/ai/2026/01/20/aya_3_v2_math_v2",
              "published": "2026-01-20",
              "snippet": "Evaluation results show Aya 3 v2 reaching 89% on MATH v2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:semantic_kernel_autogpt_integrates_with",
          "source": "tool:semantic_kernel",
          "target": "tool:autogpt",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2025-12-07_reuters_2998",
              "url": "https://reuters.com/technology/2025/12/07/semantic_kernel_autogpt",
              "published": "2025-12-07",
              "snippet": "Semantic Kernel announced official support for AutoGPT..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:transformers_next_gemma_3_lite_integrates_with",
          "source": "repo:transformers_next",
          "target": "model:gemma_3_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-13_wired_1816",
              "url": "https://wired.com/2026/01/13/transformers_next_gemma_3_lite",
              "published": "2026-01-13",
              "snippet": "transformers Next announced official support for Gemma 3 Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:deepseek_v3_lmsys_chatbot_arena_evaluated_on",
          "source": "model:deepseek_v3",
          "target": "benchmark:lmsys_chatbot_arena",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.98,
          "evidence": [
            {
              "docId": "2026-01-25_mit_technology__9818",
              "url": "https://technologyreview.com/2026/01/25/deepseek_v3_lmsys_chatbot_aren",
              "published": "2026-01-25",
              "snippet": "On the LMSYS Chatbot Arena benchmark, DeepSeek-V3 scored 75%..."
            },
            {
              "docId": "2026-01-25_wired_2187",
              "url": "https://wired.com/2026/01/25/deepseek_v3_lmsys_chatbot_aren",
              "published": "2026-01-25",
              "snippet": "Evaluation results show DeepSeek-V3 reaching 70% on LMSYS Chatbot Arena..."
            },
            {
              "docId": "2026-01-25_reuters_9577",
              "url": "https://reuters.com/technology/2026/01/25/deepseek_v3_lmsys_chatbot_aren",
              "published": "2026-01-25",
              "snippet": "On the LMSYS Chatbot Arena benchmark, DeepSeek-V3 scored 85%..."
            },
            {
              "docId": "2026-01-25_mit_technology__3256",
              "url": "https://technologyreview.com/2026/01/25/deepseek_v3_lmsys_chatbot_aren",
              "published": "2026-01-25",
              "snippet": "Evaluation results show DeepSeek-V3 reaching 73% on LMSYS Chatbot Arena..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mlflow_next_crewai_integrates_with",
          "source": "tool:mlflow_next",
          "target": "tool:crewai",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.73,
          "evidence": [
            {
              "docId": "2025-12-05_wired_1847",
              "url": "https://wired.com/2025/12/05/mlflow_next_crewai",
              "published": "2025-12-05",
              "snippet": "MLflow Next now supports CrewAI with full feature parity..."
            },
            {
              "docId": "2026-01-17_nvidia_blog_6221",
              "url": "https://blogs.nvidia.com/2026/01/17/mlflow_next_crewai",
              "published": "2026-01-17",
              "snippet": "MLflow Next now supports CrewAI with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:math_v2_grok_3_ultra_measures",
          "source": "benchmark:math_v2",
          "target": "model:grok_3_ultra",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2025-12-22_meta_ai_blog_6005",
              "url": "https://ai.meta.com/blog/2025/12/22/math_v2_grok_3_ultra",
              "published": "2025-12-22",
              "snippet": "MATH v2 provides standardized evaluation of Grok-3 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:qwen_3_next_sliding_window_attention_ultra_uses_tech",
          "source": "model:qwen_3_next",
          "target": "tech:sliding_window_attention_ultra",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.68,
          "evidence": [
            {
              "docId": "2025-12-12_the_gradient_7425",
              "url": "https://thegradient.pub/2025/12/12/qwen_3_next_sliding_window_att",
              "published": "2025-12-12",
              "snippet": "Under the hood, Qwen-3 Next implements Sliding Window Attention Ultra for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_distillation_next_uses_tech",
          "source": "paper:direct_preference_optimization",
          "target": "tech:distillation_next",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.83
        }
      },
      {
        "data": {
          "id": "e:llamacpp_stable_diffusion_4_integrates_with",
          "source": "repo:llamacpp",
          "target": "model:stable_diffusion_4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-22_techcrunch_1037",
              "url": "https://techcrunch.com/2026/01/22/llamacpp_stable_diffusion_4",
              "published": "2026-01-22",
              "snippet": "The latest release of llama.cpp adds native Stable Diffusion 4 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:jamba_2_lite_constitutional_ai_mini_uses_tech",
          "source": "model:jamba_2_lite",
          "target": "tech:constitutional_ai_mini",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.74,
          "evidence": [
            {
              "docId": "2025-12-30_techcrunch_2542",
              "url": "https://techcrunch.com/2025/12/30/jamba_2_lite_constitutional_ai",
              "published": "2025-12-30",
              "snippet": "Under the hood, Jamba 2 Lite implements Constitutional AI Mini for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:self_play_fine_tuning_for_language_model_yi_large_v2_evaluated_on",
          "source": "paper:self_play_fine_tuning_for_language_model",
          "target": "model:yi_large_v2",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2026-01-03_microsoft_resea_3706",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/03/self_play_fine_tuning_for_lang",
              "published": "2026-01-03",
              "snippet": "Self-Play Fine-Tuning for Language Models achieves 98% on Yi-Large v2, setting a new record..."
            },
            {
              "docId": "2026-01-15_hugging_face_bl_8339",
              "url": "https://huggingface.co/blog/2026/01/15/self_play_fine_tuning_for_lang",
              "published": "2026-01-15",
              "snippet": "Evaluation results show Self-Play Fine-Tuning for Language Models reaching 99% on Yi-Large v2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_next_the_stack_v2_trained_on",
          "source": "model:llama_4_next",
          "target": "dataset:the_stack_v2",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.54
        }
      },
      {
        "data": {
          "id": "e:palm_3_ultra_hellaswag_evaluated_on",
          "source": "model:palm_3_ultra",
          "target": "benchmark:hellaswag",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2025-12-30_arxiv_8154",
              "url": "https://arxiv.org/abs/2025/12/30/palm_3_ultra_hellaswag",
              "published": "2025-12-30",
              "snippet": "On the HellaSwag benchmark, PaLM 3 Ultra scored 78%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:crewai_tree_of_thought_lite_uses_tech",
          "source": "tool:crewai",
          "target": "tech:tree_of_thought_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:nemotron_5_nemotron_5_v2_depends_on",
          "source": "model:nemotron_5",
          "target": "model:nemotron_5_v2",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_pro_group_query_attention_v2_uses_tech",
          "source": "paper:llm_agents:_a_survey_pro",
          "target": "tech:group_query_attention_v2",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2026-01-19_bloomberg_8479",
              "url": "https://bloomberg.com/technology/2026/01/19/llm_agents:_a_survey_pro_group",
              "published": "2026-01-19",
              "snippet": "LLM Agents: A Survey Pro leverages Group Query Attention v2 to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-19_mit_technology__2923",
              "url": "https://technologyreview.com/2026/01/19/llm_agents:_a_survey_pro_group",
              "published": "2026-01-19",
              "snippet": "Technical details reveal LLM Agents: A Survey Pro relies heavily on Group Query Attention v2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:nemotron_5_starcoder_data_pro_trained_on",
          "source": "model:nemotron_5",
          "target": "dataset:starcoder_data_pro",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_edge_mmlu_max_evaluated_on",
          "source": "model:dall_e_4_edge",
          "target": "benchmark:mmlu_max",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-25_nextgov_4568",
              "url": "https://nextgov.com/2026/01/25/dall_e_4_edge_mmlu_max",
              "published": "2026-01-25",
              "snippet": "Evaluation results show DALL-E 4 Edge reaching 91% on MMLU Max..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:truthfulqa_plus_aya_3_v2_measures",
          "source": "benchmark:truthfulqa_plus",
          "target": "model:aya_3_v2",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-20_reuters_8521",
              "url": "https://reuters.com/technology/2026/01/20/truthfulqa_plus_aya_3_v2",
              "published": "2026-01-20",
              "snippet": "TruthfulQA Plus has become the standard for evaluating Aya 3 v2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:copilot_ultra_tokenizer_bpe_uses_tech",
          "source": "tool:copilot_ultra",
          "target": "tech:tokenizer_bpe",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.84
        }
      },
      {
        "data": {
          "id": "e:command_r_plus_roots_core_trained_on",
          "source": "model:command_r_plus",
          "target": "dataset:roots_core",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.57
        }
      },
      {
        "data": {
          "id": "e:vllm_gemini_ultra_2_edge_integrates_with",
          "source": "repo:vllm",
          "target": "model:gemini_ultra_2_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:localai_next_kv_cache_optimization_uses_tech",
          "source": "tool:localai_next",
          "target": "tech:kv_cache_optimization",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.64,
          "evidence": [
            {
              "docId": "2026-01-17_ars_technica_9707",
              "url": "https://arstechnica.com/2026/01/17/localai_next_kv_cache_optimiza",
              "published": "2026-01-17",
              "snippet": "LocalAI Next leverages KV Cache Optimization to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-23_nvidia_blog_6780",
              "url": "https://blogs.nvidia.com/2026/01/23/localai_next_kv_cache_optimiza",
              "published": "2026-01-23",
              "snippet": "Technical details reveal LocalAI Next relies heavily on KV Cache Optimization..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_gpt_5_mini_depends_on",
          "source": "model:dall_e_4",
          "target": "model:gpt_5_mini",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.63
        }
      },
      {
        "data": {
          "id": "e:bigbench_hard_plus_jamba_2_lite_measures",
          "source": "benchmark:bigbench_hard_plus",
          "target": "model:jamba_2_lite",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.9,
          "evidence": [
            {
              "docId": "2025-12-28_openai_blog_7428",
              "url": "https://openai.com/blog/2025/12/28/bigbench_hard_plus_jamba_2_lit",
              "published": "2025-12-28",
              "snippet": "BigBench Hard Plus has become the standard for evaluating Jamba 2 Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:qwen_3_ultra_yi_large_depends_on",
          "source": "model:qwen_3_ultra",
          "target": "model:yi_large",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.65
        }
      },
      {
        "data": {
          "id": "e:gradio_transformer_architecture_pro_uses_tech",
          "source": "tool:gradio",
          "target": "tech:transformer_architecture_pro",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2025-12-18_techcrunch_4462",
              "url": "https://techcrunch.com/2025/12/18/gradio_transformer_architectur",
              "published": "2025-12-18",
              "snippet": "Technical details reveal Gradio relies heavily on Transformer Architecture Pro..."
            },
            {
              "docId": "2026-01-24_hugging_face_bl_1402",
              "url": "https://huggingface.co/blog/2026/01/24/gradio_transformer_architectur",
              "published": "2026-01-24",
              "snippet": "Gradio leverages Transformer Architecture Pro to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-25_meta_ai_blog_9314",
              "url": "https://ai.meta.com/blog/2026/01/25/gradio_transformer_architectur",
              "published": "2026-01-25",
              "snippet": "Gradio leverages Transformer Architecture Pro to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:constitutional_ai:_harmlessness_from_ai__chain_of_thought_max_uses_tech",
          "source": "paper:constitutional_ai:_harmlessness_from_ai_",
          "target": "tech:chain_of_thought_max",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2025-12-15_nextgov_7908",
              "url": "https://nextgov.com/2025/12/15/constitutional_ai:_harmlessnes",
              "published": "2025-12-15",
              "snippet": "Constitutional AI: Harmlessness from AI Feedback leverages Chain-of-Thought Max to achieve state-of-the-art performance..."
            },
            {
              "docId": "2025-12-26_techcrunch_3544",
              "url": "https://techcrunch.com/2025/12/26/constitutional_ai:_harmlessnes",
              "published": "2025-12-26",
              "snippet": "Under the hood, Constitutional AI: Harmlessness from AI Feedback implements Chain-of-Thought Max for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_plus_swe_bench_next_evaluated_on",
          "source": "model:dall_e_4_plus",
          "target": "benchmark:swe_bench_next",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.96
        }
      },
      {
        "data": {
          "id": "e:constitutional_ai:_harmlessness_from_ai__retrieval_augmented_generation_plus_uses_tech",
          "source": "paper:constitutional_ai:_harmlessness_from_ai_",
          "target": "tech:retrieval_augmented_generation_plus",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2026-01-23_microsoft_resea_2786",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/23/constitutional_ai:_harmlessnes",
              "published": "2026-01-23",
              "snippet": "Under the hood, Constitutional AI: Harmlessness from AI Feedback implements Retrieval-Augmented Generation Plus for improved efficiency..."
            },
            {
              "docId": "2026-01-24_wired_6501",
              "url": "https://wired.com/2026/01/24/constitutional_ai:_harmlessnes",
              "published": "2026-01-24",
              "snippet": "Technical details reveal Constitutional AI: Harmlessness from AI Feedback relies heavily on Retrieval-Augmented Generation Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:toolformer:_language_models_can_teach_th_dpo_uses_tech",
          "source": "paper:toolformer:_language_models_can_teach_th",
          "target": "tech:dpo",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.88
        }
      },
      {
        "data": {
          "id": "e:palm_3_max_math_evaluated_on",
          "source": "model:palm_3_max",
          "target": "benchmark:math",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-21_reuters_7033",
              "url": "https://reuters.com/technology/2026/01/21/palm_3_max_math",
              "published": "2026-01-21",
              "snippet": "On the MATH benchmark, PaLM 3 Max scored 99%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_redpajama_v2_v2_trained_on",
          "source": "model:dall_e_4",
          "target": "dataset:redpajama_v2_v2",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.7
        }
      },
      {
        "data": {
          "id": "e:localai_multimodal_fusion_lite_uses_tech",
          "source": "repo:localai",
          "target": "tech:multimodal_fusion_lite",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-25_openai_blog_6682",
              "url": "https://openai.com/blog/2026/01/25/localai_multimodal_fusion_lite",
              "published": "2026-01-25",
              "snippet": "Technical details reveal LocalAI relies heavily on Multimodal Fusion Lite..."
            },
            {
              "docId": "2026-01-25_the_gradient_9918",
              "url": "https://thegradient.pub/2026/01/25/localai_multimodal_fusion_lite",
              "published": "2026-01-25",
              "snippet": "Under the hood, LocalAI implements Multimodal Fusion Lite for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:roots_core_transformer_architecture_uses_tech",
          "source": "dataset:roots_core",
          "target": "tech:transformer_architecture",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.69
        }
      },
      {
        "data": {
          "id": "e:qwen_3_ultra_tool_use_uses_tech",
          "source": "model:qwen_3_ultra",
          "target": "tech:tool_use",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.79
        }
      },
      {
        "data": {
          "id": "e:phi_4_ultra_stable_diffusion_4_mini_depends_on",
          "source": "model:phi_4_ultra",
          "target": "model:stable_diffusion_4_mini",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.44
        }
      },
      {
        "data": {
          "id": "e:mmlu_max_sora_2_measures",
          "source": "benchmark:mmlu_max",
          "target": "model:sora_2",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.96,
          "evidence": [
            {
              "docId": "2026-01-24_hugging_face_bl_4982",
              "url": "https://huggingface.co/blog/2026/01/24/mmlu_max_sora_2",
              "published": "2026-01-24",
              "snippet": "The MMLU Max benchmark measures Sora 2 across multiple tasks..."
            },
            {
              "docId": "2026-01-24_reuters_9644",
              "url": "https://reuters.com/technology/2026/01/24/mmlu_max_sora_2",
              "published": "2026-01-24",
              "snippet": "MMLU Max provides standardized evaluation of Sora 2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:codex_2_lite_slimpajama_edge_trained_on",
          "source": "model:codex_2_lite",
          "target": "dataset:slimpajama_edge",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.68
        }
      },
      {
        "data": {
          "id": "e:crewai_core_phi_4_mini_integrates_with",
          "source": "tool:crewai_core",
          "target": "model:phi_4_mini",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-21_bloomberg_6976",
              "url": "https://bloomberg.com/technology/2026/01/21/crewai_core_phi_4_mini",
              "published": "2026-01-21",
              "snippet": "CrewAI Core now supports Phi-4 Mini with full feature parity..."
            },
            {
              "docId": "2026-01-23_mit_technology__9197",
              "url": "https://technologyreview.com/2026/01/23/crewai_core_phi_4_mini",
              "published": "2026-01-23",
              "snippet": "CrewAI Core now supports Phi-4 Mini with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:openwebtext2_mini_tree_of_thought_lite_uses_tech",
          "source": "dataset:openwebtext2_mini",
          "target": "tech:tree_of_thought_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.42
        }
      },
      {
        "data": {
          "id": "e:dify_ultra_kv_cache_optimization_max_uses_tech",
          "source": "tool:dify_ultra",
          "target": "tech:kv_cache_optimization_max",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_ultra_red_teaming_mini_uses_tech",
          "source": "paper:direct_preference_optimization_ultra",
          "target": "tech:red_teaming_mini",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-10_weights_and_bia_7688",
              "url": "https://wandb.ai/articles/2026/01/10/direct_preference_optimization",
              "published": "2026-01-10",
              "snippet": "Technical details reveal Direct Preference Optimization Ultra relies heavily on Red Teaming Mini..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt_5_slimpajama_edge_trained_on",
          "source": "model:gpt_5",
          "target": "dataset:slimpajama_edge",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.59
        }
      },
      {
        "data": {
          "id": "e:llama_4_next_dall_e_4_depends_on",
          "source": "model:llama_4_next",
          "target": "model:dall_e_4",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.48
        }
      },
      {
        "data": {
          "id": "e:wikipedia_dump_2025_dpo_uses_tech",
          "source": "dataset:wikipedia_dump_2025",
          "target": "tech:dpo",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:langchain_plus_gemini_ultra_2_lite_integrates_with",
          "source": "tool:langchain_plus",
          "target": "model:gemini_ultra_2_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.78,
          "evidence": [
            {
              "docId": "2025-11-02_anthropic_blog_7765",
              "url": "https://anthropic.com/news/2025/11/02/langchain_plus_gemini_ultra_2_",
              "published": "2025-11-02",
              "snippet": "LangChain Plus now supports Gemini Ultra 2 Lite with full feature parity..."
            },
            {
              "docId": "2025-11-09_bloomberg_4282",
              "url": "https://bloomberg.com/technology/2025/11/09/langchain_plus_gemini_ultra_2_",
              "published": "2025-11-09",
              "snippet": "LangChain Plus now supports Gemini Ultra 2 Lite with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:midjourney_v7_falcon_3_depends_on",
          "source": "model:midjourney_v7",
          "target": "model:falcon_3",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.63
        }
      },
      {
        "data": {
          "id": "e:jamba_2_starcoder_data_pro_trained_on",
          "source": "model:jamba_2",
          "target": "dataset:starcoder_data_pro",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.87
        }
      },
      {
        "data": {
          "id": "e:haystack_mini_palm_3_integrates_with",
          "source": "tool:haystack_mini",
          "target": "model:palm_3",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2026-01-02_hugging_face_bl_3463",
              "url": "https://huggingface.co/blog/2026/01/02/haystack_mini_palm_3",
              "published": "2026-01-02",
              "snippet": "Haystack Mini now supports PaLM 3 with full feature parity..."
            },
            {
              "docId": "2026-01-24_arxiv_1071",
              "url": "https://arxiv.org/abs/2026/01/24/haystack_mini_palm_3",
              "published": "2026-01-24",
              "snippet": "Haystack Mini now supports PaLM 3 with full feature parity..."
            },
            {
              "docId": "2026-01-24_reuters_6949",
              "url": "https://reuters.com/technology/2026/01/24/haystack_mini_palm_3",
              "published": "2026-01-24",
              "snippet": "Haystack Mini announced official support for PaLM 3..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:alpacaeval_2_lite_codex_2_lite_measures",
          "source": "benchmark:alpacaeval_2_lite",
          "target": "model:codex_2_lite",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.97,
          "evidence": [
            {
              "docId": "2026-01-15_techcrunch_4942",
              "url": "https://techcrunch.com/2026/01/15/alpacaeval_2_lite_codex_2_lite",
              "published": "2026-01-15",
              "snippet": "AlpacaEval 2 Lite provides standardized evaluation of Codex 2 Lite..."
            },
            {
              "docId": "2026-01-19_weights_and_bia_6387",
              "url": "https://wandb.ai/articles/2026/01/19/alpacaeval_2_lite_codex_2_lite",
              "published": "2026-01-19",
              "snippet": "The AlpacaEval 2 Lite benchmark measures Codex 2 Lite across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:localai_next_langchain_integrates_with",
          "source": "tool:localai_next",
          "target": "tool:langchain",
          "rel": "INTEGRATES_WITH",
          "kind": "hypothesis",
          "confidence": 0.68
        }
      },
      {
        "data": {
          "id": "e:crewai_core_synthetic_data_generation_uses_tech",
          "source": "tool:crewai_core",
          "target": "tech:synthetic_data_generation",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.67
        }
      },
      {
        "data": {
          "id": "e:arc_agi_falcon_3_measures",
          "source": "benchmark:arc_agi",
          "target": "model:falcon_3",
          "rel": "MEASURES",
          "kind": "inferred",
          "confidence": 0.98
        }
      },
      {
        "data": {
          "id": "e:gpt4all_phi_4_lite_integrates_with",
          "source": "repo:gpt4all",
          "target": "model:phi_4_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:alpacaeval_2_lite_command_r_plus_lite_measures",
          "source": "benchmark:alpacaeval_2_lite",
          "target": "model:command_r_plus_lite",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.93,
          "evidence": [
            {
              "docId": "2026-01-19_nvidia_blog_7891",
              "url": "https://blogs.nvidia.com/2026/01/19/alpacaeval_2_lite_command_r_pl",
              "published": "2026-01-19",
              "snippet": "AlpacaEval 2 Lite provides standardized evaluation of Command R+ Lite..."
            },
            {
              "docId": "2026-01-22_bloomberg_6470",
              "url": "https://bloomberg.com/technology/2026/01/22/alpacaeval_2_lite_command_r_pl",
              "published": "2026-01-22",
              "snippet": "The AlpacaEval 2 Lite benchmark measures Command R+ Lite across multiple tasks..."
            },
            {
              "docId": "2026-01-25_bloomberg_4703",
              "url": "https://bloomberg.com/technology/2026/01/25/alpacaeval_2_lite_command_r_pl",
              "published": "2026-01-25",
              "snippet": "AlpacaEval 2 Lite has become the standard for evaluating Command R+ Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:grok_3_ultra_phi_4_ultra_depends_on",
          "source": "model:grok_3_ultra",
          "target": "model:phi_4_ultra",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.67
        }
      },
      {
        "data": {
          "id": "e:mixture_of_experts_meets_instruction_tun_tree_of_thought_lite_uses_tech",
          "source": "paper:mixture_of_experts_meets_instruction_tun",
          "target": "tech:tree_of_thought_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.92
        }
      },
      {
        "data": {
          "id": "e:scaling_data_constrained_language_models_constitutional_ai_ultra_uses_tech",
          "source": "paper:scaling_data_constrained_language_models",
          "target": "tech:constitutional_ai_ultra",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.93
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_llama_4_next_evaluated_on",
          "source": "paper:direct_preference_optimization",
          "target": "model:llama_4_next",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2026-01-25_openai_blog_4229",
              "url": "https://openai.com/blog/2026/01/25/direct_preference_optimization",
              "published": "2026-01-25",
              "snippet": "On the Llama 4 Next benchmark, Direct Preference Optimization scored 87%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:self_play_fine_tuning_for_language_model_aya_3_v2_evaluated_on",
          "source": "paper:self_play_fine_tuning_for_language_model",
          "target": "model:aya_3_v2",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.8
        }
      },
      {
        "data": {
          "id": "e:vllm_edge_distillation_next_uses_tech",
          "source": "tool:vllm_edge",
          "target": "tech:distillation_next",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.61
        }
      },
      {
        "data": {
          "id": "e:llamacpp_lite_command_r_plus_integrates_with",
          "source": "repo:llamacpp_lite",
          "target": "model:command_r_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.76,
          "evidence": [
            {
              "docId": "2026-01-07_anthropic_blog_1735",
              "url": "https://anthropic.com/news/2026/01/07/llamacpp_lite_command_r_plus",
              "published": "2026-01-07",
              "snippet": "llama.cpp Lite announced official support for Command R+..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:retrieval_augmented_generation_for_knowl_chain_of_thought_pro_uses_tech",
          "source": "paper:retrieval_augmented_generation_for_knowl",
          "target": "tech:chain_of_thought_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.94
        }
      },
      {
        "data": {
          "id": "e:gpt_5_mini_midjourney_v7_edge_depends_on",
          "source": "model:gpt_5_mini",
          "target": "model:midjourney_v7_edge",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.47
        }
      },
      {
        "data": {
          "id": "e:grok_3_ultra_synthetic_data_generation_ultra_uses_tech",
          "source": "model:grok_3_ultra",
          "target": "tech:synthetic_data_generation_ultra",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.61
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_ultra_transformer_architecture_edge_uses_tech",
          "source": "paper:direct_preference_optimization_ultra",
          "target": "tech:transformer_architecture_edge",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-12_mit_technology__4741",
              "url": "https://technologyreview.com/2026/01/12/direct_preference_optimization",
              "published": "2026-01-12",
              "snippet": "Under the hood, Direct Preference Optimization Ultra implements Transformer Architecture Edge for improved efficiency..."
            },
            {
              "docId": "2026-01-13_reuters_5225",
              "url": "https://reuters.com/technology/2026/01/13/direct_preference_optimization",
              "published": "2026-01-13",
              "snippet": "Technical details reveal Direct Preference Optimization Ultra relies heavily on Transformer Architecture Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gsm8k_grok_3_plus_measures",
          "source": "benchmark:gsm8k",
          "target": "model:grok_3_plus",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-12_microsoft_resea_7310",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/12/gsm8k_grok_3_plus",
              "published": "2026-01-12",
              "snippet": "GSM8K provides standardized evaluation of Grok-3 Plus..."
            },
            {
              "docId": "2026-01-25_techcrunch_6563",
              "url": "https://techcrunch.com/2026/01/25/gsm8k_grok_3_plus",
              "published": "2026-01-25",
              "snippet": "GSM8K has become the standard for evaluating Grok-3 Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_v2_kv_cache_optimization_uses_tech",
          "source": "model:palm_3_v2",
          "target": "tech:kv_cache_optimization",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_edge_refinedweb_ultra_trained_on",
          "source": "model:claude_opus_45_edge",
          "target": "dataset:refinedweb_ultra",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.68,
          "evidence": [
            {
              "docId": "2026-01-17_openai_blog_4440",
              "url": "https://openai.com/blog/2026/01/17/claude_opus_45_edge_refinedweb",
              "published": "2026-01-17",
              "snippet": "Claude Opus 4.5 Edge was trained on RefinedWeb Ultra comprising billions of tokens..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:autogpt_claude_opus_45_pro_integrates_with",
          "source": "repo:autogpt",
          "target": "model:claude_opus_45_pro",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.82,
          "evidence": [
            {
              "docId": "2026-01-19_openai_blog_6775",
              "url": "https://openai.com/blog/2026/01/19/autogpt_claude_opus_45_pro",
              "published": "2026-01-19",
              "snippet": "AutoGPT announced official support for Claude Opus 4.5 Pro..."
            },
            {
              "docId": "2026-01-21_venturebeat_2340",
              "url": "https://venturebeat.com/2026/01/21/autogpt_claude_opus_45_pro",
              "published": "2026-01-21",
              "snippet": "AutoGPT now supports Claude Opus 4.5 Pro with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:wikipedia_dump_2025_qlora_uses_tech",
          "source": "dataset:wikipedia_dump_2025",
          "target": "tech:qlora",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.56
        }
      },
      {
        "data": {
          "id": "e:gpt_4o_mini_2_constitutional_ai_uses_tech",
          "source": "model:gpt_4o_mini_2",
          "target": "tech:constitutional_ai",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-16_the_gradient_5247",
              "url": "https://thegradient.pub/2026/01/16/gpt_4o_mini_2_constitutional_a",
              "published": "2026-01-16",
              "snippet": "Under the hood, GPT-4o Mini 2 implements Constitutional AI for improved efficiency..."
            },
            {
              "docId": "2026-01-19_google_ai_blog_7593",
              "url": "https://blog.google/technology/ai/2026/01/19/gpt_4o_mini_2_constitutional_a",
              "published": "2026-01-19",
              "snippet": "GPT-4o Mini 2 leverages Constitutional AI to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-21_google_ai_blog_3789",
              "url": "https://blog.google/technology/ai/2026/01/21/gpt_4o_mini_2_constitutional_a",
              "published": "2026-01-21",
              "snippet": "GPT-4o Mini 2 leverages Constitutional AI to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-22_microsoft_resea_7505",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/22/gpt_4o_mini_2_constitutional_a",
              "published": "2026-01-22",
              "snippet": "Technical details reveal GPT-4o Mini 2 relies heavily on Constitutional AI..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:jamba_2_lite_bigbench_hard_evaluated_on",
          "source": "model:jamba_2_lite",
          "target": "benchmark:bigbench_hard",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-17_google_ai_blog_6898",
              "url": "https://blog.google/technology/ai/2026/01/17/jamba_2_lite_bigbench_hard",
              "published": "2026-01-17",
              "snippet": "Jamba 2 Lite achieves 96% on BigBench Hard, setting a new record..."
            },
            {
              "docId": "2026-01-20_google_ai_blog_7555",
              "url": "https://blog.google/technology/ai/2026/01/20/jamba_2_lite_bigbench_hard",
              "published": "2026-01-20",
              "snippet": "Jamba 2 Lite achieves 92% on BigBench Hard, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:lora:_low_rank_adaptation_of_large_langu_mixtral_8x22b_evaluated_on",
          "source": "paper:lora:_low_rank_adaptation_of_large_langu",
          "target": "model:mixtral_8x22b",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.76,
          "evidence": [
            {
              "docId": "2026-01-19_ars_technica_9732",
              "url": "https://arstechnica.com/2026/01/19/lora:_low_rank_adaptation_of_l",
              "published": "2026-01-19",
              "snippet": "LoRA: Low-Rank Adaptation of Large Language Models achieves 97% on Mixtral 8x22B, setting a new record..."
            },
            {
              "docId": "2026-01-23_microsoft_resea_6480",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/23/lora:_low_rank_adaptation_of_l",
              "published": "2026-01-23",
              "snippet": "LoRA: Low-Rank Adaptation of Large Language Models achieves 79% on Mixtral 8x22B, setting a new record..."
            },
            {
              "docId": "2026-01-25_meta_ai_blog_1372",
              "url": "https://ai.meta.com/blog/2026/01/25/lora:_low_rank_adaptation_of_l",
              "published": "2026-01-25",
              "snippet": "LoRA: Low-Rank Adaptation of Large Language Models achieves 88% on Mixtral 8x22B, setting a new record..."
            },
            {
              "docId": "2026-01-25_wired_9457",
              "url": "https://wired.com/2026/01/25/lora:_low_rank_adaptation_of_l",
              "published": "2026-01-25",
              "snippet": "On the Mixtral 8x22B benchmark, LoRA: Low-Rank Adaptation of Large Language Models scored 99%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:ollama_speculative_decoding_plus_uses_tech",
          "source": "repo:ollama",
          "target": "tech:speculative_decoding_plus",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2025-12-26_reuters_2457",
              "url": "https://reuters.com/technology/2025/12/26/ollama_speculative_decoding_pl",
              "published": "2025-12-26",
              "snippet": "Under the hood, ollama implements Speculative Decoding Plus for improved efficiency..."
            },
            {
              "docId": "2026-01-22_anthropic_blog_8500",
              "url": "https://anthropic.com/news/2026/01/22/ollama_speculative_decoding_pl",
              "published": "2026-01-22",
              "snippet": "ollama leverages Speculative Decoding Plus to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-24_meta_ai_blog_7252",
              "url": "https://ai.meta.com/blog/2026/01/24/ollama_speculative_decoding_pl",
              "published": "2026-01-24",
              "snippet": "Under the hood, ollama implements Speculative Decoding Plus for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gemma_3_the_stack_v2_trained_on",
          "source": "model:gemma_3",
          "target": "dataset:the_stack_v2",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:gemini_ultra_2_max_mt_bench_evaluated_on",
          "source": "model:gemini_ultra_2_max",
          "target": "benchmark:mt_bench",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-25_anthropic_blog_2193",
              "url": "https://anthropic.com/news/2026/01/25/gemini_ultra_2_max_mt_bench",
              "published": "2026-01-25",
              "snippet": "On the MT-Bench benchmark, Gemini Ultra 2 Max scored 98%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_max_midjourney_v7_edge_depends_on",
          "source": "model:claude_opus_45_max",
          "target": "model:midjourney_v7_edge",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:flowise_max_speculative_decoding_uses_tech",
          "source": "tool:flowise_max",
          "target": "tech:speculative_decoding",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.85
        }
      },
      {
        "data": {
          "id": "e:palm_3_ultra_mixture_of_experts_max_uses_tech",
          "source": "model:palm_3_ultra",
          "target": "tech:mixture_of_experts_max",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.69
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_max_group_query_attention_v2_uses_tech",
          "source": "model:claude_opus_45_max",
          "target": "tech:group_query_attention_v2",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.77,
          "evidence": [
            {
              "docId": "2025-12-18_openai_blog_1809",
              "url": "https://openai.com/blog/2025/12/18/claude_opus_45_max_group_query",
              "published": "2025-12-18",
              "snippet": "Technical details reveal Claude Opus 4.5 Max relies heavily on Group Query Attention v2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:scaling_laws_for_neural_language_models__claude_sonnet_4_edge_evaluated_on",
          "source": "paper:scaling_laws_for_neural_language_models_",
          "target": "model:claude_sonnet_4_edge",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.74,
          "evidence": [
            {
              "docId": "2026-01-02_microsoft_resea_5607",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/02/scaling_laws_for_neural_langua",
              "published": "2026-01-02",
              "snippet": "Evaluation results show Scaling Laws for Neural Language Models (2025) reaching 86% on Claude Sonnet 4 Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:qwen_3_ultra_dolma_next_trained_on",
          "source": "model:qwen_3_ultra",
          "target": "dataset:dolma_next",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.86
        }
      },
      {
        "data": {
          "id": "e:transformers_next_gpt_4o_mini_2_ultra_integrates_with",
          "source": "repo:transformers_next",
          "target": "model:gpt_4o_mini_2_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-15_google_ai_blog_9156",
              "url": "https://blog.google/technology/ai/2026/01/15/transformers_next_gpt_4o_mini_",
              "published": "2026-01-15",
              "snippet": "The latest release of transformers Next adds native GPT-4o Mini 2 Ultra integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:ollama_palm_3_ultra_integrates_with",
          "source": "repo:ollama",
          "target": "model:palm_3_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:open_interpreter_yi_large_lite_integrates_with",
          "source": "repo:open_interpreter",
          "target": "model:yi_large_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.84
        }
      },
      {
        "data": {
          "id": "e:copilot_langchain_plus_integrates_with",
          "source": "tool:copilot",
          "target": "tool:langchain_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2025-12-25_mit_technology__3197",
              "url": "https://technologyreview.com/2025/12/25/copilot_langchain_plus",
              "published": "2025-12-25",
              "snippet": "Copilot announced official support for LangChain Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:claude_sonnet_4_edge_mc4_trained_on",
          "source": "model:claude_sonnet_4_edge",
          "target": "dataset:mc4",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.61
        }
      },
      {
        "data": {
          "id": "e:phi_4_mini_claude_opus_45_edge_depends_on",
          "source": "model:phi_4_mini",
          "target": "model:claude_opus_45_edge",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:transformers_next_codex_2_pro_integrates_with",
          "source": "repo:transformers_next",
          "target": "model:codex_2_pro",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.76,
          "evidence": [
            {
              "docId": "2025-12-31_wired_5641",
              "url": "https://wired.com/2025/12/31/transformers_next_codex_2_pro",
              "published": "2025-12-31",
              "snippet": "transformers Next now supports Codex 2 Pro with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:swe_bench_next_llama_4_next_measures",
          "source": "benchmark:swe_bench_next",
          "target": "model:llama_4_next",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2026-01-25_nvidia_blog_4624",
              "url": "https://blogs.nvidia.com/2026/01/25/swe_bench_next_llama_4_next",
              "published": "2026-01-25",
              "snippet": "The SWE-bench Next benchmark measures Llama 4 Next across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:cursor_kv_cache_optimization_max_uses_tech",
          "source": "tool:cursor",
          "target": "tech:kv_cache_optimization_max",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.79
        }
      },
      {
        "data": {
          "id": "e:the_stack_v2_ultra_synthetic_data_generation_uses_tech",
          "source": "dataset:the_stack_v2_ultra",
          "target": "tech:synthetic_data_generation",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.64
        }
      },
      {
        "data": {
          "id": "e:dolma_retrieval_augmented_generation_uses_tech",
          "source": "dataset:dolma",
          "target": "tech:retrieval_augmented_generation",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.55
        }
      },
      {
        "data": {
          "id": "e:jamba_2_multimodal_fusion_plus_uses_tech",
          "source": "model:jamba_2",
          "target": "tech:multimodal_fusion_plus",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.83
        }
      },
      {
        "data": {
          "id": "e:phi_4_ultra_palm_3_ultra_depends_on",
          "source": "model:phi_4_ultra",
          "target": "model:palm_3_ultra",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:phi_4_dolma_next_trained_on",
          "source": "model:phi_4",
          "target": "dataset:dolma_next",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.53
        }
      },
      {
        "data": {
          "id": "e:ollama_llama_4_integrates_with",
          "source": "repo:ollama",
          "target": "model:llama_4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-19_ars_technica_8609",
              "url": "https://arstechnica.com/2026/01/19/ollama_llama_4",
              "published": "2026-01-19",
              "snippet": "The latest release of ollama adds native Llama 4 integration..."
            },
            {
              "docId": "2026-01-21_techcrunch_4160",
              "url": "https://techcrunch.com/2026/01/21/ollama_llama_4",
              "published": "2026-01-21",
              "snippet": "The latest release of ollama adds native Llama 4 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:streamlit_pro_langchain_integrates_with",
          "source": "tool:streamlit_pro",
          "target": "tool:langchain",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.8
        }
      },
      {
        "data": {
          "id": "e:alpacaeval_2_llama_4_max_measures",
          "source": "benchmark:alpacaeval_2",
          "target": "model:llama_4_max",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.95,
          "evidence": [
            {
              "docId": "2026-01-20_ars_technica_5049",
              "url": "https://arstechnica.com/2026/01/20/alpacaeval_2_llama_4_max",
              "published": "2026-01-20",
              "snippet": "AlpacaEval 2 has become the standard for evaluating Llama 4 Max..."
            },
            {
              "docId": "2026-01-20_openai_blog_2135",
              "url": "https://openai.com/blog/2026/01/20/alpacaeval_2_llama_4_max",
              "published": "2026-01-20",
              "snippet": "AlpacaEval 2 provides standardized evaluation of Llama 4 Max..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:haystack_core_ollama_edge_integrates_with",
          "source": "tool:haystack_core",
          "target": "tool:ollama_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.59
        }
      },
      {
        "data": {
          "id": "e:mixture_of_experts_meets_instruction_tun_constitutional_ai_ultra_uses_tech",
          "source": "paper:mixture_of_experts_meets_instruction_tun",
          "target": "tech:constitutional_ai_ultra",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.79
        }
      },
      {
        "data": {
          "id": "e:swe_bench_palm_3_measures",
          "source": "benchmark:swe_bench",
          "target": "model:palm_3",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.96,
          "evidence": [
            {
              "docId": "2026-01-17_techcrunch_6475",
              "url": "https://techcrunch.com/2026/01/17/swe_bench_palm_3",
              "published": "2026-01-17",
              "snippet": "SWE-bench provides standardized evaluation of PaLM 3..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:midjourney_v7_grok_3_depends_on",
          "source": "model:midjourney_v7",
          "target": "model:grok_3",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.64
        }
      },
      {
        "data": {
          "id": "e:gpqa_command_r_plus_plus_measures",
          "source": "benchmark:gpqa",
          "target": "model:command_r_plus_plus",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.97,
          "evidence": [
            {
              "docId": "2026-01-24_techcrunch_7975",
              "url": "https://techcrunch.com/2026/01/24/gpqa_command_r_plus_plus",
              "published": "2026-01-24",
              "snippet": "The GPQA benchmark measures Command R+ Plus across multiple tasks..."
            },
            {
              "docId": "2026-01-24_hugging_face_bl_9235",
              "url": "https://huggingface.co/blog/2026/01/24/gpqa_command_r_plus_plus",
              "published": "2026-01-24",
              "snippet": "GPQA has become the standard for evaluating Command R+ Plus..."
            },
            {
              "docId": "2026-01-24_reuters_6051",
              "url": "https://reuters.com/technology/2026/01/24/gpqa_command_r_plus_plus",
              "published": "2026-01-24",
              "snippet": "The GPQA benchmark measures Command R+ Plus across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:arc_agi_command_r_plus_measures",
          "source": "benchmark:arc_agi",
          "target": "model:command_r_plus",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-23_arxiv_7187",
              "url": "https://arxiv.org/abs/2026/01/23/arc_agi_command_r_plus",
              "published": "2026-01-23",
              "snippet": "The ARC-AGI benchmark measures Command R+ across multiple tasks..."
            },
            {
              "docId": "2026-01-24_google_ai_blog_4687",
              "url": "https://blog.google/technology/ai/2026/01/24/arc_agi_command_r_plus",
              "published": "2026-01-24",
              "snippet": "ARC-AGI has become the standard for evaluating Command R+..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_edge_gsm8k_evaluated_on",
          "source": "model:dall_e_4_edge",
          "target": "benchmark:gsm8k",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-12_nvidia_blog_3702",
              "url": "https://blogs.nvidia.com/2026/01/12/dall_e_4_edge_gsm8k",
              "published": "2026-01-12",
              "snippet": "DALL-E 4 Edge achieves 91% on GSM8K, setting a new record..."
            },
            {
              "docId": "2026-01-24_meta_ai_blog_5829",
              "url": "https://ai.meta.com/blog/2026/01/24/dall_e_4_edge_gsm8k",
              "published": "2026-01-24",
              "snippet": "On the GSM8K benchmark, DALL-E 4 Edge scored 83%..."
            },
            {
              "docId": "2026-01-24_ars_technica_9628",
              "url": "https://arstechnica.com/2026/01/24/dall_e_4_edge_gsm8k",
              "published": "2026-01-24",
              "snippet": "On the GSM8K benchmark, DALL-E 4 Edge scored 70%..."
            },
            {
              "docId": "2026-01-24_wired_3776",
              "url": "https://wired.com/2026/01/24/dall_e_4_edge_gsm8k",
              "published": "2026-01-24",
              "snippet": "On the GSM8K benchmark, DALL-E 4 Edge scored 92%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:vllm_edge_weights_and_biases_plus_integrates_with",
          "source": "tool:vllm_edge",
          "target": "tool:weights_and_biases_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.57
        }
      },
      {
        "data": {
          "id": "e:gsm8k_core_dall_e_4_edge_measures",
          "source": "benchmark:gsm8k_core",
          "target": "model:dall_e_4_edge",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-19_venturebeat_6875",
              "url": "https://venturebeat.com/2026/01/19/gsm8k_core_dall_e_4_edge",
              "published": "2026-01-19",
              "snippet": "GSM8K Core provides standardized evaluation of DALL-E 4 Edge..."
            },
            {
              "docId": "2026-01-22_reuters_1092",
              "url": "https://reuters.com/technology/2026/01/22/gsm8k_core_dall_e_4_edge",
              "published": "2026-01-22",
              "snippet": "GSM8K Core provides standardized evaluation of DALL-E 4 Edge..."
            },
            {
              "docId": "2026-01-22_ars_technica_7121",
              "url": "https://arstechnica.com/2026/01/22/gsm8k_core_dall_e_4_edge",
              "published": "2026-01-22",
              "snippet": "GSM8K Core has become the standard for evaluating DALL-E 4 Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:alpacaeval_2_whisper_v4_next_measures",
          "source": "benchmark:alpacaeval_2",
          "target": "model:whisper_v4_next",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-25_reuters_3625",
              "url": "https://reuters.com/technology/2026/01/25/alpacaeval_2_whisper_v4_next",
              "published": "2026-01-25",
              "snippet": "AlpacaEval 2 provides standardized evaluation of Whisper v4 Next..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_pro_nemotron_5_evaluated_on",
          "source": "paper:llm_agents:_a_survey_pro",
          "target": "model:nemotron_5",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-02_ars_technica_8460",
              "url": "https://arstechnica.com/2026/01/02/llm_agents:_a_survey_pro_nemot",
              "published": "2026-01-02",
              "snippet": "On the Nemotron-5 benchmark, LLM Agents: A Survey Pro scored 92%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mc4_rotary_position_embedding_pro_uses_tech",
          "source": "dataset:mc4",
          "target": "tech:rotary_position_embedding_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.43
        }
      },
      {
        "data": {
          "id": "e:llamaindex_core_sliding_window_attention_pro_uses_tech",
          "source": "tool:llamaindex_core",
          "target": "tech:sliding_window_attention_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.69
        }
      },
      {
        "data": {
          "id": "e:llama_4_next_slimpajama_trained_on",
          "source": "model:llama_4_next",
          "target": "dataset:slimpajama",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.68
        }
      },
      {
        "data": {
          "id": "e:tree_of_thoughts:_deliberate_problem_sol_gemini_ultra_2_edge_evaluated_on",
          "source": "paper:tree_of_thoughts:_deliberate_problem_sol",
          "target": "model:gemini_ultra_2_edge",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.86
        }
      },
      {
        "data": {
          "id": "e:mbpp_midjourney_v7_measures",
          "source": "benchmark:mbpp",
          "target": "model:midjourney_v7",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.97,
          "evidence": [
            {
              "docId": "2025-12-22_the_gradient_9591",
              "url": "https://thegradient.pub/2025/12/22/mbpp_midjourney_v7",
              "published": "2025-12-22",
              "snippet": "The MBPP benchmark measures Midjourney V7 across multiple tasks..."
            },
            {
              "docId": "2026-01-17_nvidia_blog_5514",
              "url": "https://blogs.nvidia.com/2026/01/17/mbpp_midjourney_v7",
              "published": "2026-01-17",
              "snippet": "MBPP has become the standard for evaluating Midjourney V7..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_ultra_codex_2_lite_evaluated_on",
          "source": "paper:direct_preference_optimization_ultra",
          "target": "model:codex_2_lite",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.79
        }
      },
      {
        "data": {
          "id": "e:stable_diffusion_4_lora_core_uses_tech",
          "source": "model:stable_diffusion_4",
          "target": "tech:lora_core",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.73
        }
      },
      {
        "data": {
          "id": "e:cody_gemini_ultra_2_max_integrates_with",
          "source": "tool:cody",
          "target": "model:gemini_ultra_2_max",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2025-12-11_bloomberg_7617",
              "url": "https://bloomberg.com/technology/2025/12/11/cody_gemini_ultra_2_max",
              "published": "2025-12-11",
              "snippet": "The latest release of Cody adds native Gemini Ultra 2 Max integration..."
            },
            {
              "docId": "2025-12-29_hugging_face_bl_3147",
              "url": "https://huggingface.co/blog/2025/12/29/cody_gemini_ultra_2_max",
              "published": "2025-12-29",
              "snippet": "Cody now supports Gemini Ultra 2 Max with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:weights_and_biases_core_kv_cache_optimization_next_uses_tech",
          "source": "tool:weights_and_biases_core",
          "target": "tech:kv_cache_optimization_next",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:weights_and_biases_core_chain_of_thought_uses_tech",
          "source": "tool:weights_and_biases_core",
          "target": "tech:chain_of_thought",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.88
        }
      },
      {
        "data": {
          "id": "e:sora_2_openwebtext2_mini_trained_on",
          "source": "model:sora_2",
          "target": "dataset:openwebtext2_mini",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.9,
          "evidence": [
            {
              "docId": "2026-01-25_meta_ai_blog_1131",
              "url": "https://ai.meta.com/blog/2026/01/25/sora_2_openwebtext2_mini",
              "published": "2026-01-25",
              "snippet": "Sora 2 was trained on OpenWebText2 Mini comprising billions of tokens..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:starcoder_data_group_query_attention_uses_tech",
          "source": "dataset:starcoder_data",
          "target": "tech:group_query_attention",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.6
        }
      },
      {
        "data": {
          "id": "e:jamba_2_constitutional_ai_uses_tech",
          "source": "model:jamba_2",
          "target": "tech:constitutional_ai",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.88
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_lite_sora_2_max_depends_on",
          "source": "model:dall_e_4_lite",
          "target": "model:sora_2_max",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.52
        }
      },
      {
        "data": {
          "id": "e:vllm_v2_mixture_of_experts_max_uses_tech",
          "source": "repo:vllm_v2",
          "target": "tech:mixture_of_experts_max",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.77
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_ultra_palm_3_max_evaluated_on",
          "source": "paper:direct_preference_optimization_ultra",
          "target": "model:palm_3_max",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-19_techcrunch_2083",
              "url": "https://techcrunch.com/2026/01/19/direct_preference_optimization",
              "published": "2026-01-19",
              "snippet": "On the PaLM 3 Max benchmark, Direct Preference Optimization Ultra scored 90%..."
            },
            {
              "docId": "2026-01-21_nextgov_9502",
              "url": "https://nextgov.com/2026/01/21/direct_preference_optimization",
              "published": "2026-01-21",
              "snippet": "Evaluation results show Direct Preference Optimization Ultra reaching 81% on PaLM 3 Max..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_claude_sonnet_4_integrates_with",
          "source": "repo:langchain",
          "target": "model:claude_sonnet_4",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.83
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_plus_synthetic_data_generation_uses_tech",
          "source": "model:dall_e_4_plus",
          "target": "tech:synthetic_data_generation",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.58,
          "evidence": [
            {
              "docId": "2025-11-02_nextgov_8970",
              "url": "https://nextgov.com/2025/11/02/dall_e_4_plus_synthetic_data_g",
              "published": "2025-11-02",
              "snippet": "Under the hood, DALL-E 4 Plus implements Synthetic Data Generation for improved efficiency..."
            },
            {
              "docId": "2025-12-23_the_verge_5087",
              "url": "https://theverge.com/2025/12/23/dall_e_4_plus_synthetic_data_g",
              "published": "2025-12-23",
              "snippet": "Technical details reveal DALL-E 4 Plus relies heavily on Synthetic Data Generation..."
            },
            {
              "docId": "2026-01-02_nvidia_blog_4030",
              "url": "https://blogs.nvidia.com/2026/01/02/dall_e_4_plus_synthetic_data_g",
              "published": "2026-01-02",
              "snippet": "DALL-E 4 Plus leverages Synthetic Data Generation to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt_4o_mini_2_ultra_arc_agi_lite_evaluated_on",
          "source": "model:gpt_4o_mini_2_ultra",
          "target": "benchmark:arc_agi_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.98,
          "evidence": [
            {
              "docId": "2026-01-20_nextgov_1915",
              "url": "https://nextgov.com/2026/01/20/gpt_4o_mini_2_ultra_arc_agi_li",
              "published": "2026-01-20",
              "snippet": "On the ARC-AGI Lite benchmark, GPT-4o Mini 2 Ultra scored 72%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:codex_2_pro_llama_4_depends_on",
          "source": "model:codex_2_pro",
          "target": "model:llama_4",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.61
        }
      },
      {
        "data": {
          "id": "e:weights_and_biases_core_localai_next_integrates_with",
          "source": "tool:weights_and_biases_core",
          "target": "tool:localai_next",
          "rel": "INTEGRATES_WITH",
          "kind": "hypothesis",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:tensorrt_llm_next_quantization_uses_tech",
          "source": "tool:tensorrt_llm_next",
          "target": "tech:quantization",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.69,
          "evidence": [
            {
              "docId": "2026-01-14_techcrunch_5392",
              "url": "https://techcrunch.com/2026/01/14/tensorrt_llm_next_quantization",
              "published": "2026-01-14",
              "snippet": "Under the hood, TensorRT-LLM Next implements Quantization for improved efficiency..."
            },
            {
              "docId": "2026-01-18_hugging_face_bl_7955",
              "url": "https://huggingface.co/blog/2026/01/18/tensorrt_llm_next_quantization",
              "published": "2026-01-18",
              "snippet": "TensorRT-LLM Next leverages Quantization to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:falcon_3_v2_gpqa_next_evaluated_on",
          "source": "model:falcon_3_v2",
          "target": "benchmark:gpqa_next",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.82,
          "evidence": [
            {
              "docId": "2026-01-22_arxiv_8189",
              "url": "https://arxiv.org/abs/2026/01/22/falcon_3_v2_gpqa_next",
              "published": "2026-01-22",
              "snippet": "Falcon 3 v2 achieves 95% on GPQA Next, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:haystack_aya_3_integrates_with",
          "source": "tool:haystack",
          "target": "model:aya_3",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-24_bloomberg_5995",
              "url": "https://bloomberg.com/technology/2026/01/24/haystack_aya_3",
              "published": "2026-01-24",
              "snippet": "Haystack now supports Aya 3 with full feature parity..."
            },
            {
              "docId": "2026-01-24_nextgov_6081",
              "url": "https://nextgov.com/2026/01/24/haystack_aya_3",
              "published": "2026-01-24",
              "snippet": "The latest release of Haystack adds native Aya 3 integration..."
            },
            {
              "docId": "2026-01-25_hugging_face_bl_9564",
              "url": "https://huggingface.co/blog/2026/01/25/haystack_aya_3",
              "published": "2026-01-25",
              "snippet": "Haystack announced official support for Aya 3..."
            },
            {
              "docId": "2026-01-25_venturebeat_3168",
              "url": "https://venturebeat.com/2026/01/25/haystack_aya_3",
              "published": "2026-01-25",
              "snippet": "Haystack now supports Aya 3 with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:streamlit_litellm_integrates_with",
          "source": "tool:streamlit",
          "target": "tool:litellm",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2026-01-24_anthropic_blog_6498",
              "url": "https://anthropic.com/news/2026/01/24/streamlit_litellm",
              "published": "2026-01-24",
              "snippet": "Streamlit now supports LiteLLM with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:arc_agi_phi_4_mini_measures",
          "source": "benchmark:arc_agi",
          "target": "model:phi_4_mini",
          "rel": "MEASURES",
          "kind": "inferred",
          "confidence": 0.95
        }
      },
      {
        "data": {
          "id": "e:textbooks_are_all_you_need_sparse_attention_lite_uses_tech",
          "source": "paper:textbooks_are_all_you_need",
          "target": "tech:sparse_attention_lite",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-25_openai_blog_9671",
              "url": "https://openai.com/blog/2026/01/25/textbooks_are_all_you_need_spa",
              "published": "2026-01-25",
              "snippet": "Under the hood, Textbooks Are All You Need implements Sparse Attention Lite for improved efficiency..."
            },
            {
              "docId": "2026-01-25_hugging_face_bl_2396",
              "url": "https://huggingface.co/blog/2026/01/25/textbooks_are_all_you_need_spa",
              "published": "2026-01-25",
              "snippet": "Technical details reveal Textbooks Are All You Need relies heavily on Sparse Attention Lite..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_phi_4_evaluated_on",
          "source": "paper:llm_agents:_a_survey",
          "target": "model:phi_4",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.75,
          "evidence": [
            {
              "docId": "2026-01-19_arxiv_4525",
              "url": "https://arxiv.org/abs/2026/01/19/llm_agents:_a_survey_phi_4",
              "published": "2026-01-19",
              "snippet": "LLM Agents: A Survey achieves 94% on Phi-4, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:chain_of_thought_prompting_elicits_reaso_claude_opus_45_pro_evaluated_on",
          "source": "paper:chain_of_thought_prompting_elicits_reaso",
          "target": "model:claude_opus_45_pro",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-23_google_ai_blog_4971",
              "url": "https://blog.google/technology/ai/2026/01/23/chain_of_thought_prompting_eli",
              "published": "2026-01-23",
              "snippet": "On the Claude Opus 4.5 Pro benchmark, Chain-of-Thought Prompting Elicits Reasoning scored 84%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:nemotron_5_stable_diffusion_4_depends_on",
          "source": "model:nemotron_5",
          "target": "model:stable_diffusion_4",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.74
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_ultra_gpt_4o_mini_2_ultra_evaluated_on",
          "source": "paper:direct_preference_optimization_ultra",
          "target": "model:gpt_4o_mini_2_ultra",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.72,
          "evidence": [
            {
              "docId": "2026-01-25_reuters_2232",
              "url": "https://reuters.com/technology/2026/01/25/direct_preference_optimization",
              "published": "2026-01-25",
              "snippet": "Evaluation results show Direct Preference Optimization Ultra reaching 94% on GPT-4o Mini 2 Ultra..."
            },
            {
              "docId": "2026-01-25_nextgov_9503",
              "url": "https://nextgov.com/2026/01/25/direct_preference_optimization",
              "published": "2026-01-25",
              "snippet": "Direct Preference Optimization Ultra achieves 72% on GPT-4o Mini 2 Ultra, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:scaling_data_constrained_language_models_quantization_uses_tech",
          "source": "paper:scaling_data_constrained_language_models",
          "target": "tech:quantization",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.89
        }
      },
      {
        "data": {
          "id": "e:mt_bench_v2_palm_3_v2_measures",
          "source": "benchmark:mt_bench_v2",
          "target": "model:palm_3_v2",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.95,
          "evidence": [
            {
              "docId": "2025-12-26_arxiv_5266",
              "url": "https://arxiv.org/abs/2025/12/26/mt_bench_v2_palm_3_v2",
              "published": "2025-12-26",
              "snippet": "The MT-Bench v2 benchmark measures PaLM 3 v2 across multiple tasks..."
            },
            {
              "docId": "2025-12-30_hugging_face_bl_4455",
              "url": "https://huggingface.co/blog/2025/12/30/mt_bench_v2_palm_3_v2",
              "published": "2025-12-30",
              "snippet": "MT-Bench v2 has become the standard for evaluating PaLM 3 v2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:refinedweb_ultra_speculative_decoding_plus_uses_tech",
          "source": "dataset:refinedweb_ultra",
          "target": "tech:speculative_decoding_plus",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.77
        }
      },
      {
        "data": {
          "id": "e:vllm_v2_mixtral_8x22b_core_integrates_with",
          "source": "repo:vllm_v2",
          "target": "model:mixtral_8x22b_core",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.74,
          "evidence": [
            {
              "docId": "2026-01-23_hugging_face_bl_6922",
              "url": "https://huggingface.co/blog/2026/01/23/vllm_v2_mixtral_8x22b_core",
              "published": "2026-01-23",
              "snippet": "vllm v2 announced official support for Mixtral 8x22B Core..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mixtral_8x22b_gemma_3_depends_on",
          "source": "model:mixtral_8x22b",
          "target": "model:gemma_3",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:mlflow_dpo_uses_tech",
          "source": "tool:mlflow",
          "target": "tech:dpo",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-24_ars_technica_2260",
              "url": "https://arstechnica.com/2026/01/24/mlflow_dpo",
              "published": "2026-01-24",
              "snippet": "Under the hood, MLflow implements DPO for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:jamba_2_edge_gemma_3_depends_on",
          "source": "model:jamba_2_edge",
          "target": "model:gemma_3",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.69
        }
      },
      {
        "data": {
          "id": "e:attention_is_all_you_need_v2_v2_red_teaming_uses_tech",
          "source": "paper:attention_is_all_you_need_v2_v2",
          "target": "tech:red_teaming",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.89
        }
      },
      {
        "data": {
          "id": "e:langchain_sliding_window_attention_pro_uses_tech",
          "source": "repo:langchain",
          "target": "tech:sliding_window_attention_pro",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2025-12-10_langchain_blog_1687",
              "url": "https://blog.langchain.dev/2025/12/10/langchain_sliding_window_atten",
              "published": "2025-12-10",
              "snippet": "langchain leverages Sliding Window Attention Pro to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_v2_lmsys_chatbot_arena_lite_evaluated_on",
          "source": "model:palm_3_v2",
          "target": "benchmark:lmsys_chatbot_arena_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-12_openai_blog_6009",
              "url": "https://openai.com/blog/2026/01/12/palm_3_v2_lmsys_chatbot_arena_",
              "published": "2026-01-12",
              "snippet": "PaLM 3 v2 achieves 70% on LMSYS Chatbot Arena Lite, setting a new record..."
            },
            {
              "docId": "2026-01-25_wired_4738",
              "url": "https://wired.com/2026/01/25/palm_3_v2_lmsys_chatbot_arena_",
              "published": "2026-01-25",
              "snippet": "PaLM 3 v2 achieves 92% on LMSYS Chatbot Arena Lite, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:lmsys_chatbot_arena_lite_llama_4_measures",
          "source": "benchmark:lmsys_chatbot_arena_lite",
          "target": "model:llama_4",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.95,
          "evidence": [
            {
              "docId": "2026-01-20_venturebeat_7872",
              "url": "https://venturebeat.com/2026/01/20/lmsys_chatbot_arena_lite_llama",
              "published": "2026-01-20",
              "snippet": "LMSYS Chatbot Arena Lite provides standardized evaluation of Llama 4..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:laion_5b_lora_uses_tech",
          "source": "dataset:laion_5b",
          "target": "tech:lora",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.7
        }
      },
      {
        "data": {
          "id": "e:stable_diffusion_4_the_pile_core_trained_on",
          "source": "model:stable_diffusion_4",
          "target": "dataset:the_pile_core",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.46,
          "evidence": [
            {
              "docId": "2026-01-01_anthropic_blog_4763",
              "url": "https://anthropic.com/news/2026/01/01/stable_diffusion_4_the_pile_co",
              "published": "2026-01-01",
              "snippet": "Stable Diffusion 4 was trained on The Pile Core comprising billions of tokens..."
            },
            {
              "docId": "2026-01-14_hugging_face_bl_7544",
              "url": "https://huggingface.co/blog/2026/01/14/stable_diffusion_4_the_pile_co",
              "published": "2026-01-14",
              "snippet": "Stable Diffusion 4 was trained on The Pile Core comprising billions of tokens..."
            },
            {
              "docId": "2026-01-24_mit_technology__3948",
              "url": "https://technologyreview.com/2026/01/24/stable_diffusion_4_the_pile_co",
              "published": "2026-01-24",
              "snippet": "Stable Diffusion 4 was trained on The Pile Core comprising billions of tokens..."
            },
            {
              "docId": "2026-01-24_nextgov_1587",
              "url": "https://nextgov.com/2026/01/24/stable_diffusion_4_the_pile_co",
              "published": "2026-01-24",
              "snippet": "Stable Diffusion 4 utilized The Pile Core as part of its pre-training data mix..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:vllm_edge_localai_integrates_with",
          "source": "tool:vllm_edge",
          "target": "tool:localai",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.61
        }
      },
      {
        "data": {
          "id": "e:llama_4_max_codex_2_depends_on",
          "source": "model:llama_4_max",
          "target": "model:codex_2",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:stable_diffusion_4_max_openwebtext2_mini_trained_on",
          "source": "model:stable_diffusion_4_max",
          "target": "dataset:openwebtext2_mini",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-25_bloomberg_7222",
              "url": "https://bloomberg.com/technology/2026/01/25/stable_diffusion_4_max_openweb",
              "published": "2026-01-25",
              "snippet": "The training corpus for Stable Diffusion 4 Max includes OpenWebText2 Mini..."
            },
            {
              "docId": "2026-01-25_techcrunch_8382",
              "url": "https://techcrunch.com/2026/01/25/stable_diffusion_4_max_openweb",
              "published": "2026-01-25",
              "snippet": "The training corpus for Stable Diffusion 4 Max includes OpenWebText2 Mini..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_max_dolma_trained_on",
          "source": "model:palm_3_max",
          "target": "dataset:dolma",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.68,
          "evidence": [
            {
              "docId": "2026-01-21_ars_technica_1553",
              "url": "https://arstechnica.com/2026/01/21/palm_3_max_dolma",
              "published": "2026-01-21",
              "snippet": "PaLM 3 Max utilized Dolma as part of its pre-training data mix..."
            },
            {
              "docId": "2026-01-23_anthropic_blog_3633",
              "url": "https://anthropic.com/news/2026/01/23/palm_3_max_dolma",
              "published": "2026-01-23",
              "snippet": "PaLM 3 Max was trained on Dolma comprising billions of tokens..."
            },
            {
              "docId": "2026-01-23_the_gradient_1104",
              "url": "https://thegradient.pub/2026/01/23/palm_3_max_dolma",
              "published": "2026-01-23",
              "snippet": "PaLM 3 Max utilized Dolma as part of its pre-training data mix..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mbpp_palm_3_ultra_measures",
          "source": "benchmark:mbpp",
          "target": "model:palm_3_ultra",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2025-12-19_venturebeat_3702",
              "url": "https://venturebeat.com/2025/12/19/mbpp_palm_3_ultra",
              "published": "2025-12-19",
              "snippet": "MBPP has become the standard for evaluating PaLM 3 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:grok_3_ultra_roots_core_trained_on",
          "source": "model:grok_3_ultra",
          "target": "dataset:roots_core",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.7
        }
      },
      {
        "data": {
          "id": "e:llamacpp_lite_command_r_plus_lite_integrates_with",
          "source": "repo:llamacpp_lite",
          "target": "model:command_r_plus_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-20_techcrunch_7246",
              "url": "https://techcrunch.com/2026/01/20/llamacpp_lite_command_r_plus_l",
              "published": "2026-01-20",
              "snippet": "llama.cpp Lite now supports Command R+ Lite with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:lora:_low_rank_adaptation_of_large_langu_qlora_uses_tech",
          "source": "paper:lora:_low_rank_adaptation_of_large_langu",
          "target": "tech:qlora",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2025-12-28_ars_technica_7870",
              "url": "https://arstechnica.com/2025/12/28/lora:_low_rank_adaptation_of_l",
              "published": "2025-12-28",
              "snippet": "Technical details reveal LoRA: Low-Rank Adaptation of Large Language Models relies heavily on QLoRA..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt_5_mini_dall_e_4_plus_depends_on",
          "source": "model:gpt_5_mini",
          "target": "model:dall_e_4_plus",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.52
        }
      },
      {
        "data": {
          "id": "e:open_interpreter_midjourney_v7_integrates_with",
          "source": "repo:open_interpreter",
          "target": "model:midjourney_v7",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2025-12-23_arxiv_2358",
              "url": "https://arxiv.org/abs/2025/12/23/open_interpreter_midjourney_v7",
              "published": "2025-12-23",
              "snippet": "open-interpreter now supports Midjourney V7 with full feature parity..."
            },
            {
              "docId": "2026-01-23_nvidia_blog_3577",
              "url": "https://blogs.nvidia.com/2026/01/23/open_interpreter_midjourney_v7",
              "published": "2026-01-23",
              "snippet": "open-interpreter announced official support for Midjourney V7..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:refinedweb_ultra_tool_use_v2_uses_tech",
          "source": "dataset:refinedweb_ultra",
          "target": "tech:tool_use_v2",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.49
        }
      },
      {
        "data": {
          "id": "e:localai_dify_integrates_with",
          "source": "tool:localai",
          "target": "tool:dify",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.8,
          "evidence": [
            {
              "docId": "2026-01-20_venturebeat_5419",
              "url": "https://venturebeat.com/2026/01/20/localai_dify",
              "published": "2026-01-20",
              "snippet": "LocalAI announced official support for Dify..."
            },
            {
              "docId": "2026-01-24_the_gradient_3586",
              "url": "https://thegradient.pub/2026/01/24/localai_dify",
              "published": "2026-01-24",
              "snippet": "LocalAI announced official support for Dify..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:codex_2_ultra_dolma_next_trained_on",
          "source": "model:codex_2_ultra",
          "target": "dataset:dolma_next",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.48
        }
      },
      {
        "data": {
          "id": "e:self_play_fine_tuning_for_language_model_phi_4_ultra_evaluated_on",
          "source": "paper:self_play_fine_tuning_for_language_model",
          "target": "model:phi_4_ultra",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:scaling_data_constrained_language_models_gemini_ultra_2_lite_evaluated_on",
          "source": "paper:scaling_data_constrained_language_models",
          "target": "model:gemini_ultra_2_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-18_meta_ai_blog_5449",
              "url": "https://ai.meta.com/blog/2026/01/18/scaling_data_constrained_langu",
              "published": "2026-01-18",
              "snippet": "On the Gemini Ultra 2 Lite benchmark, Scaling Data-Constrained Language Models scored 97%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamacpp_rotary_position_embedding_uses_tech",
          "source": "repo:llamacpp",
          "target": "tech:rotary_position_embedding",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.79
        }
      },
      {
        "data": {
          "id": "e:copilot_ultra_mixtral_8x22b_edge_integrates_with",
          "source": "tool:copilot_ultra",
          "target": "model:mixtral_8x22b_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.94
        }
      },
      {
        "data": {
          "id": "e:codex_2_pro_whisper_v4_max_depends_on",
          "source": "model:codex_2_pro",
          "target": "model:whisper_v4_max",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.72
        }
      },
      {
        "data": {
          "id": "e:open_interpreter_gpt_4o_mini_2_ultra_integrates_with",
          "source": "repo:open_interpreter",
          "target": "model:gpt_4o_mini_2_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_max_humaneval_edge_evaluated_on",
          "source": "model:claude_opus_45_max",
          "target": "benchmark:humaneval_edge",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2025-12-31_anthropic_blog_3799",
              "url": "https://anthropic.com/news/2025/12/31/claude_opus_45_max_humaneval_e",
              "published": "2025-12-31",
              "snippet": "Evaluation results show Claude Opus 4.5 Max reaching 96% on HumanEval Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:localai_codex_2_pro_integrates_with",
          "source": "repo:localai",
          "target": "model:codex_2_pro",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-18_the_verge_4486",
              "url": "https://theverge.com/2026/01/18/localai_codex_2_pro",
              "published": "2026-01-18",
              "snippet": "The latest release of LocalAI adds native Codex 2 Pro integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:semantic_kernel_mini_cody_pro_integrates_with",
          "source": "tool:semantic_kernel_mini",
          "target": "tool:cody_pro",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.6,
          "evidence": [
            {
              "docId": "2026-01-25_google_ai_blog_6928",
              "url": "https://blog.google/technology/ai/2026/01/25/semantic_kernel_mini_cody_pro",
              "published": "2026-01-25",
              "snippet": "Semantic Kernel Mini announced official support for Cody Pro..."
            },
            {
              "docId": "2026-01-25_venturebeat_2163",
              "url": "https://venturebeat.com/2026/01/25/semantic_kernel_mini_cody_pro",
              "published": "2026-01-25",
              "snippet": "Semantic Kernel Mini announced official support for Cody Pro..."
            },
            {
              "docId": "2026-01-25_the_verge_4172",
              "url": "https://theverge.com/2026/01/25/semantic_kernel_mini_cody_pro",
              "published": "2026-01-25",
              "snippet": "The latest release of Semantic Kernel Mini adds native Cody Pro integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:nemotron_5_flash_attention_uses_tech",
          "source": "model:nemotron_5",
          "target": "tech:flash_attention",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.67,
          "evidence": [
            {
              "docId": "2026-01-07_arxiv_6605",
              "url": "https://arxiv.org/abs/2026/01/07/nemotron_5_flash_attention",
              "published": "2026-01-07",
              "snippet": "Under the hood, Nemotron-5 implements Flash Attention for improved efficiency..."
            },
            {
              "docId": "2026-01-11_techcrunch_9732",
              "url": "https://techcrunch.com/2026/01/11/nemotron_5_flash_attention",
              "published": "2026-01-11",
              "snippet": "Technical details reveal Nemotron-5 relies heavily on Flash Attention..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gemini_ultra_2_lite_stable_diffusion_4_mini_depends_on",
          "source": "model:gemini_ultra_2_lite",
          "target": "model:stable_diffusion_4_mini",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:codex_2_midjourney_v7_depends_on",
          "source": "model:codex_2",
          "target": "model:midjourney_v7",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.53
        }
      },
      {
        "data": {
          "id": "e:cursor_tree_of_thought_uses_tech",
          "source": "tool:cursor",
          "target": "tech:tree_of_thought",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.66,
          "evidence": [
            {
              "docId": "2025-12-17_langchain_blog_1049",
              "url": "https://blog.langchain.dev/2025/12/17/cursor_tree_of_thought",
              "published": "2025-12-17",
              "snippet": "Under the hood, Cursor implements Tree of Thought for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_plus_grok_3_integrates_with",
          "source": "tool:langchain_plus",
          "target": "model:grok_3",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:gsm8k_palm_3_ultra_measures",
          "source": "benchmark:gsm8k",
          "target": "model:palm_3_ultra",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.96,
          "evidence": [
            {
              "docId": "2026-01-25_bloomberg_6912",
              "url": "https://bloomberg.com/technology/2026/01/25/gsm8k_palm_3_ultra",
              "published": "2026-01-25",
              "snippet": "GSM8K provides standardized evaluation of PaLM 3 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:redpajama_v2_kv_cache_optimization_max_uses_tech",
          "source": "dataset:redpajama_v2",
          "target": "tech:kv_cache_optimization_max",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:localai_gguf_uses_tech",
          "source": "repo:localai",
          "target": "tech:gguf",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.69
        }
      },
      {
        "data": {
          "id": "e:localai_palm_3_v2_integrates_with",
          "source": "repo:localai",
          "target": "model:palm_3_v2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.9,
          "evidence": [
            {
              "docId": "2026-01-24_openai_blog_5541",
              "url": "https://openai.com/blog/2026/01/24/localai_palm_3_v2",
              "published": "2026-01-24",
              "snippet": "The latest release of LocalAI adds native PaLM 3 v2 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:jamba_2_nemotron_5_depends_on",
          "source": "model:jamba_2",
          "target": "model:nemotron_5",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.48
        }
      },
      {
        "data": {
          "id": "e:cursor_mixtral_8x22b_core_integrates_with",
          "source": "tool:cursor",
          "target": "model:mixtral_8x22b_core",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2026-01-21_hugging_face_bl_4277",
              "url": "https://huggingface.co/blog/2026/01/21/cursor_mixtral_8x22b_core",
              "published": "2026-01-21",
              "snippet": "Cursor announced official support for Mixtral 8x22B Core..."
            },
            {
              "docId": "2026-01-24_reuters_5287",
              "url": "https://reuters.com/technology/2026/01/24/cursor_mixtral_8x22b_core",
              "published": "2026-01-24",
              "snippet": "The latest release of Cursor adds native Mixtral 8x22B Core integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:phi_4_mini_hellaswag_evaluated_on",
          "source": "model:phi_4_mini",
          "target": "benchmark:hellaswag",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.95,
          "evidence": [
            {
              "docId": "2025-12-16_venturebeat_4503",
              "url": "https://venturebeat.com/2025/12/16/phi_4_mini_hellaswag",
              "published": "2025-12-16",
              "snippet": "Phi-4 Mini achieves 82% on HellaSwag, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:common_crawl_qlora_uses_tech",
          "source": "dataset:common_crawl",
          "target": "tech:qlora",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.5
        }
      },
      {
        "data": {
          "id": "e:ollama_multimodal_fusion_lite_uses_tech",
          "source": "repo:ollama",
          "target": "tech:multimodal_fusion_lite",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.69,
          "evidence": [
            {
              "docId": "2026-01-24_hugging_face_bl_8393",
              "url": "https://huggingface.co/blog/2026/01/24/ollama_multimodal_fusion_lite",
              "published": "2026-01-24",
              "snippet": "Under the hood, ollama implements Multimodal Fusion Lite for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gemma_3_lite_gsm8k_evaluated_on",
          "source": "model:gemma_3_lite",
          "target": "benchmark:gsm8k",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.97,
          "evidence": [
            {
              "docId": "2026-01-25_ars_technica_1529",
              "url": "https://arstechnica.com/2026/01/25/gemma_3_lite_gsm8k",
              "published": "2026-01-25",
              "snippet": "Gemma 3 Lite achieves 99% on GSM8K, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:stable_diffusion_4_max_hellaswag_v2_evaluated_on",
          "source": "model:stable_diffusion_4_max",
          "target": "benchmark:hellaswag_v2",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-25_techcrunch_5473",
              "url": "https://techcrunch.com/2026/01/25/stable_diffusion_4_max_hellasw",
              "published": "2026-01-25",
              "snippet": "On the HellaSwag v2 benchmark, Stable Diffusion 4 Max scored 94%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:haystack_gemma_3_integrates_with",
          "source": "tool:haystack",
          "target": "model:gemma_3",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-24_openai_blog_6982",
              "url": "https://openai.com/blog/2026/01/24/haystack_gemma_3",
              "published": "2026-01-24",
              "snippet": "The latest release of Haystack adds native Gemma 3 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:phi_4_grok_3_ultra_depends_on",
          "source": "model:phi_4",
          "target": "model:grok_3_ultra",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.7
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_constitutional_ai_mini_uses_tech",
          "source": "paper:direct_preference_optimization",
          "target": "tech:constitutional_ai_mini",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.93,
          "evidence": [
            {
              "docId": "2026-01-12_openai_blog_2420",
              "url": "https://openai.com/blog/2026/01/12/direct_preference_optimization",
              "published": "2026-01-12",
              "snippet": "Direct Preference Optimization leverages Constitutional AI Mini to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:flash_attention:_fast_and_memory_efficie_sparse_attention_uses_tech",
          "source": "paper:flash_attention:_fast_and_memory_efficie",
          "target": "tech:sparse_attention",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-25_hugging_face_bl_9979",
              "url": "https://huggingface.co/blog/2026/01/25/flash_attention:_fast_and_memo",
              "published": "2026-01-25",
              "snippet": "Flash Attention: Fast and Memory-Efficient Attention leverages Sparse Attention to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamacpp_lite_mixture_of_experts_uses_tech",
          "source": "repo:llamacpp_lite",
          "target": "tech:mixture_of_experts",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.67,
          "evidence": [
            {
              "docId": "2025-11-22_microsoft_resea_6881",
              "url": "https://microsoft.com/en-us/research/blog/2025/11/22/llamacpp_lite_mixture_of_exper",
              "published": "2025-11-22",
              "snippet": "Technical details reveal llama.cpp Lite relies heavily on Mixture of Experts..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gsm8k_phi_4_mini_measures",
          "source": "benchmark:gsm8k",
          "target": "model:phi_4_mini",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.97,
          "evidence": [
            {
              "docId": "2026-01-09_meta_ai_blog_1461",
              "url": "https://ai.meta.com/blog/2026/01/09/gsm8k_phi_4_mini",
              "published": "2026-01-09",
              "snippet": "The GSM8K benchmark measures Phi-4 Mini across multiple tasks..."
            },
            {
              "docId": "2026-01-13_reuters_5734",
              "url": "https://reuters.com/technology/2026/01/13/gsm8k_phi_4_mini",
              "published": "2026-01-13",
              "snippet": "GSM8K provides standardized evaluation of Phi-4 Mini..."
            },
            {
              "docId": "2026-01-20_google_ai_blog_4049",
              "url": "https://blog.google/technology/ai/2026/01/20/gsm8k_phi_4_mini",
              "published": "2026-01-20",
              "snippet": "GSM8K has become the standard for evaluating Phi-4 Mini..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:swe_bench_falcon_3_v2_measures",
          "source": "benchmark:swe_bench",
          "target": "model:falcon_3_v2",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.98,
          "evidence": [
            {
              "docId": "2026-01-16_the_verge_6550",
              "url": "https://theverge.com/2026/01/16/swe_bench_falcon_3_v2",
              "published": "2026-01-16",
              "snippet": "SWE-bench provides standardized evaluation of Falcon 3 v2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_max_the_pile_core_trained_on",
          "source": "model:claude_opus_45_max",
          "target": "dataset:the_pile_core",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.84
        }
      },
      {
        "data": {
          "id": "e:roots_core_chain_of_thought_uses_tech",
          "source": "dataset:roots_core",
          "target": "tech:chain_of_thought",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.45
        }
      },
      {
        "data": {
          "id": "e:cody_pro_langchain_plus_integrates_with",
          "source": "tool:cody_pro",
          "target": "tool:langchain_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "hypothesis",
          "confidence": 0.83
        }
      },
      {
        "data": {
          "id": "e:vllm_edge_deepseek_v3_plus_integrates_with",
          "source": "tool:vllm_edge",
          "target": "model:deepseek_v3_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.93,
          "evidence": [
            {
              "docId": "2025-12-29_anthropic_blog_2313",
              "url": "https://anthropic.com/news/2025/12/29/vllm_edge_deepseek_v3_plus",
              "published": "2025-12-29",
              "snippet": "The latest release of vLLM Edge adds native DeepSeek-V3 Plus integration..."
            },
            {
              "docId": "2026-01-16_weights_and_bia_1164",
              "url": "https://wandb.ai/articles/2026/01/16/vllm_edge_deepseek_v3_plus",
              "published": "2026-01-16",
              "snippet": "The latest release of vLLM Edge adds native DeepSeek-V3 Plus integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:refinedweb_tokenizer_bpe_next_uses_tech",
          "source": "dataset:refinedweb",
          "target": "tech:tokenizer_bpe_next",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.5
        }
      },
      {
        "data": {
          "id": "e:vllm_yi_large_v2_integrates_with",
          "source": "repo:vllm",
          "target": "model:yi_large_v2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.7,
          "evidence": [
            {
              "docId": "2026-01-01_nvidia_blog_4648",
              "url": "https://blogs.nvidia.com/2026/01/01/vllm_yi_large_v2",
              "published": "2026-01-01",
              "snippet": "The latest release of vllm adds native Yi-Large v2 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:swe_bench_whisper_v4_max_measures",
          "source": "benchmark:swe_bench",
          "target": "model:whisper_v4_max",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-11_hugging_face_bl_8625",
              "url": "https://huggingface.co/blog/2026/01/11/swe_bench_whisper_v4_max",
              "published": "2026-01-11",
              "snippet": "SWE-bench has become the standard for evaluating Whisper v4 Max..."
            },
            {
              "docId": "2026-01-23_techcrunch_9790",
              "url": "https://techcrunch.com/2026/01/23/swe_bench_whisper_v4_max",
              "published": "2026-01-23",
              "snippet": "The SWE-bench benchmark measures Whisper v4 Max across multiple tasks..."
            },
            {
              "docId": "2026-01-23_the_verge_7468",
              "url": "https://theverge.com/2026/01/23/swe_bench_whisper_v4_max",
              "published": "2026-01-23",
              "snippet": "SWE-bench provides standardized evaluation of Whisper v4 Max..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:falcon_3_pro_alpacaeval_2_lite_evaluated_on",
          "source": "model:falcon_3_pro",
          "target": "benchmark:alpacaeval_2_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2026-01-03_the_verge_2360",
              "url": "https://theverge.com/2026/01/03/falcon_3_pro_alpacaeval_2_lite",
              "published": "2026-01-03",
              "snippet": "Falcon 3 Pro achieves 77% on AlpacaEval 2 Lite, setting a new record..."
            },
            {
              "docId": "2026-01-09_the_verge_8186",
              "url": "https://theverge.com/2026/01/09/falcon_3_pro_alpacaeval_2_lite",
              "published": "2026-01-09",
              "snippet": "On the AlpacaEval 2 Lite benchmark, Falcon 3 Pro scored 94%..."
            },
            {
              "docId": "2026-01-15_arxiv_9201",
              "url": "https://arxiv.org/abs/2026/01/15/falcon_3_pro_alpacaeval_2_lite",
              "published": "2026-01-15",
              "snippet": "On the AlpacaEval 2 Lite benchmark, Falcon 3 Pro scored 93%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpqa_stable_diffusion_4_mini_measures",
          "source": "benchmark:gpqa",
          "target": "model:stable_diffusion_4_mini",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2026-01-25_hugging_face_bl_2164",
              "url": "https://huggingface.co/blog/2026/01/25/gpqa_stable_diffusion_4_mini",
              "published": "2026-01-25",
              "snippet": "GPQA provides standardized evaluation of Stable Diffusion 4 Mini..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:open_interpreter_qwen_3_next_integrates_with",
          "source": "repo:open_interpreter",
          "target": "model:qwen_3_next",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-18_microsoft_resea_2101",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/18/open_interpreter_qwen_3_next",
              "published": "2026-01-18",
              "snippet": "open-interpreter announced official support for Qwen-3 Next..."
            },
            {
              "docId": "2026-01-22_venturebeat_7475",
              "url": "https://venturebeat.com/2026/01/22/open_interpreter_qwen_3_next",
              "published": "2026-01-22",
              "snippet": "open-interpreter announced official support for Qwen-3 Next..."
            },
            {
              "docId": "2026-01-23_the_verge_7466",
              "url": "https://theverge.com/2026/01/23/open_interpreter_qwen_3_next",
              "published": "2026-01-23",
              "snippet": "The latest release of open-interpreter adds native Qwen-3 Next integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt4all_dall_e_4_plus_integrates_with",
          "source": "repo:gpt4all",
          "target": "model:dall_e_4_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.85
        }
      },
      {
        "data": {
          "id": "e:ollama_qlora_pro_uses_tech",
          "source": "repo:ollama",
          "target": "tech:qlora_pro",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.73,
          "evidence": [
            {
              "docId": "2026-01-24_openai_blog_2831",
              "url": "https://openai.com/blog/2026/01/24/ollama_qlora_pro",
              "published": "2026-01-24",
              "snippet": "Technical details reveal ollama relies heavily on QLoRA Pro..."
            },
            {
              "docId": "2026-01-24_the_gradient_3458",
              "url": "https://thegradient.pub/2026/01/24/ollama_qlora_pro",
              "published": "2026-01-24",
              "snippet": "Technical details reveal ollama relies heavily on QLoRA Pro..."
            },
            {
              "docId": "2026-01-24_techcrunch_1584",
              "url": "https://techcrunch.com/2026/01/24/ollama_qlora_pro",
              "published": "2026-01-24",
              "snippet": "Under the hood, ollama implements QLoRA Pro for improved efficiency..."
            },
            {
              "docId": "2026-01-24_meta_ai_blog_8563",
              "url": "https://ai.meta.com/blog/2026/01/24/ollama_qlora_pro",
              "published": "2026-01-24",
              "snippet": "ollama leverages QLoRA Pro to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:falcon_3_pro_truthfulqa_plus_evaluated_on",
          "source": "model:falcon_3_pro",
          "target": "benchmark:truthfulqa_plus",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.9,
          "evidence": [
            {
              "docId": "2026-01-15_venturebeat_9578",
              "url": "https://venturebeat.com/2026/01/15/falcon_3_pro_truthfulqa_plus",
              "published": "2026-01-15",
              "snippet": "Falcon 3 Pro achieves 98% on TruthfulQA Plus, setting a new record..."
            },
            {
              "docId": "2026-01-15_openai_blog_1158",
              "url": "https://openai.com/blog/2026/01/15/falcon_3_pro_truthfulqa_plus",
              "published": "2026-01-15",
              "snippet": "Evaluation results show Falcon 3 Pro reaching 83% on TruthfulQA Plus..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_nemotron_5_ultra_integrates_with",
          "source": "repo:langchain",
          "target": "model:nemotron_5_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2025-12-26_the_verge_7822",
              "url": "https://theverge.com/2025/12/26/langchain_nemotron_5_ultra",
              "published": "2025-12-26",
              "snippet": "langchain now supports Nemotron-5 Ultra with full feature parity..."
            },
            {
              "docId": "2026-01-19_venturebeat_7071",
              "url": "https://venturebeat.com/2026/01/19/langchain_nemotron_5_ultra",
              "published": "2026-01-19",
              "snippet": "langchain now supports Nemotron-5 Ultra with full feature parity..."
            },
            {
              "docId": "2026-01-25_meta_ai_blog_4084",
              "url": "https://ai.meta.com/blog/2026/01/25/langchain_nemotron_5_ultra",
              "published": "2026-01-25",
              "snippet": "langchain now supports Nemotron-5 Ultra with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:ollama_quantization_edge_uses_tech",
          "source": "tool:ollama",
          "target": "tech:quantization_edge",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.66,
          "evidence": [
            {
              "docId": "2026-01-21_nextgov_2390",
              "url": "https://nextgov.com/2026/01/21/ollama_quantization_edge",
              "published": "2026-01-21",
              "snippet": "Technical details reveal Ollama relies heavily on Quantization Edge..."
            },
            {
              "docId": "2026-01-24_reuters_2515",
              "url": "https://reuters.com/technology/2026/01/24/ollama_quantization_edge",
              "published": "2026-01-24",
              "snippet": "Technical details reveal Ollama relies heavily on Quantization Edge..."
            },
            {
              "docId": "2026-01-24_microsoft_resea_2500",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/24/ollama_quantization_edge",
              "published": "2026-01-24",
              "snippet": "Technical details reveal Ollama relies heavily on Quantization Edge..."
            },
            {
              "docId": "2026-01-25_venturebeat_6627",
              "url": "https://venturebeat.com/2026/01/25/ollama_quantization_edge",
              "published": "2026-01-25",
              "snippet": "Ollama leverages Quantization Edge to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:falcon_3_pro_rlhf_mini_uses_tech",
          "source": "model:falcon_3_pro",
          "target": "tech:rlhf_mini",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.77
        }
      },
      {
        "data": {
          "id": "e:palm_3_chain_of_thought_uses_tech",
          "source": "model:palm_3",
          "target": "tech:chain_of_thought",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_deepseek_v3_evaluated_on",
          "source": "paper:direct_preference_optimization",
          "target": "model:deepseek_v3",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.9,
          "evidence": [
            {
              "docId": "2026-01-24_arxiv_7141",
              "url": "https://arxiv.org/abs/2026/01/24/direct_preference_optimization",
              "published": "2026-01-24",
              "snippet": "On the DeepSeek-V3 benchmark, Direct Preference Optimization scored 70%..."
            },
            {
              "docId": "2026-01-24_arxiv_4866",
              "url": "https://arxiv.org/abs/2026/01/24/direct_preference_optimization",
              "published": "2026-01-24",
              "snippet": "Direct Preference Optimization achieves 95% on DeepSeek-V3, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mbpp_stable_diffusion_4_mini_measures",
          "source": "benchmark:mbpp",
          "target": "model:stable_diffusion_4_mini",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2026-01-15_weights_and_bia_2700",
              "url": "https://wandb.ai/articles/2026/01/15/mbpp_stable_diffusion_4_mini",
              "published": "2026-01-15",
              "snippet": "MBPP provides standardized evaluation of Stable Diffusion 4 Mini..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:vllm_haystack_integrates_with",
          "source": "tool:vllm",
          "target": "tool:haystack",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.56
        }
      },
      {
        "data": {
          "id": "e:tensorrt_llm_quantization_uses_tech",
          "source": "tool:tensorrt_llm",
          "target": "tech:quantization",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.85
        }
      },
      {
        "data": {
          "id": "e:transformers_next_tree_of_thought_lite_uses_tech",
          "source": "repo:transformers_next",
          "target": "tech:tree_of_thought_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:yi_large_lite_synthetic_data_generation_uses_tech",
          "source": "model:yi_large_lite",
          "target": "tech:synthetic_data_generation",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.68
        }
      },
      {
        "data": {
          "id": "e:codex_2_yi_large_depends_on",
          "source": "model:codex_2",
          "target": "model:yi_large",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.53
        }
      },
      {
        "data": {
          "id": "e:llama_4_max_the_stack_v2_ultra_trained_on",
          "source": "model:llama_4_max",
          "target": "dataset:the_stack_v2_ultra",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.46
        }
      },
      {
        "data": {
          "id": "e:mlflow_lite_quantization_edge_uses_tech",
          "source": "tool:mlflow_lite",
          "target": "tech:quantization_edge",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2025-11-26_weights_and_bia_4186",
              "url": "https://wandb.ai/articles/2025/11/26/mlflow_lite_quantization_edge",
              "published": "2025-11-26",
              "snippet": "Technical details reveal MLflow Lite relies heavily on Quantization Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_ultra_sliding_window_attention_uses_tech",
          "source": "paper:direct_preference_optimization_ultra",
          "target": "tech:sliding_window_attention",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:the_pile_core_qlora_ultra_uses_tech",
          "source": "dataset:the_pile_core",
          "target": "tech:qlora_ultra",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.45
        }
      },
      {
        "data": {
          "id": "e:langchain_rlhf_edge_uses_tech",
          "source": "tool:langchain",
          "target": "tech:rlhf_edge",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.8
        }
      },
      {
        "data": {
          "id": "e:phi_4_ultra_sora_2_ultra_depends_on",
          "source": "model:phi_4_ultra",
          "target": "model:sora_2_ultra",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.53
        }
      },
      {
        "data": {
          "id": "e:sora_2_ultra_multimodal_fusion_plus_uses_tech",
          "source": "model:sora_2_ultra",
          "target": "tech:multimodal_fusion_plus",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.8
        }
      },
      {
        "data": {
          "id": "e:transformers_next_deepseek_v3_integrates_with",
          "source": "repo:transformers_next",
          "target": "model:deepseek_v3",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-23_hugging_face_bl_5634",
              "url": "https://huggingface.co/blog/2026/01/23/transformers_next_deepseek_v3",
              "published": "2026-01-23",
              "snippet": "transformers Next now supports DeepSeek-V3 with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamaindex_cursor_integrates_with",
          "source": "tool:llamaindex",
          "target": "tool:cursor",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.56
        }
      },
      {
        "data": {
          "id": "e:llamacpp_gguf_uses_tech",
          "source": "repo:llamacpp",
          "target": "tech:gguf",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-08_the_verge_7427",
              "url": "https://theverge.com/2026/01/08/llamacpp_gguf",
              "published": "2026-01-08",
              "snippet": "Technical details reveal llama.cpp relies heavily on GGUF..."
            },
            {
              "docId": "2026-01-20_openai_blog_7813",
              "url": "https://openai.com/blog/2026/01/20/llamacpp_gguf",
              "published": "2026-01-20",
              "snippet": "Under the hood, llama.cpp implements GGUF for improved efficiency..."
            },
            {
              "docId": "2026-01-23_anthropic_blog_4130",
              "url": "https://anthropic.com/news/2026/01/23/llamacpp_gguf",
              "published": "2026-01-23",
              "snippet": "Technical details reveal llama.cpp relies heavily on GGUF..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:the_pile_constitutional_ai_uses_tech",
          "source": "dataset:the_pile",
          "target": "tech:constitutional_ai",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.59
        }
      },
      {
        "data": {
          "id": "e:phi_4_mini_dall_e_4_edge_depends_on",
          "source": "model:phi_4_mini",
          "target": "model:dall_e_4_edge",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.7
        }
      },
      {
        "data": {
          "id": "e:llamacpp_tokenizer_bpe_next_uses_tech",
          "source": "repo:llamacpp",
          "target": "tech:tokenizer_bpe_next",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.9
        }
      },
      {
        "data": {
          "id": "e:gradio_mixture_of_experts_uses_tech",
          "source": "tool:gradio",
          "target": "tech:mixture_of_experts",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.7,
          "evidence": [
            {
              "docId": "2026-01-16_mit_technology__4772",
              "url": "https://technologyreview.com/2026/01/16/gradio_mixture_of_experts",
              "published": "2026-01-16",
              "snippet": "Technical details reveal Gradio relies heavily on Mixture of Experts..."
            },
            {
              "docId": "2026-01-24_reuters_8471",
              "url": "https://reuters.com/technology/2026/01/24/gradio_mixture_of_experts",
              "published": "2026-01-24",
              "snippet": "Under the hood, Gradio implements Mixture of Experts for improved efficiency..."
            },
            {
              "docId": "2026-01-25_techcrunch_6346",
              "url": "https://techcrunch.com/2026/01/25/gradio_mixture_of_experts",
              "published": "2026-01-25",
              "snippet": "Gradio leverages Mixture of Experts to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-25_hugging_face_bl_8889",
              "url": "https://huggingface.co/blog/2026/01/25/gradio_mixture_of_experts",
              "published": "2026-01-25",
              "snippet": "Technical details reveal Gradio relies heavily on Mixture of Experts..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:crewai_llama_4_next_integrates_with",
          "source": "tool:crewai",
          "target": "model:llama_4_next",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:roots_group_query_attention_v2_uses_tech",
          "source": "dataset:roots",
          "target": "tech:group_query_attention_v2",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.74
        }
      },
      {
        "data": {
          "id": "e:dify_ultra_jamba_2_integrates_with",
          "source": "tool:dify_ultra",
          "target": "model:jamba_2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.86,
          "evidence": [
            {
              "docId": "2026-01-25_anthropic_blog_2986",
              "url": "https://anthropic.com/news/2026/01/25/dify_ultra_jamba_2",
              "published": "2026-01-25",
              "snippet": "Dify Ultra announced official support for Jamba 2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_v2_flash_attention_core_uses_tech",
          "source": "model:palm_3_v2",
          "target": "tech:flash_attention_core",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.76,
          "evidence": [
            {
              "docId": "2026-01-11_techcrunch_2802",
              "url": "https://techcrunch.com/2026/01/11/palm_3_v2_flash_attention_core",
              "published": "2026-01-11",
              "snippet": "Under the hood, PaLM 3 v2 implements Flash Attention Core for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:codex_2_ultra_truthfulqa_evaluated_on",
          "source": "model:codex_2_ultra",
          "target": "benchmark:truthfulqa",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-17_anthropic_blog_1816",
              "url": "https://anthropic.com/news/2026/01/17/codex_2_ultra_truthfulqa",
              "published": "2026-01-17",
              "snippet": "On the TruthfulQA benchmark, Codex 2 Ultra scored 73%..."
            },
            {
              "docId": "2026-01-25_hugging_face_bl_7489",
              "url": "https://huggingface.co/blog/2026/01/25/codex_2_ultra_truthfulqa",
              "published": "2026-01-25",
              "snippet": "On the TruthfulQA benchmark, Codex 2 Ultra scored 81%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamacpp_constitutional_ai_ultra_uses_tech",
          "source": "repo:llamacpp",
          "target": "tech:constitutional_ai_ultra",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.75,
          "evidence": [
            {
              "docId": "2026-01-21_reuters_1106",
              "url": "https://reuters.com/technology/2026/01/21/llamacpp_constitutional_ai_ult",
              "published": "2026-01-21",
              "snippet": "llama.cpp leverages Constitutional AI Ultra to achieve state-of-the-art performance..."
            },
            {
              "docId": "2026-01-24_openai_blog_9813",
              "url": "https://openai.com/blog/2026/01/24/llamacpp_constitutional_ai_ult",
              "published": "2026-01-24",
              "snippet": "Technical details reveal llama.cpp relies heavily on Constitutional AI Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:bigbench_hard_sora_2_ultra_measures",
          "source": "benchmark:bigbench_hard",
          "target": "model:sora_2_ultra",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.8,
          "evidence": [
            {
              "docId": "2025-12-13_techcrunch_8056",
              "url": "https://techcrunch.com/2025/12/13/bigbench_hard_sora_2_ultra",
              "published": "2025-12-13",
              "snippet": "BigBench Hard provides standardized evaluation of Sora 2 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:grok_3_ultra_palm_3_depends_on",
          "source": "model:grok_3_ultra",
          "target": "model:palm_3",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.48
        }
      },
      {
        "data": {
          "id": "e:dolma_rotary_position_embedding_uses_tech",
          "source": "dataset:dolma",
          "target": "tech:rotary_position_embedding",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.55
        }
      },
      {
        "data": {
          "id": "e:langchain_multimodal_fusion_lite_uses_tech",
          "source": "repo:langchain",
          "target": "tech:multimodal_fusion_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:semantic_kernel_autogpt_edge_integrates_with",
          "source": "tool:semantic_kernel",
          "target": "tool:autogpt_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.73,
          "evidence": [
            {
              "docId": "2026-01-16_google_ai_blog_3434",
              "url": "https://blog.google/technology/ai/2026/01/16/semantic_kernel_autogpt_edge",
              "published": "2026-01-16",
              "snippet": "The latest release of Semantic Kernel adds native AutoGPT Edge integration..."
            },
            {
              "docId": "2026-01-22_techcrunch_8826",
              "url": "https://techcrunch.com/2026/01/22/semantic_kernel_autogpt_edge",
              "published": "2026-01-22",
              "snippet": "The latest release of Semantic Kernel adds native AutoGPT Edge integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:retrieval_augmented_generation_for_knowl_transformer_architecture_pro_uses_tech",
          "source": "paper:retrieval_augmented_generation_for_knowl",
          "target": "tech:transformer_architecture_pro",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-10_anthropic_blog_1668",
              "url": "https://anthropic.com/news/2026/01/10/retrieval_augmented_generation",
              "published": "2026-01-10",
              "snippet": "Technical details reveal Retrieval-Augmented Generation for Knowledge-Intensive NLP relies heavily on Transformer Architecture Pro..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:alpacaeval_2_palm_3_v2_measures",
          "source": "benchmark:alpacaeval_2",
          "target": "model:palm_3_v2",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2026-01-18_the_gradient_7573",
              "url": "https://thegradient.pub/2026/01/18/alpacaeval_2_palm_3_v2",
              "published": "2026-01-18",
              "snippet": "AlpacaEval 2 has become the standard for evaluating PaLM 3 v2..."
            },
            {
              "docId": "2026-01-21_anthropic_blog_8155",
              "url": "https://anthropic.com/news/2026/01/21/alpacaeval_2_palm_3_v2",
              "published": "2026-01-21",
              "snippet": "AlpacaEval 2 provides standardized evaluation of PaLM 3 v2..."
            },
            {
              "docId": "2026-01-23_mit_technology__4354",
              "url": "https://technologyreview.com/2026/01/23/alpacaeval_2_palm_3_v2",
              "published": "2026-01-23",
              "snippet": "The AlpacaEval 2 benchmark measures PaLM 3 v2 across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_synthetic_data_generation_uses_tech",
          "source": "repo:langchain",
          "target": "tech:synthetic_data_generation",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:llama_4_max_roots_trained_on",
          "source": "model:llama_4_max",
          "target": "dataset:roots",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.47
        }
      },
      {
        "data": {
          "id": "e:qwen_3_ultra_laion_5b_edge_trained_on",
          "source": "model:qwen_3_ultra",
          "target": "dataset:laion_5b_edge",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.65
        }
      },
      {
        "data": {
          "id": "e:qwen_3_stable_diffusion_4_max_depends_on",
          "source": "model:qwen_3",
          "target": "model:stable_diffusion_4_max",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.5
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_pro_retrieval_augmented_generation_uses_tech",
          "source": "paper:llm_agents:_a_survey_pro",
          "target": "tech:retrieval_augmented_generation",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2026-01-25_venturebeat_9583",
              "url": "https://venturebeat.com/2026/01/25/llm_agents:_a_survey_pro_retri",
              "published": "2026-01-25",
              "snippet": "Under the hood, LLM Agents: A Survey Pro implements Retrieval-Augmented Generation for improved efficiency..."
            },
            {
              "docId": "2026-01-25_google_ai_blog_5920",
              "url": "https://blog.google/technology/ai/2026/01/25/llm_agents:_a_survey_pro_retri",
              "published": "2026-01-25",
              "snippet": "Under the hood, LLM Agents: A Survey Pro implements Retrieval-Augmented Generation for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_next_whisper_v4_next_depends_on",
          "source": "model:llama_4_next",
          "target": "model:whisper_v4_next",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.51
        }
      },
      {
        "data": {
          "id": "e:the_stack_v2_sliding_window_attention_ultra_uses_tech",
          "source": "dataset:the_stack_v2",
          "target": "tech:sliding_window_attention_ultra",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.64
        }
      },
      {
        "data": {
          "id": "e:streamlit_pro_tokenizer_bpe_next_uses_tech",
          "source": "tool:streamlit_pro",
          "target": "tech:tokenizer_bpe_next",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-06_nvidia_blog_4843",
              "url": "https://blogs.nvidia.com/2026/01/06/streamlit_pro_tokenizer_bpe_ne",
              "published": "2026-01-06",
              "snippet": "Streamlit Pro leverages Tokenizer BPE Next to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_plus_gemma_3_v2_integrates_with",
          "source": "tool:langchain_plus",
          "target": "model:gemma_3_v2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2026-01-24_bloomberg_3730",
              "url": "https://bloomberg.com/technology/2026/01/24/langchain_plus_gemma_3_v2",
              "published": "2026-01-24",
              "snippet": "LangChain Plus now supports Gemma 3 v2 with full feature parity..."
            },
            {
              "docId": "2026-01-24_google_ai_blog_1378",
              "url": "https://blog.google/technology/ai/2026/01/24/langchain_plus_gemma_3_v2",
              "published": "2026-01-24",
              "snippet": "LangChain Plus now supports Gemma 3 v2 with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:codex_2_pro_laion_5b_trained_on",
          "source": "model:codex_2_pro",
          "target": "dataset:laion_5b",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.68
        }
      },
      {
        "data": {
          "id": "e:vllm_v2_rotary_position_embedding_v2_uses_tech",
          "source": "repo:vllm_v2",
          "target": "tech:rotary_position_embedding_v2",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:nemotron_5_group_query_attention_uses_tech",
          "source": "model:nemotron_5",
          "target": "tech:group_query_attention",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.58,
          "evidence": [
            {
              "docId": "2026-01-05_hugging_face_bl_3199",
              "url": "https://huggingface.co/blog/2026/01/05/nemotron_5_group_query_attenti",
              "published": "2026-01-05",
              "snippet": "Technical details reveal Nemotron-5 relies heavily on Group Query Attention..."
            },
            {
              "docId": "2026-01-25_anthropic_blog_6974",
              "url": "https://anthropic.com/news/2026/01/25/nemotron_5_group_query_attenti",
              "published": "2026-01-25",
              "snippet": "Under the hood, Nemotron-5 implements Group Query Attention for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:dall_e_4_truthfulqa_evaluated_on",
          "source": "model:dall_e_4",
          "target": "benchmark:truthfulqa",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.92
        }
      },
      {
        "data": {
          "id": "e:vllm_deepseek_v3_edge_integrates_with",
          "source": "repo:vllm",
          "target": "model:deepseek_v3_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2025-11-12_nextgov_2154",
              "url": "https://nextgov.com/2025/11/12/vllm_deepseek_v3_edge",
              "published": "2025-11-12",
              "snippet": "vllm now supports DeepSeek-V3 Edge with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:refinedweb_ultra_sparse_attention_lite_uses_tech",
          "source": "dataset:refinedweb_ultra",
          "target": "tech:sparse_attention_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:attention_is_all_you_need_v2_v2_multimodal_fusion_lite_uses_tech",
          "source": "paper:attention_is_all_you_need_v2_v2",
          "target": "tech:multimodal_fusion_lite",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.93
        }
      },
      {
        "data": {
          "id": "e:mixture_of_experts_meets_instruction_tun_deepseek_v3_edge_evaluated_on",
          "source": "paper:mixture_of_experts_meets_instruction_tun",
          "target": "model:deepseek_v3_edge",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2025-12-21_meta_ai_blog_6802",
              "url": "https://ai.meta.com/blog/2025/12/21/mixture_of_experts_meets_instr",
              "published": "2025-12-21",
              "snippet": "On the DeepSeek-V3 Edge benchmark, Mixture of Experts Meets Instruction Tuning scored 92%..."
            },
            {
              "docId": "2025-12-25_wired_6773",
              "url": "https://wired.com/2025/12/25/mixture_of_experts_meets_instr",
              "published": "2025-12-25",
              "snippet": "Mixture of Experts Meets Instruction Tuning achieves 81% on DeepSeek-V3 Edge, setting a new record..."
            },
            {
              "docId": "2026-01-04_mit_technology__8839",
              "url": "https://technologyreview.com/2026/01/04/mixture_of_experts_meets_instr",
              "published": "2026-01-04",
              "snippet": "On the DeepSeek-V3 Edge benchmark, Mixture of Experts Meets Instruction Tuning scored 84%..."
            },
            {
              "docId": "2026-01-08_langchain_blog_1278",
              "url": "https://blog.langchain.dev/2026/01/08/mixture_of_experts_meets_instr",
              "published": "2026-01-08",
              "snippet": "Mixture of Experts Meets Instruction Tuning achieves 90% on DeepSeek-V3 Edge, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:jamba_2_arc_agi_lite_evaluated_on",
          "source": "model:jamba_2",
          "target": "benchmark:arc_agi_lite",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-15_weights_and_bia_5428",
              "url": "https://wandb.ai/articles/2026/01/15/jamba_2_arc_agi_lite",
              "published": "2026-01-15",
              "snippet": "On the ARC-AGI Lite benchmark, Jamba 2 scored 84%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:semantic_kernel_mini_multimodal_fusion_uses_tech",
          "source": "tool:semantic_kernel_mini",
          "target": "tech:multimodal_fusion",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.72,
          "evidence": [
            {
              "docId": "2026-01-11_venturebeat_6993",
              "url": "https://venturebeat.com/2026/01/11/semantic_kernel_mini_multimoda",
              "published": "2026-01-11",
              "snippet": "Technical details reveal Semantic Kernel Mini relies heavily on Multimodal Fusion..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:phi_4_mini_wikipedia_dump_2025_trained_on",
          "source": "model:phi_4_mini",
          "target": "dataset:wikipedia_dump_2025",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.62,
          "evidence": [
            {
              "docId": "2026-01-15_microsoft_resea_6481",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/15/phi_4_mini_wikipedia_dump_2025",
              "published": "2026-01-15",
              "snippet": "Phi-4 Mini was trained on Wikipedia Dump 2025 comprising billions of tokens..."
            },
            {
              "docId": "2026-01-22_nextgov_5124",
              "url": "https://nextgov.com/2026/01/22/phi_4_mini_wikipedia_dump_2025",
              "published": "2026-01-22",
              "snippet": "Phi-4 Mini utilized Wikipedia Dump 2025 as part of its pre-training data mix..."
            },
            {
              "docId": "2026-01-24_wired_5652",
              "url": "https://wired.com/2026/01/24/phi_4_mini_wikipedia_dump_2025",
              "published": "2026-01-24",
              "snippet": "The training corpus for Phi-4 Mini includes Wikipedia Dump 2025..."
            },
            {
              "docId": "2026-01-24_anthropic_blog_7479",
              "url": "https://anthropic.com/news/2026/01/24/phi_4_mini_wikipedia_dump_2025",
              "published": "2026-01-24",
              "snippet": "Phi-4 Mini utilized Wikipedia Dump 2025 as part of its pre-training data mix..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:vllm_sliding_window_attention_pro_uses_tech",
          "source": "repo:vllm",
          "target": "tech:sliding_window_attention_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:mlflow_lite_copilot_ultra_integrates_with",
          "source": "tool:mlflow_lite",
          "target": "tool:copilot_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.61
        }
      },
      {
        "data": {
          "id": "e:langchain_lite_phi_4_integrates_with",
          "source": "repo:langchain_lite",
          "target": "model:phi_4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-22_ars_technica_1637",
              "url": "https://arstechnica.com/2026/01/22/langchain_lite_phi_4",
              "published": "2026-01-22",
              "snippet": "langchain Lite now supports Phi-4 with full feature parity..."
            },
            {
              "docId": "2026-01-24_openai_blog_4322",
              "url": "https://openai.com/blog/2026/01/24/langchain_lite_phi_4",
              "published": "2026-01-24",
              "snippet": "langchain Lite now supports Phi-4 with full feature parity..."
            },
            {
              "docId": "2026-01-24_the_verge_8800",
              "url": "https://theverge.com/2026/01/24/langchain_lite_phi_4",
              "published": "2026-01-24",
              "snippet": "langchain Lite announced official support for Phi-4..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:codex_2_the_pile_trained_on",
          "source": "model:codex_2",
          "target": "dataset:the_pile",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.54,
          "evidence": [
            {
              "docId": "2026-01-06_hugging_face_bl_6107",
              "url": "https://huggingface.co/blog/2026/01/06/codex_2_the_pile",
              "published": "2026-01-06",
              "snippet": "Codex 2 utilized The Pile as part of its pre-training data mix..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:autogpt_max_rlhf_mini_uses_tech",
          "source": "tool:autogpt_max",
          "target": "tech:rlhf_mini",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.82
        }
      },
      {
        "data": {
          "id": "e:gradio_rotary_position_embedding_pro_uses_tech",
          "source": "tool:gradio",
          "target": "tech:rotary_position_embedding_pro",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.74,
          "evidence": [
            {
              "docId": "2025-12-21_weights_and_bia_4516",
              "url": "https://wandb.ai/articles/2025/12/21/gradio_rotary_position_embeddi",
              "published": "2025-12-21",
              "snippet": "Technical details reveal Gradio relies heavily on Rotary Position Embedding Pro..."
            },
            {
              "docId": "2026-01-17_mit_technology__1199",
              "url": "https://technologyreview.com/2026/01/17/gradio_rotary_position_embeddi",
              "published": "2026-01-17",
              "snippet": "Gradio leverages Rotary Position Embedding Pro to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_mbpp_evaluated_on",
          "source": "model:palm_3",
          "target": "benchmark:mbpp",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2025-12-31_the_gradient_5130",
              "url": "https://thegradient.pub/2025/12/31/palm_3_mbpp",
              "published": "2025-12-31",
              "snippet": "PaLM 3 achieves 87% on MBPP, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:attention_is_all_you_need_v2_v2_gemini_ultra_2_lite_evaluated_on",
          "source": "paper:attention_is_all_you_need_v2_v2",
          "target": "model:gemini_ultra_2_lite",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.73
        }
      },
      {
        "data": {
          "id": "e:claude_sonnet_4_edge_mt_bench_evaluated_on",
          "source": "model:claude_sonnet_4_edge",
          "target": "benchmark:mt_bench",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.86
        }
      },
      {
        "data": {
          "id": "e:open_interpreter_dall_e_4_plus_integrates_with",
          "source": "repo:open_interpreter",
          "target": "model:dall_e_4_plus",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.9
        }
      },
      {
        "data": {
          "id": "e:midjourney_v7_plus_arc_agi_evaluated_on",
          "source": "model:midjourney_v7_plus",
          "target": "benchmark:arc_agi",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-22_langchain_blog_2379",
              "url": "https://blog.langchain.dev/2026/01/22/midjourney_v7_plus_arc_agi",
              "published": "2026-01-22",
              "snippet": "On the ARC-AGI benchmark, Midjourney V7 Plus scored 95%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_max_nemotron_5_v2_depends_on",
          "source": "model:palm_3_max",
          "target": "model:nemotron_5_v2",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.72
        }
      },
      {
        "data": {
          "id": "e:toolformer:_language_models_can_teach_th_codex_2_evaluated_on",
          "source": "paper:toolformer:_language_models_can_teach_th",
          "target": "model:codex_2",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-03_arxiv_4919",
              "url": "https://arxiv.org/abs/2026/01/03/toolformer:_language_models_ca",
              "published": "2026-01-03",
              "snippet": "On the Codex 2 benchmark, Toolformer: Language Models Can Teach Themselves to Use Tools scored 81%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:redpajama_v2_flash_attention_uses_tech",
          "source": "dataset:redpajama_v2",
          "target": "tech:flash_attention",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.56
        }
      },
      {
        "data": {
          "id": "e:whisper_v4_v2_humaneval_edge_evaluated_on",
          "source": "model:whisper_v4_v2",
          "target": "benchmark:humaneval_edge",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2026-01-24_microsoft_resea_5873",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/24/whisper_v4_v2_humaneval_edge",
              "published": "2026-01-24",
              "snippet": "Whisper v4 v2 achieves 79% on HumanEval Edge, setting a new record..."
            },
            {
              "docId": "2026-01-25_ars_technica_2115",
              "url": "https://arstechnica.com/2026/01/25/whisper_v4_v2_humaneval_edge",
              "published": "2026-01-25",
              "snippet": "Whisper v4 v2 achieves 86% on HumanEval Edge, setting a new record..."
            },
            {
              "docId": "2026-01-25_langchain_blog_6033",
              "url": "https://blog.langchain.dev/2026/01/25/whisper_v4_v2_humaneval_edge",
              "published": "2026-01-25",
              "snippet": "On the HumanEval Edge benchmark, Whisper v4 v2 scored 92%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:litellm_edge_phi_4_integrates_with",
          "source": "tool:litellm_edge",
          "target": "model:phi_4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.87,
          "evidence": [
            {
              "docId": "2026-01-11_reuters_2508",
              "url": "https://reuters.com/technology/2026/01/11/litellm_edge_phi_4",
              "published": "2026-01-11",
              "snippet": "The latest release of LiteLLM Edge adds native Phi-4 integration..."
            },
            {
              "docId": "2026-01-24_reuters_4222",
              "url": "https://reuters.com/technology/2026/01/24/litellm_edge_phi_4",
              "published": "2026-01-24",
              "snippet": "LiteLLM Edge announced official support for Phi-4..."
            },
            {
              "docId": "2026-01-25_the_gradient_9183",
              "url": "https://thegradient.pub/2026/01/25/litellm_edge_phi_4",
              "published": "2026-01-25",
              "snippet": "The latest release of LiteLLM Edge adds native Phi-4 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_flash_attention_uses_tech",
          "source": "paper:direct_preference_optimization",
          "target": "tech:flash_attention",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-05_techcrunch_9094",
              "url": "https://techcrunch.com/2026/01/05/direct_preference_optimization",
              "published": "2026-01-05",
              "snippet": "Technical details reveal Direct Preference Optimization relies heavily on Flash Attention..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:cursor_stable_diffusion_4_integrates_with",
          "source": "tool:cursor",
          "target": "model:stable_diffusion_4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2025-12-20_arxiv_4021",
              "url": "https://arxiv.org/abs/2025/12/20/cursor_stable_diffusion_4",
              "published": "2025-12-20",
              "snippet": "Cursor now supports Stable Diffusion 4 with full feature parity..."
            },
            {
              "docId": "2025-12-24_microsoft_resea_9172",
              "url": "https://microsoft.com/en-us/research/blog/2025/12/24/cursor_stable_diffusion_4",
              "published": "2025-12-24",
              "snippet": "Cursor announced official support for Stable Diffusion 4..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:whisper_v4_v2_gsm8k_evaluated_on",
          "source": "model:whisper_v4_v2",
          "target": "benchmark:gsm8k",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.8,
          "evidence": [
            {
              "docId": "2026-01-24_ars_technica_5003",
              "url": "https://arstechnica.com/2026/01/24/whisper_v4_v2_gsm8k",
              "published": "2026-01-24",
              "snippet": "Evaluation results show Whisper v4 v2 reaching 87% on GSM8K..."
            },
            {
              "docId": "2026-01-25_anthropic_blog_1874",
              "url": "https://anthropic.com/news/2026/01/25/whisper_v4_v2_gsm8k",
              "published": "2026-01-25",
              "snippet": "Whisper v4 v2 achieves 90% on GSM8K, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:localai_midjourney_v7_edge_integrates_with",
          "source": "tool:localai",
          "target": "model:midjourney_v7_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.76,
          "evidence": [
            {
              "docId": "2026-01-18_nvidia_blog_6343",
              "url": "https://blogs.nvidia.com/2026/01/18/localai_midjourney_v7_edge",
              "published": "2026-01-18",
              "snippet": "LocalAI announced official support for Midjourney V7 Edge..."
            },
            {
              "docId": "2026-01-18_arxiv_1752",
              "url": "https://arxiv.org/abs/2026/01/18/localai_midjourney_v7_edge",
              "published": "2026-01-18",
              "snippet": "LocalAI now supports Midjourney V7 Edge with full feature parity..."
            },
            {
              "docId": "2026-01-23_openai_blog_3090",
              "url": "https://openai.com/blog/2026/01/23/localai_midjourney_v7_edge",
              "published": "2026-01-23",
              "snippet": "LocalAI announced official support for Midjourney V7 Edge..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:ollama_tool_use_v2_uses_tech",
          "source": "repo:ollama",
          "target": "tech:tool_use_v2",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:localai_next_claude_opus_45_pro_integrates_with",
          "source": "tool:localai_next",
          "target": "model:claude_opus_45_pro",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.95,
          "evidence": [
            {
              "docId": "2026-01-23_weights_and_bia_4062",
              "url": "https://wandb.ai/articles/2026/01/23/localai_next_claude_opus_45_pr",
              "published": "2026-01-23",
              "snippet": "LocalAI Next now supports Claude Opus 4.5 Pro with full feature parity..."
            },
            {
              "docId": "2026-01-23_meta_ai_blog_8019",
              "url": "https://ai.meta.com/blog/2026/01/23/localai_next_claude_opus_45_pr",
              "published": "2026-01-23",
              "snippet": "LocalAI Next announced official support for Claude Opus 4.5 Pro..."
            },
            {
              "docId": "2026-01-25_langchain_blog_1427",
              "url": "https://blog.langchain.dev/2026/01/25/localai_next_claude_opus_45_pr",
              "published": "2026-01-25",
              "snippet": "LocalAI Next now supports Claude Opus 4.5 Pro with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:vllm_v2_retrieval_augmented_generation_uses_tech",
          "source": "repo:vllm_v2",
          "target": "tech:retrieval_augmented_generation",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.67,
          "evidence": [
            {
              "docId": "2026-01-25_mit_technology__1078",
              "url": "https://technologyreview.com/2026/01/25/vllm_v2_retrieval_augmented_ge",
              "published": "2026-01-25",
              "snippet": "Technical details reveal vllm v2 relies heavily on Retrieval-Augmented Generation..."
            },
            {
              "docId": "2026-01-25_bloomberg_6511",
              "url": "https://bloomberg.com/technology/2026/01/25/vllm_v2_retrieval_augmented_ge",
              "published": "2026-01-25",
              "snippet": "vllm v2 leverages Retrieval-Augmented Generation to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:dolma_next_dpo_uses_tech",
          "source": "dataset:dolma_next",
          "target": "tech:dpo",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.57
        }
      },
      {
        "data": {
          "id": "e:localai_claude_opus_45_integrates_with",
          "source": "repo:localai",
          "target": "model:claude_opus_45",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.78,
          "evidence": [
            {
              "docId": "2026-01-15_meta_ai_blog_2107",
              "url": "https://ai.meta.com/blog/2026/01/15/localai_claude_opus_45",
              "published": "2026-01-15",
              "snippet": "LocalAI announced official support for Claude Opus 4.5..."
            },
            {
              "docId": "2026-01-23_wired_6856",
              "url": "https://wired.com/2026/01/23/localai_claude_opus_45",
              "published": "2026-01-23",
              "snippet": "The latest release of LocalAI adds native Claude Opus 4.5 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_group_query_attention_uses_tech",
          "source": "paper:direct_preference_optimization",
          "target": "tech:group_query_attention",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:gpt_4o_mini_2_the_stack_v2_ultra_trained_on",
          "source": "model:gpt_4o_mini_2",
          "target": "dataset:the_stack_v2_ultra",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.55,
          "evidence": [
            {
              "docId": "2025-12-24_ars_technica_1360",
              "url": "https://arstechnica.com/2025/12/24/gpt_4o_mini_2_the_stack_v2_ult",
              "published": "2025-12-24",
              "snippet": "The training corpus for GPT-4o Mini 2 includes The Stack v2 Ultra..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mixture_of_experts_meets_instruction_tun_claude_opus_45_edge_evaluated_on",
          "source": "paper:mixture_of_experts_meets_instruction_tun",
          "target": "model:claude_opus_45_edge",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-07_arxiv_8817",
              "url": "https://arxiv.org/abs/2026/01/07/mixture_of_experts_meets_instr",
              "published": "2026-01-07",
              "snippet": "Evaluation results show Mixture of Experts Meets Instruction Tuning reaching 71% on Claude Opus 4.5 Edge..."
            },
            {
              "docId": "2026-01-20_mit_technology__1753",
              "url": "https://technologyreview.com/2026/01/20/mixture_of_experts_meets_instr",
              "published": "2026-01-20",
              "snippet": "Mixture of Experts Meets Instruction Tuning achieves 95% on Claude Opus 4.5 Edge, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamaindex_ultra_ollama_edge_integrates_with",
          "source": "tool:llamaindex_ultra",
          "target": "tool:ollama_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.66
        }
      },
      {
        "data": {
          "id": "e:llm_agents:_a_survey_chain_of_thought_pro_uses_tech",
          "source": "paper:llm_agents:_a_survey",
          "target": "tech:chain_of_thought_pro",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.83
        }
      },
      {
        "data": {
          "id": "e:transformers_sora_2_integrates_with",
          "source": "repo:transformers",
          "target": "model:sora_2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-20_venturebeat_9386",
              "url": "https://venturebeat.com/2026/01/20/transformers_sora_2",
              "published": "2026-01-20",
              "snippet": "The latest release of transformers adds native Sora 2 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_stable_diffusion_4_integrates_with",
          "source": "repo:langchain",
          "target": "model:stable_diffusion_4",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.92,
          "evidence": [
            {
              "docId": "2025-12-18_nextgov_9862",
              "url": "https://nextgov.com/2025/12/18/langchain_stable_diffusion_4",
              "published": "2025-12-18",
              "snippet": "The latest release of langchain adds native Stable Diffusion 4 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:qwen_3_jamba_2_edge_depends_on",
          "source": "model:qwen_3",
          "target": "model:jamba_2_edge",
          "rel": "DEPENDS_ON",
          "kind": "hypothesis",
          "confidence": 0.73
        }
      },
      {
        "data": {
          "id": "e:mlflow_yi_large_v2_integrates_with",
          "source": "tool:mlflow",
          "target": "model:yi_large_v2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2025-12-26_openai_blog_2630",
              "url": "https://openai.com/blog/2025/12/26/mlflow_yi_large_v2",
              "published": "2025-12-26",
              "snippet": "MLflow announced official support for Yi-Large v2..."
            },
            {
              "docId": "2025-12-27_ars_technica_5250",
              "url": "https://arstechnica.com/2025/12/27/mlflow_yi_large_v2",
              "published": "2025-12-27",
              "snippet": "MLflow now supports Yi-Large v2 with full feature parity..."
            },
            {
              "docId": "2026-01-11_meta_ai_blog_8945",
              "url": "https://ai.meta.com/blog/2026/01/11/mlflow_yi_large_v2",
              "published": "2026-01-11",
              "snippet": "MLflow now supports Yi-Large v2 with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpt4all_constitutional_ai_uses_tech",
          "source": "repo:gpt4all",
          "target": "tech:constitutional_ai",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.68
        }
      },
      {
        "data": {
          "id": "e:haystack_mini_codex_2_integrates_with",
          "source": "tool:haystack_mini",
          "target": "model:codex_2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2025-12-23_nvidia_blog_9868",
              "url": "https://blogs.nvidia.com/2025/12/23/haystack_mini_codex_2",
              "published": "2025-12-23",
              "snippet": "Haystack Mini announced official support for Codex 2..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:text_generation_webui_lora_ultra_uses_tech",
          "source": "repo:text_generation_webui",
          "target": "tech:lora_ultra",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.75,
          "evidence": [
            {
              "docId": "2026-01-25_bloomberg_9695",
              "url": "https://bloomberg.com/technology/2026/01/25/text_generation_webui_lora_ult",
              "published": "2026-01-25",
              "snippet": "text-generation-webui leverages LoRA Ultra to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:dolma_next_mixture_of_experts_max_uses_tech",
          "source": "dataset:dolma_next",
          "target": "tech:mixture_of_experts_max",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.78
        }
      },
      {
        "data": {
          "id": "e:mlflow_next_phi_4_lite_integrates_with",
          "source": "tool:mlflow_next",
          "target": "model:phi_4_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.82,
          "evidence": [
            {
              "docId": "2025-12-17_reuters_7749",
              "url": "https://reuters.com/technology/2025/12/17/mlflow_next_phi_4_lite",
              "published": "2025-12-17",
              "snippet": "MLflow Next now supports Phi-4 Lite with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llamacpp_lite_rlhf_uses_tech",
          "source": "repo:llamacpp_lite",
          "target": "tech:rlhf",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.67,
          "evidence": [
            {
              "docId": "2025-12-25_wired_9007",
              "url": "https://wired.com/2025/12/25/llamacpp_lite_rlhf",
              "published": "2025-12-25",
              "snippet": "Technical details reveal llama.cpp Lite relies heavily on RLHF..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mixture_of_experts_meets_instruction_tun_speculative_decoding_uses_tech",
          "source": "paper:mixture_of_experts_meets_instruction_tun",
          "target": "tech:speculative_decoding",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.86
        }
      },
      {
        "data": {
          "id": "e:whisper_v4_v2_chain_of_thought_uses_tech",
          "source": "model:whisper_v4_v2",
          "target": "tech:chain_of_thought",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-25_anthropic_blog_9204",
              "url": "https://anthropic.com/news/2026/01/25/whisper_v4_v2_chain_of_thought",
              "published": "2026-01-25",
              "snippet": "Under the hood, Whisper v4 v2 implements Chain-of-Thought for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:semantic_kernel_edge_aya_3_v2_integrates_with",
          "source": "tool:semantic_kernel_edge",
          "target": "model:aya_3_v2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2026-01-03_wired_5043",
              "url": "https://wired.com/2026/01/03/semantic_kernel_edge_aya_3_v2",
              "published": "2026-01-03",
              "snippet": "The latest release of Semantic Kernel Edge adds native Aya 3 v2 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:cursor_edge_llamaindex_integrates_with",
          "source": "tool:cursor_edge",
          "target": "tool:llamaindex",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.76,
          "evidence": [
            {
              "docId": "2026-01-25_ars_technica_2290",
              "url": "https://arstechnica.com/2026/01/25/cursor_edge_llamaindex",
              "published": "2026-01-25",
              "snippet": "The latest release of Cursor Edge adds native LlamaIndex integration..."
            },
            {
              "docId": "2026-01-25_meta_ai_blog_2907",
              "url": "https://ai.meta.com/blog/2026/01/25/cursor_edge_llamaindex",
              "published": "2026-01-25",
              "snippet": "The latest release of Cursor Edge adds native LlamaIndex integration..."
            },
            {
              "docId": "2026-01-25_wired_7085",
              "url": "https://wired.com/2026/01/25/cursor_edge_llamaindex",
              "published": "2026-01-25",
              "snippet": "Cursor Edge announced official support for LlamaIndex..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:lora:_low_rank_adaptation_of_large_langu_speculative_decoding_uses_tech",
          "source": "paper:lora:_low_rank_adaptation_of_large_langu",
          "target": "tech:speculative_decoding",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2026-01-21_anthropic_blog_7814",
              "url": "https://anthropic.com/news/2026/01/21/lora:_low_rank_adaptation_of_l",
              "published": "2026-01-21",
              "snippet": "Technical details reveal LoRA: Low-Rank Adaptation of Large Language Models relies heavily on Speculative Decoding..."
            },
            {
              "docId": "2026-01-25_reuters_8007",
              "url": "https://reuters.com/technology/2026/01/25/lora:_low_rank_adaptation_of_l",
              "published": "2026-01-25",
              "snippet": "Under the hood, LoRA: Low-Rank Adaptation of Large Language Models implements Speculative Decoding for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:scaling_data_constrained_language_models_codex_2_evaluated_on",
          "source": "paper:scaling_data_constrained_language_models",
          "target": "model:codex_2",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.74,
          "evidence": [
            {
              "docId": "2026-01-25_ars_technica_5669",
              "url": "https://arstechnica.com/2026/01/25/scaling_data_constrained_langu",
              "published": "2026-01-25",
              "snippet": "Evaluation results show Scaling Data-Constrained Language Models reaching 93% on Codex 2..."
            },
            {
              "docId": "2026-01-25_reuters_2563",
              "url": "https://reuters.com/technology/2026/01/25/scaling_data_constrained_langu",
              "published": "2026-01-25",
              "snippet": "On the Codex 2 benchmark, Scaling Data-Constrained Language Models scored 81%..."
            },
            {
              "docId": "2026-01-25_the_gradient_4397",
              "url": "https://thegradient.pub/2026/01/25/scaling_data_constrained_langu",
              "published": "2026-01-25",
              "snippet": "Scaling Data-Constrained Language Models achieves 86% on Codex 2, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:math_midjourney_v7_measures",
          "source": "benchmark:math",
          "target": "model:midjourney_v7",
          "rel": "MEASURES",
          "kind": "inferred",
          "confidence": 0.81
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_group_query_attention_v2_uses_tech",
          "source": "paper:direct_preference_optimization",
          "target": "tech:group_query_attention_v2",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.81,
          "evidence": [
            {
              "docId": "2026-01-21_nextgov_7337",
              "url": "https://nextgov.com/2026/01/21/direct_preference_optimization",
              "published": "2026-01-21",
              "snippet": "Direct Preference Optimization leverages Group Query Attention v2 to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:haystack_stable_diffusion_4_mini_integrates_with",
          "source": "tool:haystack",
          "target": "model:stable_diffusion_4_mini",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.92
        }
      },
      {
        "data": {
          "id": "e:claude_sonnet_4_edge_mbpp_evaluated_on",
          "source": "model:claude_sonnet_4_edge",
          "target": "benchmark:mbpp",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.8,
          "evidence": [
            {
              "docId": "2026-01-13_arxiv_7952",
              "url": "https://arxiv.org/abs/2026/01/13/claude_sonnet_4_edge_mbpp",
              "published": "2026-01-13",
              "snippet": "Claude Sonnet 4 Edge achieves 70% on MBPP, setting a new record..."
            },
            {
              "docId": "2026-01-16_hugging_face_bl_2420",
              "url": "https://huggingface.co/blog/2026/01/16/claude_sonnet_4_edge_mbpp",
              "published": "2026-01-16",
              "snippet": "On the MBPP benchmark, Claude Sonnet 4 Edge scored 72%..."
            },
            {
              "docId": "2026-01-25_the_verge_8014",
              "url": "https://theverge.com/2026/01/25/claude_sonnet_4_edge_mbpp",
              "published": "2026-01-25",
              "snippet": "Claude Sonnet 4 Edge achieves 79% on MBPP, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:constitutional_ai:_harmlessness_from_ai__stable_diffusion_4_evaluated_on",
          "source": "paper:constitutional_ai:_harmlessness_from_ai_",
          "target": "model:stable_diffusion_4",
          "rel": "EVALUATED_ON",
          "kind": "inferred",
          "confidence": 0.9
        }
      },
      {
        "data": {
          "id": "e:claude_opus_45_lmsys_chatbot_arena_evaluated_on",
          "source": "model:claude_opus_45",
          "target": "benchmark:lmsys_chatbot_arena",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.84,
          "evidence": [
            {
              "docId": "2025-12-29_venturebeat_1328",
              "url": "https://venturebeat.com/2025/12/29/claude_opus_45_lmsys_chatbot_a",
              "published": "2025-12-29",
              "snippet": "Evaluation results show Claude Opus 4.5 reaching 87% on LMSYS Chatbot Arena..."
            },
            {
              "docId": "2026-01-25_the_gradient_7445",
              "url": "https://thegradient.pub/2026/01/25/claude_opus_45_lmsys_chatbot_a",
              "published": "2026-01-25",
              "snippet": "Evaluation results show Claude Opus 4.5 reaching 73% on LMSYS Chatbot Arena..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:whisper_v4_quantization_uses_tech",
          "source": "model:whisper_v4",
          "target": "tech:quantization",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.7,
          "evidence": [
            {
              "docId": "2026-01-25_microsoft_resea_8206",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/25/whisper_v4_quantization",
              "published": "2026-01-25",
              "snippet": "Technical details reveal Whisper v4 relies heavily on Quantization..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:weights_and_biases_plus_cody_pro_integrates_with",
          "source": "tool:weights_and_biases_plus",
          "target": "tool:cody_pro",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.85,
          "evidence": [
            {
              "docId": "2026-01-23_venturebeat_7985",
              "url": "https://venturebeat.com/2026/01/23/weights_and_biases_plus_cody_p",
              "published": "2026-01-23",
              "snippet": "Weights & Biases Plus now supports Cody Pro with full feature parity..."
            },
            {
              "docId": "2026-01-25_arxiv_3887",
              "url": "https://arxiv.org/abs/2026/01/25/weights_and_biases_plus_cody_p",
              "published": "2026-01-25",
              "snippet": "Weights & Biases Plus now supports Cody Pro with full feature parity..."
            },
            {
              "docId": "2026-01-25_hugging_face_bl_9343",
              "url": "https://huggingface.co/blog/2026/01/25/weights_and_biases_plus_cody_p",
              "published": "2026-01-25",
              "snippet": "The latest release of Weights & Biases Plus adds native Cody Pro integration..."
            },
            {
              "docId": "2026-01-25_techcrunch_3967",
              "url": "https://techcrunch.com/2026/01/25/weights_and_biases_plus_cody_p",
              "published": "2026-01-25",
              "snippet": "Weights & Biases Plus announced official support for Cody Pro..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:llama_4_next_c4_ultra_trained_on",
          "source": "model:llama_4_next",
          "target": "dataset:c4_ultra",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.69,
          "evidence": [
            {
              "docId": "2026-01-25_ars_technica_8179",
              "url": "https://arstechnica.com/2026/01/25/llama_4_next_c4_ultra",
              "published": "2026-01-25",
              "snippet": "Llama 4 Next was trained on C4 Ultra comprising billions of tokens..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:vllm_jamba_2_integrates_with",
          "source": "repo:vllm",
          "target": "model:jamba_2",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.79
        }
      },
      {
        "data": {
          "id": "e:llamacpp_aya_3_integrates_with",
          "source": "repo:llamacpp",
          "target": "model:aya_3",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.79,
          "evidence": [
            {
              "docId": "2026-01-25_reuters_8812",
              "url": "https://reuters.com/technology/2026/01/25/llamacpp_aya_3",
              "published": "2026-01-25",
              "snippet": "llama.cpp announced official support for Aya 3..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:localai_whisper_v4_next_integrates_with",
          "source": "repo:localai",
          "target": "model:whisper_v4_next",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.76
        }
      },
      {
        "data": {
          "id": "e:direct_preference_optimization_aya_3_evaluated_on",
          "source": "paper:direct_preference_optimization",
          "target": "model:aya_3",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.89,
          "evidence": [
            {
              "docId": "2026-01-21_nvidia_blog_2466",
              "url": "https://blogs.nvidia.com/2026/01/21/direct_preference_optimization",
              "published": "2026-01-21",
              "snippet": "Direct Preference Optimization achieves 86% on Aya 3, setting a new record..."
            },
            {
              "docId": "2026-01-23_reuters_3202",
              "url": "https://reuters.com/technology/2026/01/23/direct_preference_optimization",
              "published": "2026-01-23",
              "snippet": "On the Aya 3 benchmark, Direct Preference Optimization scored 94%..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:grok_3_ultra_common_crawl_plus_trained_on",
          "source": "model:grok_3_ultra",
          "target": "dataset:common_crawl_plus",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.74
        }
      },
      {
        "data": {
          "id": "e:localai_cursor_edge_integrates_with",
          "source": "tool:localai",
          "target": "tool:cursor_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.65,
          "evidence": [
            {
              "docId": "2025-11-21_bloomberg_5481",
              "url": "https://bloomberg.com/technology/2025/11/21/localai_cursor_edge",
              "published": "2025-11-21",
              "snippet": "LocalAI now supports Cursor Edge with full feature parity..."
            },
            {
              "docId": "2026-01-09_reuters_9256",
              "url": "https://reuters.com/technology/2026/01/09/localai_cursor_edge",
              "published": "2026-01-09",
              "snippet": "The latest release of LocalAI adds native Cursor Edge integration..."
            },
            {
              "docId": "2026-01-19_nextgov_3970",
              "url": "https://nextgov.com/2026/01/19/localai_cursor_edge",
              "published": "2026-01-19",
              "snippet": "The latest release of LocalAI adds native Cursor Edge integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:roots_chain_of_thought_max_uses_tech",
          "source": "dataset:roots",
          "target": "tech:chain_of_thought_max",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.43
        }
      },
      {
        "data": {
          "id": "e:swe_bench_next_falcon_3_pro_measures",
          "source": "benchmark:swe_bench_next",
          "target": "model:falcon_3_pro",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.9,
          "evidence": [
            {
              "docId": "2025-12-21_ars_technica_2293",
              "url": "https://arstechnica.com/2025/12/21/swe_bench_next_falcon_3_pro",
              "published": "2025-12-21",
              "snippet": "SWE-bench Next has become the standard for evaluating Falcon 3 Pro..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:palm_3_the_pile_core_trained_on",
          "source": "model:palm_3",
          "target": "dataset:the_pile_core",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.64,
          "evidence": [
            {
              "docId": "2026-01-02_wired_8565",
              "url": "https://wired.com/2026/01/02/palm_3_the_pile_core",
              "published": "2026-01-02",
              "snippet": "The training corpus for PaLM 3 includes The Pile Core..."
            },
            {
              "docId": "2026-01-10_google_ai_blog_5030",
              "url": "https://blog.google/technology/ai/2026/01/10/palm_3_the_pile_core",
              "published": "2026-01-10",
              "snippet": "PaLM 3 was trained on The Pile Core comprising billions of tokens..."
            },
            {
              "docId": "2026-01-14_nextgov_5754",
              "url": "https://nextgov.com/2026/01/14/palm_3_the_pile_core",
              "published": "2026-01-14",
              "snippet": "PaLM 3 was trained on The Pile Core comprising billions of tokens..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:claude_sonnet_4_edge_mixture_of_experts_max_uses_tech",
          "source": "model:claude_sonnet_4_edge",
          "target": "tech:mixture_of_experts_max",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.73
        }
      },
      {
        "data": {
          "id": "e:starcoder_data_pro_sliding_window_attention_uses_tech",
          "source": "dataset:starcoder_data_pro",
          "target": "tech:sliding_window_attention",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.65
        }
      },
      {
        "data": {
          "id": "e:palm_3_laion_5b_trained_on",
          "source": "model:palm_3",
          "target": "dataset:laion_5b",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.86
        }
      },
      {
        "data": {
          "id": "e:alpacaeval_2_dall_e_4_edge_measures",
          "source": "benchmark:alpacaeval_2",
          "target": "model:dall_e_4_edge",
          "rel": "MEASURES",
          "kind": "inferred",
          "confidence": 0.94
        }
      },
      {
        "data": {
          "id": "e:transformers_tool_use_uses_tech",
          "source": "repo:transformers",
          "target": "tech:tool_use",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.74,
          "evidence": [
            {
              "docId": "2026-01-24_openai_blog_7396",
              "url": "https://openai.com/blog/2026/01/24/transformers_tool_use",
              "published": "2026-01-24",
              "snippet": "transformers leverages Tool Use to achieve state-of-the-art performance..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:starcoder_data_mixture_of_experts_max_uses_tech",
          "source": "dataset:starcoder_data",
          "target": "tech:mixture_of_experts_max",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.61
        }
      },
      {
        "data": {
          "id": "e:tree_of_thoughts:_deliberate_problem_sol_multimodal_fusion_uses_tech",
          "source": "paper:tree_of_thoughts:_deliberate_problem_sol",
          "target": "tech:multimodal_fusion",
          "rel": "USES_TECH",
          "kind": "asserted",
          "confidence": 0.91,
          "evidence": [
            {
              "docId": "2025-12-26_meta_ai_blog_5255",
              "url": "https://ai.meta.com/blog/2025/12/26/tree_of_thoughts:_deliberate_p",
              "published": "2025-12-26",
              "snippet": "Under the hood, Tree of Thoughts: Deliberate Problem Solving with LLMs implements Multimodal Fusion for improved efficiency..."
            },
            {
              "docId": "2026-01-02_microsoft_resea_3542",
              "url": "https://microsoft.com/en-us/research/blog/2026/01/02/tree_of_thoughts:_deliberate_p",
              "published": "2026-01-02",
              "snippet": "Technical details reveal Tree of Thoughts: Deliberate Problem Solving with LLMs relies heavily on Multimodal Fusion..."
            },
            {
              "docId": "2026-01-21_ars_technica_1657",
              "url": "https://arstechnica.com/2026/01/21/tree_of_thoughts:_deliberate_p",
              "published": "2026-01-21",
              "snippet": "Under the hood, Tree of Thoughts: Deliberate Problem Solving with LLMs implements Multimodal Fusion for improved efficiency..."
            },
            {
              "docId": "2026-01-24_techcrunch_4157",
              "url": "https://techcrunch.com/2026/01/24/tree_of_thoughts:_deliberate_p",
              "published": "2026-01-24",
              "snippet": "Under the hood, Tree of Thoughts: Deliberate Problem Solving with LLMs implements Multimodal Fusion for improved efficiency..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:gpqa_next_command_r_plus_measures",
          "source": "benchmark:gpqa_next",
          "target": "model:command_r_plus",
          "rel": "MEASURES",
          "kind": "asserted",
          "confidence": 0.88,
          "evidence": [
            {
              "docId": "2026-01-16_mit_technology__7093",
              "url": "https://technologyreview.com/2026/01/16/gpqa_next_command_r_plus",
              "published": "2026-01-16",
              "snippet": "The GPQA Next benchmark measures Command R+ across multiple tasks..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:falcon_3_pro_mixtral_8x22b_depends_on",
          "source": "model:falcon_3_pro",
          "target": "model:mixtral_8x22b",
          "rel": "DEPENDS_ON",
          "kind": "inferred",
          "confidence": 0.53
        }
      },
      {
        "data": {
          "id": "e:vllm_gemini_ultra_2_lite_integrates_with",
          "source": "tool:vllm",
          "target": "model:gemini_ultra_2_lite",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.91
        }
      },
      {
        "data": {
          "id": "e:haystack_mixture_of_experts_uses_tech",
          "source": "tool:haystack",
          "target": "tech:mixture_of_experts",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.71
        }
      },
      {
        "data": {
          "id": "e:transformers_next_falcon_3_integrates_with",
          "source": "repo:transformers_next",
          "target": "model:falcon_3",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.75
        }
      },
      {
        "data": {
          "id": "e:phi_4_mini_tokenizer_bpe_uses_tech",
          "source": "model:phi_4_mini",
          "target": "tech:tokenizer_bpe",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.63
        }
      },
      {
        "data": {
          "id": "e:jamba_2_dolma_next_trained_on",
          "source": "model:jamba_2",
          "target": "dataset:dolma_next",
          "rel": "TRAINED_ON",
          "kind": "asserted",
          "confidence": 0.73,
          "evidence": [
            {
              "docId": "2026-01-11_techcrunch_6507",
              "url": "https://techcrunch.com/2026/01/11/jamba_2_dolma_next",
              "published": "2026-01-11",
              "snippet": "Jamba 2 utilized Dolma Next as part of its pre-training data mix..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:nemotron_5_gsm8k_core_evaluated_on",
          "source": "model:nemotron_5",
          "target": "benchmark:gsm8k_core",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.94,
          "evidence": [
            {
              "docId": "2026-01-23_nvidia_blog_7846",
              "url": "https://blogs.nvidia.com/2026/01/23/nemotron_5_gsm8k_core",
              "published": "2026-01-23",
              "snippet": "Evaluation results show Nemotron-5 reaching 83% on GSM8K Core..."
            },
            {
              "docId": "2026-01-23_meta_ai_blog_6143",
              "url": "https://ai.meta.com/blog/2026/01/23/nemotron_5_gsm8k_core",
              "published": "2026-01-23",
              "snippet": "Nemotron-5 achieves 94% on GSM8K Core, setting a new record..."
            },
            {
              "docId": "2026-01-23_bloomberg_7040",
              "url": "https://bloomberg.com/technology/2026/01/23/nemotron_5_gsm8k_core",
              "published": "2026-01-23",
              "snippet": "Evaluation results show Nemotron-5 reaching 71% on GSM8K Core..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:streamlit_pro_ollama_edge_integrates_with",
          "source": "tool:streamlit_pro",
          "target": "tool:ollama_edge",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.6
        }
      },
      {
        "data": {
          "id": "e:semantic_kernel_edge_llamaindex_integrates_with",
          "source": "tool:semantic_kernel_edge",
          "target": "tool:llamaindex",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.61,
          "evidence": [
            {
              "docId": "2026-01-24_mit_technology__9066",
              "url": "https://technologyreview.com/2026/01/24/semantic_kernel_edge_llamainde",
              "published": "2026-01-24",
              "snippet": "Semantic Kernel Edge now supports LlamaIndex with full feature parity..."
            },
            {
              "docId": "2026-01-25_anthropic_blog_8838",
              "url": "https://anthropic.com/news/2026/01/25/semantic_kernel_edge_llamainde",
              "published": "2026-01-25",
              "snippet": "The latest release of Semantic Kernel Edge adds native LlamaIndex integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:localai_deepseek_v3_integrates_with",
          "source": "repo:localai",
          "target": "model:deepseek_v3",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.74,
          "evidence": [
            {
              "docId": "2026-01-23_arxiv_9076",
              "url": "https://arxiv.org/abs/2026/01/23/localai_deepseek_v3",
              "published": "2026-01-23",
              "snippet": "The latest release of LocalAI adds native DeepSeek-V3 integration..."
            },
            {
              "docId": "2026-01-24_mit_technology__9318",
              "url": "https://technologyreview.com/2026/01/24/localai_deepseek_v3",
              "published": "2026-01-24",
              "snippet": "LocalAI now supports DeepSeek-V3 with full feature parity..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:langchain_plus_group_query_attention_core_uses_tech",
          "source": "tool:langchain_plus",
          "target": "tech:group_query_attention_core",
          "rel": "USES_TECH",
          "kind": "hypothesis",
          "confidence": 0.89
        }
      },
      {
        "data": {
          "id": "e:claude_sonnet_4_math_evaluated_on",
          "source": "model:claude_sonnet_4",
          "target": "benchmark:math",
          "rel": "EVALUATED_ON",
          "kind": "asserted",
          "confidence": 0.97,
          "evidence": [
            {
              "docId": "2026-01-23_wired_5924",
              "url": "https://wired.com/2026/01/23/claude_sonnet_4_math",
              "published": "2026-01-23",
              "snippet": "On the MATH benchmark, Claude Sonnet 4 scored 85%..."
            },
            {
              "docId": "2026-01-25_langchain_blog_9418",
              "url": "https://blog.langchain.dev/2026/01/25/claude_sonnet_4_math",
              "published": "2026-01-25",
              "snippet": "Claude Sonnet 4 achieves 97% on MATH, setting a new record..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:mixtral_8x22b_the_stack_v2_trained_on",
          "source": "model:mixtral_8x22b",
          "target": "dataset:the_stack_v2",
          "rel": "TRAINED_ON",
          "kind": "hypothesis",
          "confidence": 0.6
        }
      },
      {
        "data": {
          "id": "e:fineweb_v2_tool_use_v2_uses_tech",
          "source": "dataset:fineweb_v2",
          "target": "tech:tool_use_v2",
          "rel": "USES_TECH",
          "kind": "inferred",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:ollama_edge_gpt_5_v2_integrates_with",
          "source": "tool:ollama_edge",
          "target": "model:gpt_5_v2",
          "rel": "INTEGRATES_WITH",
          "kind": "asserted",
          "confidence": 0.83,
          "evidence": [
            {
              "docId": "2026-01-25_openai_blog_7258",
              "url": "https://openai.com/blog/2026/01/25/ollama_edge_gpt_5_v2",
              "published": "2026-01-25",
              "snippet": "The latest release of Ollama Edge adds native GPT-5 v2 integration..."
            }
          ]
        }
      },
      {
        "data": {
          "id": "e:copilot_ultra_dify_ultra_integrates_with",
          "source": "tool:copilot_ultra",
          "target": "tool:dify_ultra",
          "rel": "INTEGRATES_WITH",
          "kind": "inferred",
          "confidence": 0.62
        }
      },
      {
        "data": {
          "id": "e:gemma_3_slimpajama_edge_trained_on",
          "source": "model:gemma_3",
          "target": "dataset:slimpajama_edge",
          "rel": "TRAINED_ON",
          "kind": "inferred",
          "confidence": 0.63
        }
      }
    ]
  }
}